{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pepperamy/disclosure_change/blob/main/change_siamese_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeAcrDg6XCXT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHs8hBX-gir"
      },
      "source": [
        "# initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJb2zDwTTYN_"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu0EN6PyT1PH",
        "outputId": "e843e0b8-ee5e-4e14-99d3-1742f8b58124"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\KK\\Anaconda3\\envs\\py38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "C:\\Users\\KK\\Anaconda3\\envs\\py38\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
            "C:\\Users\\KK\\Anaconda3\\envs\\py38\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys, os\n",
        "\n",
        "use_colab = False\n",
        "if use_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    !pip install linearmodels\n",
        "    \n",
        "    cur_path = os.path.join('/content/drive/MyDrive/change')\n",
        "    os.chdir(cur_path)\n",
        "\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install -U sentence-transformers\n",
        "\n",
        "    !pip install torchinfo\n",
        "\n",
        "    !pip install tqdm\n",
        "\n",
        "    \n",
        "    !pip install numba\n",
        "    \n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "      print('and then re-execute this cell.')\n",
        "    else:\n",
        "      print(gpu_info)\n",
        "\n",
        "\n",
        "else:\n",
        "    cur_path = os.path.join('H:\\\\My Drive\\\\change')\n",
        "    os.chdir(cur_path)\n",
        "    import torch\n",
        "    torch.cuda.is_available()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozNiaCk1-giv"
      },
      "outputs": [],
      "source": [
        "import random, pickle\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss, MSELoss\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score, precision_recall_fscore_support\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "#from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from torchinfo import summary\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import copy\n",
        "from sklearn.utils import shuffle\n",
        "import glob\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from numba import cuda "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QizxEwD8UAOS"
      },
      "outputs": [],
      "source": [
        "# # Get the GPU device name.\n",
        "# device_name = torch.cuda.get_device_name()\n",
        "# print(device_name)\n",
        "# # The device name should look like the following:\n",
        "# if device_name == '/device:GPU:0':\n",
        "#     print('Found GPU at: {}'.format(device_name))\n",
        "# else:\n",
        "#     device_name =\"/cpu:0\"\n",
        "#     print('GPU device not found')\n",
        "#     #raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTwQrBkpUCCl",
        "outputId": "ace172b4-87b8-4351-ceb4-3c3f63356d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA GeForce GTX 1060 6GB\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUug4wghYz5i"
      },
      "outputs": [],
      "source": [
        "# t = torch.cuda.get_device_properties(0).total_memory\n",
        "# r = torch.cuda.memory_reserved(0)\n",
        "# a = torch.cuda.memory_allocated(0)\n",
        "# f = r-a  # free inside reserved\n",
        "# print(f// 1024 ** 2)\n",
        "from pynvml import *\n",
        "def get_free_gpu():\n",
        "    nvmlInit()\n",
        "    h = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(h)\n",
        "    print(f'total    : {info.total // 1024 ** 2}')\n",
        "    print(f'free     : {info.free// 1024 ** 2}')\n",
        "    print(f'used     : {info.used// 1024 ** 2}')\n",
        "    #print(torch.cuda.memory_summary()) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa4tBC4E-giy",
        "outputId": "c391cad2-b44c-4474-da55-d2f61009ffda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 4576\n",
            "used     : 1567\n"
          ]
        }
      ],
      "source": [
        "get_free_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU3LGfKTwd40"
      },
      "outputs": [],
      "source": [
        "# def get_free_gpu():\n",
        "#     t = torch.cuda.get_device_properties(0).total_memory\n",
        "#     r = torch.cuda.memory_reserved(0)\n",
        "#     a = torch.cuda.memory_allocated(0)\n",
        "#     f = r-a  # free inside reserved\n",
        "#     print(f// 1024 ** 2)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yQXj6xF-giz"
      },
      "outputs": [],
      "source": [
        "# from pynvml import *\n",
        "# nvmlInit()\n",
        "# h = nvmlDeviceGetHandleByIndex(0)\n",
        "# info = nvmlDeviceGetMemoryInfo(h)\n",
        "# print(f'total    : {info.total}')\n",
        "# print(f'free     : {info.free}')\n",
        "# print(f'used     : {info.used}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnJvkQHFZUhZ"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6MPD-c79971"
      },
      "outputs": [],
      "source": [
        "#para_map = pickle.load(open(\"./data/paragraphs_1994_2016-001.pkl\", 'rb'))\n",
        "#para_map = pickle.load(open(\"data/mda/paragraphs_1994_2016_original.pkl\", 'rb'))\n",
        "# len(para_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO5o9c_29971"
      },
      "outputs": [],
      "source": [
        "#cik_list = list(para_map.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liRWixWG-gi0"
      },
      "outputs": [],
      "source": [
        "# para_test only contian 20 1750\n",
        "para_map = pickle.load(open(\"./data/para_test.pkl\",\"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4ECAOFv9971"
      },
      "outputs": [],
      "source": [
        "pos_neg_pair = pd.read_csv('./data/pos_neg_pair.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JPzMsaFZ9_hA",
        "outputId": "09f04345-0255-4d14-af3c-5b4e088785f3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>fyear</th>\n",
              "      <th>count_para</th>\n",
              "      <th>fraud</th>\n",
              "      <th>fyear_bf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>1995</td>\n",
              "      <td>41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>1996</td>\n",
              "      <td>31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1995.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>1997</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1996.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>1998</td>\n",
              "      <td>49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>1999</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cik  fyear  count_para  fraud  fyear_bf\n",
              "0   20   1995          41    0.0       NaN\n",
              "1   20   1996          31    0.0    1995.0\n",
              "2   20   1997          34    0.0    1996.0\n",
              "3   20   1998          49    0.0    1997.0\n",
              "4   20   1999          40    0.0    1998.0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_pair.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hy59_Qqi-BJj",
        "outputId": "ed705405-2ff6-4278-9317-82bf6a980e5d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>fyear</th>\n",
              "      <th>count_para</th>\n",
              "      <th>fraud</th>\n",
              "      <th>fyear_bf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151165</th>\n",
              "      <td>1688941</td>\n",
              "      <td>2016</td>\n",
              "      <td>126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151166</th>\n",
              "      <td>1689490</td>\n",
              "      <td>2016</td>\n",
              "      <td>55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151167</th>\n",
              "      <td>1690666</td>\n",
              "      <td>2016</td>\n",
              "      <td>109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151168</th>\n",
              "      <td>1691430</td>\n",
              "      <td>2016</td>\n",
              "      <td>46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151169</th>\n",
              "      <td>1695098</td>\n",
              "      <td>2016</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            cik  fyear  count_para  fraud  fyear_bf\n",
              "151165  1688941   2016         126    0.0       NaN\n",
              "151166  1689490   2016          55    0.0       NaN\n",
              "151167  1690666   2016         109    0.0       NaN\n",
              "151168  1691430   2016          46    0.0       NaN\n",
              "151169  1695098   2016          27    0.0       NaN"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_pair.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3hutWlF_feu"
      },
      "outputs": [],
      "source": [
        "pos_neg_pair = pos_neg_pair.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMdKtiqP_h02",
        "outputId": "7e650a97-698d-4faa-eb88-e80f2304ca1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0    129440\n",
              "1.0       837\n",
              "Name: fraud, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_pair.fraud.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0_1ffd1n-gi2",
        "outputId": "820dfdac-e5f6-4a55-a39e-8d0fc48d34b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>fyear</th>\n",
              "      <th>count_para</th>\n",
              "      <th>fraud</th>\n",
              "      <th>fyear_bf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>1996</td>\n",
              "      <td>31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1995.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>1997</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1996.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>1998</td>\n",
              "      <td>49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>1999</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>2000</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1999.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151039</th>\n",
              "      <td>1658432</td>\n",
              "      <td>2016</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151051</th>\n",
              "      <td>1660156</td>\n",
              "      <td>2016</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151056</th>\n",
              "      <td>1660719</td>\n",
              "      <td>2016</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151067</th>\n",
              "      <td>1662684</td>\n",
              "      <td>2016</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151079</th>\n",
              "      <td>1666114</td>\n",
              "      <td>2016</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130277 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            cik  fyear  count_para  fraud  fyear_bf\n",
              "1            20   1996          31    0.0    1995.0\n",
              "2            20   1997          34    0.0    1996.0\n",
              "3            20   1998          49    0.0    1997.0\n",
              "4            20   1999          40    0.0    1998.0\n",
              "5            20   2000          34    0.0    1999.0\n",
              "...         ...    ...         ...    ...       ...\n",
              "151039  1658432   2016          25    0.0    2015.0\n",
              "151051  1660156   2016          11    0.0    2015.0\n",
              "151056  1660719   2016          32    0.0    2015.0\n",
              "151067  1662684   2016          39    0.0    2015.0\n",
              "151079  1666114   2016          27    0.0    2015.0\n",
              "\n",
              "[130277 rows x 5 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_neg_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUMdwIrQZHpu"
      },
      "outputs": [],
      "source": [
        "# def get_df_for_cik(cik):\n",
        "    \n",
        "#     df = pd.concat({k: pd.Series(v) for k, v in para_map[cik].items()})\n",
        "#     df = df.reset_index()\n",
        "    \n",
        "#     df.columns = ['fyear','pid','text']\n",
        "#     df = df.sort_values(by=['fyear','pid'])\n",
        "#     df = df.reset_index(drop = True)\n",
        "#     df['cik'] = cik\n",
        "#     df = df[['cik', 'fyear','pid','text']]\n",
        "    \n",
        "#     return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oLd-QiEbxEB"
      },
      "source": [
        "# funtions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuR9o8Ca-gi3"
      },
      "source": [
        "## embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrAB2zmq-gi4",
        "outputId": "ee329e0e-2fdd-4b1a-d6d8-7676cdbcdbbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the BERT tokenizer.\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(\n",
        "    # 'ProsusAI/finbert',\n",
        "    'bert-base-uncased',\n",
        "    # 'yiyanghkust/finbert-pretrain',\n",
        "    num_labels = 2, \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "    )\n",
        "bert_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          2
        ],
        "id": "pB8b7WaQ-gi4"
      },
      "outputs": [],
      "source": [
        "# Put everything together as a function. This is for pretrained word vectors\n",
        "\n",
        "def get_pretrained_wordvector(sentences, tokenizer, bert_model, max_len=100):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    max_len = max_len\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        #padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(input_ids.to(device), attention_masks.to(device))   \n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    \n",
        "    # get the last four layers\n",
        "    token_embeddings = torch.stack(hidden_states[-4:], dim=0) \n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # permute axis\n",
        "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
        "    #print(token_embeddings.size())\n",
        "\n",
        "    # take the mean of the last 4 layers\n",
        "    token_embeddings = token_embeddings.mean(axis=2)\n",
        "\n",
        "    #print(token_embeddings.size())\n",
        "    input_ids.detach().to('cpu')\n",
        "    attention_masks.detach().to('cpu')\n",
        "    token_embeddings.detach().to('cpu')\n",
        "    del input_ids\n",
        "    return token_embeddings, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "GiHGlNGq-gi4"
      },
      "outputs": [],
      "source": [
        "def get_text_embedding(cik, fyear, fyear_bf, tokenizer, bert_model, num_para, wrd_len=100, para_map = para_map):\n",
        "    print(cik, fyear, fyear_bf)\n",
        "    df = pd.concat({k: pd.Series(v) for k, v in para_map[cik].items()})\n",
        "    df = df.reset_index()\n",
        "    df.columns = ['fyear','pid','text']\n",
        "\n",
        "    input = df[df.fyear == fyear].text.values\n",
        "    input_bf = df[df.fyear == fyear_bf].text.values\n",
        "\n",
        "    #get embedding for input\n",
        "    token_embeddings, masks = get_pretrained_wordvector(input, tokenizer, bert_model, max_len = wrd_len)\n",
        "    token_embeddings = token_embeddings.to(device) * masks.unsqueeze(-1).to(device) # (atc_num_para, #wrd_len, #dim)\n",
        "    # padding paragraphs\n",
        "    print('1 token_embeddings',token_embeddings.size())\n",
        "    pad_num = num_para - token_embeddings.size()[0]\n",
        "    if pad_num>0:\n",
        "        token_embeddings = F.pad(input=token_embeddings, pad=(0,0,0,0,0,pad_num))\n",
        "        print('2 token_embeddings',token_embeddings.size())\n",
        "    elif pad_num<0:\n",
        "        token_embeddings = token_embeddings[0:60]\n",
        "        print('2 token_embeddings',token_embeddings.size())\n",
        "    else:\n",
        "        token_embeddings = token_embeddings\n",
        "\n",
        "    #get embedding for input_bf\n",
        "    token_embeddings_bf, masks_bf = get_pretrained_wordvector(input_bf, tokenizer, bert_model, max_len = wrd_len)\n",
        "    token_embeddings_bf = token_embeddings_bf.to(device) * masks_bf.unsqueeze(-1).to(device) # (atc_num_para, #wrd_len, #dim)\n",
        "    # padding paragraphs\n",
        "    print('1 token_embeddings_bf',token_embeddings_bf.size())\n",
        "    pad_num_bf = num_para - token_embeddings_bf.size()[0]\n",
        "    #print('pad_num_bf', pad_num_bf)\n",
        "    if pad_num_bf>0:\n",
        "        #print('>0')\n",
        "        token_embeddings_bf = F.pad(input=token_embeddings_bf, pad=(0,0,0,0,0,pad_num_bf))\n",
        "        print('2 token_embeddings_bf',token_embeddings_bf.size())\n",
        "    elif pad_num_bf<0:\n",
        "        #print('<0')\n",
        "        token_embeddings_bf = token_embeddings_bf[0:60]\n",
        "        print('2 token_embeddings_bf',token_embeddings_bf.size())\n",
        "    else:\n",
        "        token_embeddings_bf = token_embeddings_bf\n",
        "\n",
        "    return token_embeddings, token_embeddings_bf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz0kJH_J-gi5"
      },
      "source": [
        "## define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "RZC9BSfUZHvX"
      },
      "outputs": [],
      "source": [
        "# define Siamese model\n",
        "class simple_siamese(nn.Module):\n",
        "    def __init__(self, emb_dim, wrd_len, num_filters, kernel_sizes, kernel_sizes2, num_classes=2.0, dropout_rate = 0.3):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.wrd_len = wrd_len\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.kernel_sizes2 = kernel_sizes2\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(768, 256, kernel_size = kernel_sizes), # input (#batch, 768, num_para->60, num_words->100) # kernal size = 10,50  # output: (#batch, 256, 50, 50)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(5, padding=0),  # input (#batch, 256, 50, 50) #output (#batch, 256, 10, 10)\n",
        "            nn.Conv2d(256, 128,  kernel_size = kernel_sizes2), # input (#batch, 256, num_para->10, num_words->10) # kernal size = 3,3\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, padding=0),\n",
        "            nn.ReLU(), \n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(1152, int(self.num_classes))\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        \n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        #permute input to make it fit cnn\n",
        "        x1 = torch.permute(input1, (0,3,1,2))\n",
        "        x2 = torch.permute(input2, (0,3,1,2))\n",
        "        print(x1.size())\n",
        "        print(x2.size())\n",
        "\n",
        "        x1 = self.conv(x1)\n",
        "        x2 = self.conv(x2)\n",
        "        x = torch.sub(x1,x2)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        print(x.size())\n",
        "        x = torch.reshape(x,(x.size()[0],-1))\n",
        "        print(x.size())\n",
        "        logit = self.fc(x)\n",
        "        print('model output',logit.size())\n",
        "\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3WKpV1dZHxu"
      },
      "outputs": [],
      "source": [
        "emb_dim = 768\n",
        "wrd_len = 100\n",
        "num_filters = 128\n",
        "kernel_sizes =  (10,50)\n",
        "kernel_sizes2 =  (2,2)\n",
        "dropout_rate = 0.3\n",
        "num_classes=2.0\n",
        "model = simple_siamese( emb_dim, wrd_len, num_filters, kernel_sizes, kernel_sizes2, num_classes=num_classes,dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsMAbNRCdRQe",
        "outputId": "2d21e88c-ac24-48ed-881a-7b417231f4d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 768, 60, 100])\n",
            "torch.Size([32, 768, 60, 100])\n",
            "torch.Size([32, 128, 3, 3])\n",
            "torch.Size([32, 1152])\n",
            "model output torch.Size([32, 2])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "simple_siamese                           [32, 2]                   --\n",
              "â”œâ”€Sequential: 1-1                        [32, 128, 3, 3]           --\n",
              "â”‚    â””â”€Conv2d: 2-1                       [32, 256, 51, 51]         98,304,256\n",
              "â”‚    â””â”€ReLU: 2-2                         [32, 256, 51, 51]         --\n",
              "â”‚    â””â”€MaxPool2d: 2-3                    [32, 256, 10, 10]         --\n",
              "â”‚    â””â”€Conv2d: 2-4                       [32, 128, 9, 9]           131,200\n",
              "â”‚    â””â”€ReLU: 2-5                         [32, 128, 9, 9]           --\n",
              "â”‚    â””â”€MaxPool2d: 2-6                    [32, 128, 3, 3]           --\n",
              "â”‚    â””â”€ReLU: 2-7                         [32, 128, 3, 3]           --\n",
              "â”œâ”€Sequential: 1-2                        [32, 128, 3, 3]           (recursive)\n",
              "â”‚    â””â”€Conv2d: 2-8                       [32, 256, 51, 51]         (recursive)\n",
              "â”‚    â””â”€ReLU: 2-9                         [32, 256, 51, 51]         --\n",
              "â”‚    â””â”€MaxPool2d: 2-10                   [32, 256, 10, 10]         --\n",
              "â”‚    â””â”€Conv2d: 2-11                      [32, 128, 9, 9]           (recursive)\n",
              "â”‚    â””â”€ReLU: 2-12                        [32, 128, 9, 9]           --\n",
              "â”‚    â””â”€MaxPool2d: 2-13                   [32, 128, 3, 3]           --\n",
              "â”‚    â””â”€ReLU: 2-14                        [32, 128, 3, 3]           --\n",
              "â”œâ”€Dropout: 1-3                           [32, 128, 3, 3]           --\n",
              "â”œâ”€Linear: 1-4                            [32, 2]                   2,306\n",
              "==========================================================================================\n",
              "Total params: 98,437,762\n",
              "Trainable params: 98,437,762\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (T): 16.36\n",
              "==========================================================================================\n",
              "Input size (MB): 1179.65\n",
              "Forward/backward pass size (MB): 173.11\n",
              "Params size (MB): 393.75\n",
              "Estimated Total Size (MB): 1746.51\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model, [(32, 60, 100, 768), (32, 60, 100, 768)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC7yKolO-gi6",
        "outputId": "6bab0a82-eb8c-4b1f-86de-83e377d6f591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 421\n",
            "used     : 5722\n"
          ]
        }
      ],
      "source": [
        "get_free_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5-WiFbb-gi6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6nJ4cRp-gi7"
      },
      "source": [
        "## training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "5a_EaONReznc"
      },
      "outputs": [],
      "source": [
        "def model_eval(model, validation_dataloader, num_labels, class_weight=None):\n",
        "    #tokenized_texts = []\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "\n",
        "    threshold = 0.5\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        print('val 1 free gpu',get_free_gpu())\n",
        "        b_input_key = batch[0]\n",
        "        b_labels = batch[1].to(device)\n",
        "\n",
        "\n",
        "        #convert key to text embedding\n",
        "        tk_batch = []\n",
        "        tk_batch_bf = []\n",
        "        #print('val batch',batch)\n",
        "        for t in b_input_key.detach().to('cpu').numpy():\n",
        "            tk, tk_bf = get_text_embedding(t[0], t[1], t[2], tokenizer, bert_model, para_len, wrd_len=100)\n",
        "            if tk.size()[0] == 60:              \n",
        "                tk_batch.append(tk)\n",
        "                tk_batch_bf.append(tk_bf)\n",
        "            else:\n",
        "                print('token size error')\n",
        "                break\n",
        "\n",
        "        tk_batch = torch.stack(tk_batch)\n",
        "        tk_batch = tk_batch.to(device)\n",
        "\n",
        "        tk_batch_bf = torch.stack(tk_batch_bf)\n",
        "        tk_batch_bf = tk_batch_bf.to(device)\n",
        "        print('val 2 free gpu',get_free_gpu())\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            logits = model(tk_batch, tk_batch_bf)\n",
        "            #loss_func = BCELoss()\n",
        "            #val_loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "            tk_batch.detach().to('cpu')\n",
        "            del tk_batch\n",
        "            tk_batch_bf.detach().to('cpu')\n",
        "            del tk_batch_bf           \n",
        "            print('val 3 free gpu',get_free_gpu())\n",
        "            \n",
        "            if class_weight != None:\n",
        "                pos_weight = torch.tensor(class_weight).to(device)\n",
        "                loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "            else:\n",
        "                loss_func = BCEWithLogitsLoss()\n",
        "\n",
        "            val_loss = loss_func(\n",
        "                logits,\n",
        "                b_labels.type_as(logits))  #convert labels to float for calculation\n",
        "\n",
        "            total_eval_loss += val_loss.item()\n",
        "\n",
        "            pred_label = torch.sigmoid(logits)\n",
        "            b_labels = b_labels.to('cpu').numpy()\n",
        "            pred_label = pred_label.to('cpu').numpy()\n",
        "\n",
        "            #tokenized_texts.append(b_input_ids)\n",
        "            true_labels.append(b_labels)\n",
        "            pred_labels.append(pred_label)\n",
        "\n",
        "    # Flatten outputs\n",
        "    pred_labels = np.vstack(pred_labels)\n",
        "    true_labels = np.vstack(true_labels)\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    return  pred_labels, true_labels, avg_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          22
        ],
        "id": "mZgRlyk0rcMx"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_labels, train_dataloader, validation_dataloader, model_path,\\\n",
        "                             optimizer=None, scheduler=None, epochs = 10, \\\n",
        "                             class_weight = None, patience = 5):\n",
        "\n",
        "    seed_val = 42\n",
        "\n",
        "    threshold = 0.5\n",
        "    #model_path = 'best_model.model'  # save the best model\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    training_stats = []\n",
        "\n",
        "    best_score = -0.5\n",
        "    best_epoch = 0\n",
        "    cnt = 0\n",
        "\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    if optimizer == None:\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "\n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        #print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            \n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: (cik, fyear, fyear_bf)\n",
        "            #   [1]: labels\n",
        "            \n",
        "            print('1 free gpu',get_free_gpu())\n",
        "            b_input_key = batch[0]\n",
        "            b_labels = batch[1].to(device)\n",
        "            \n",
        "            \n",
        "            #convert key to text embedding\n",
        "            tk_batch = []\n",
        "            tk_batch_bf = []\n",
        "            print('b_input_key',b_input_key)\n",
        "            for t in b_input_key.detach().to('cpu').numpy():\n",
        "                tk, tk_bf = get_text_embedding(t[0], t[1], t[2], tokenizer, bert_model, para_len, wrd_len=100)\n",
        "                if tk.size()[0] == 60:              \n",
        "                    tk_batch.append(tk)\n",
        "                    tk_batch_bf.append(tk_bf)\n",
        "                else:\n",
        "                    print('token size error')\n",
        "                    break\n",
        "                \n",
        "            tk_batch = torch.stack(tk_batch)\n",
        "            tk_batch = tk_batch.to(device)\n",
        "            \n",
        "            tk_batch_bf = torch.stack(tk_batch_bf)\n",
        "            tk_batch_bf = tk_batch_bf.to(device)\n",
        "            print('2 free gpu',get_free_gpu())\n",
        "            model.zero_grad()\n",
        "\n",
        "            logits = model(tk_batch,tk_batch_bf)\n",
        "            #print(\"logits shape: \", b_input_ids.size(), b_labels.size(), logits.shape())\n",
        "            #loss_func = BCELoss()\n",
        "            #loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "\n",
        "            # add class weight\n",
        "            if class_weight != None:\n",
        "                pos_weight = torch.tensor(class_weight).to(device)\n",
        "                loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "            else:\n",
        "                loss_func = BCEWithLogitsLoss()\n",
        "                \n",
        "            global X \n",
        "            global Y \n",
        "            global Z\n",
        "            X = logits\n",
        "            Y = b_labels\n",
        "            \n",
        "            tk_batch.detach().to('cpu')\n",
        "            del tk_batch\n",
        "            tk_batch_bf.detach().to('cpu')\n",
        "            del tk_batch_bf\n",
        "            \n",
        "            print('3 free gpu',get_free_gpu())\n",
        "            print(logits.size(), b_labels.size())\n",
        "#             loss = loss_func(\n",
        "#                 logits.view(-1, num_labels),\n",
        "#                 b_labels.type_as(logits).view(\n",
        "#                     -1, num_labels))  \n",
        "            # convert labels to float for calculation\n",
        "            loss = loss_func(logits, b_labels.type_as(logits))\n",
        "            \n",
        "            Z = loss\n",
        "        \n",
        "        \n",
        "\n",
        "        \n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            if scheduler != None:\n",
        "                scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "        # Measure how long this epoch took.\n",
        "        #training_time = format_time(time.time() - t0)\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        #print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        #print(\"\")\n",
        "        #print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        pred_labels, true_labels, avg_val_loss = model_eval(\n",
        "            model,  validation_dataloader, num_labels, class_weight=class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis=1)\n",
        "        true_bools = np.argmax(true_labels, axis=1)\n",
        "\n",
        "        val_f1 = f1_score(true_bools, pred_bools, average=None) * 100\n",
        "        val_f1 = val_f1[1]  # return f1 for  class 1\n",
        "        val_acc = (\n",
        "            pred_bools == true_bools).astype(int).sum() / len(pred_bools)\n",
        "\n",
        "        #print('Validation Accuracy: {0:.4f}, F1: {1:.4f}, Loss: {2:.4f}'.format(val_f1, val_acc, avg_val_loss))\n",
        "        #print(classification_report(np.array(true_labels), pred_bools, target_names=label_cols) )\n",
        "        print(\"Epoch {0}\\t Train Loss: {1:.4f}\\t Val Loss {2:.4f}\\t Val Acc: {3:.4f}\\t Val F1: {4:.4f}\".\\\n",
        "          format(epoch_i +1, avg_train_loss, avg_val_loss, val_acc, val_f1))\n",
        "\n",
        "        # Measure how long the validation run took.\n",
        "        #validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        #print(\"  Validation Loss: {0:.2f}\".format(val_f1_accuracy))\n",
        "        #print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append({\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': val_f1,\n",
        "            'Best F1': best_score,\n",
        "            'Best epoch': best_epoch\n",
        "            #'Training Time': training_time,\n",
        "            #'Validation Time': validation_time\n",
        "        })\n",
        "\n",
        "        # early stopping\n",
        "        if val_f1 > best_score:\n",
        "            best_score = val_f1\n",
        "            best_epoch = epoch_i + 1\n",
        "            torch.save(copy.deepcopy(model.state_dict()), model_path)\n",
        "            print(\"model saved\")\n",
        "            cnt = 0\n",
        "        else:\n",
        "            cnt += 1\n",
        "            if cnt == patience:\n",
        "                print(\"\\n\")\n",
        "                print(\"early stopping at epoch {0}\".format(epoch_i + 1))\n",
        "\n",
        "                break\n",
        "\n",
        "    print(\"\")\n",
        "    #print(\"Training complete!\")\n",
        "\n",
        "    #print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "    \n",
        "    return model, training_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duo5hnu52yb6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYW7A8QX24zS"
      },
      "source": [
        "# training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9OJkmYr92EM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaKAEjlQ2yei"
      },
      "outputs": [],
      "source": [
        "emb_dim = 768\n",
        "wrd_len = 100\n",
        "para_len = 60\n",
        "num_filters = 128\n",
        "kernel_sizes =  (10,50)\n",
        "kernel_sizes2 =  (2,2)\n",
        "dropout_rate = 0.3\n",
        "num_classes=2.0\n",
        "batch_size = 8\n",
        "para_map = para_map\n",
        "class_weight = 10\n",
        "\n",
        "result = []\n",
        "label_cols = ['fraud']\n",
        "\n",
        "df = pos_neg_pair.copy()\n",
        "# create traning dataset only to test the code\n",
        "df = pos_neg_pair.iloc[0:32,:]\n",
        "df.loc[1,'fraud'] = 1\n",
        "df.loc[30,'fraud'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsem3rPa-gi9",
        "outputId": "cb92a077-ad63-49a1-a85d-5b0d77f0b1b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 429\n",
            "used     : 5714\n"
          ]
        }
      ],
      "source": [
        "get_free_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYkIEuao-gi-"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3cqKzHf-gi-",
        "outputId": "f25e1f2c-f209-4c6a-91f4-f4bdfbb42f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 3034\n",
            "used     : 3109\n"
          ]
        }
      ],
      "source": [
        "get_free_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "385FOhD_-gi-"
      },
      "outputs": [],
      "source": [
        "X = None\n",
        "Y = None\n",
        "Z = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9UibyBe--gi-",
        "outputId": "f5d4e93b-f9a8-40d4-fded-702a19757724"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>fyear</th>\n",
              "      <th>count_para</th>\n",
              "      <th>fraud</th>\n",
              "      <th>fyear_bf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>1996</td>\n",
              "      <td>31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1995.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>1997</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1996.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>1998</td>\n",
              "      <td>49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>1999</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>2000</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1999.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20</td>\n",
              "      <td>2001</td>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20</td>\n",
              "      <td>2002</td>\n",
              "      <td>52</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2001.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20</td>\n",
              "      <td>2003</td>\n",
              "      <td>61</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20</td>\n",
              "      <td>2004</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20</td>\n",
              "      <td>2005</td>\n",
              "      <td>71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2004.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20</td>\n",
              "      <td>2006</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2005.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20</td>\n",
              "      <td>2007</td>\n",
              "      <td>79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20</td>\n",
              "      <td>2008</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20</td>\n",
              "      <td>2009</td>\n",
              "      <td>78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2008.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1750</td>\n",
              "      <td>1995</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1750</td>\n",
              "      <td>1996</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1995.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1750</td>\n",
              "      <td>1997</td>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1996.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1750</td>\n",
              "      <td>1998</td>\n",
              "      <td>28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1750</td>\n",
              "      <td>1999</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1750</td>\n",
              "      <td>2000</td>\n",
              "      <td>36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1999.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1750</td>\n",
              "      <td>2001</td>\n",
              "      <td>44</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1750</td>\n",
              "      <td>2002</td>\n",
              "      <td>55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2001.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1750</td>\n",
              "      <td>2003</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2002.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1750</td>\n",
              "      <td>2004</td>\n",
              "      <td>49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2003.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1750</td>\n",
              "      <td>2005</td>\n",
              "      <td>175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2004.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1750</td>\n",
              "      <td>2006</td>\n",
              "      <td>59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2005.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1750</td>\n",
              "      <td>2007</td>\n",
              "      <td>60</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2006.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1750</td>\n",
              "      <td>2008</td>\n",
              "      <td>67</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2007.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1750</td>\n",
              "      <td>2009</td>\n",
              "      <td>65</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2008.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1750</td>\n",
              "      <td>2010</td>\n",
              "      <td>57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2009.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011</td>\n",
              "      <td>76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1750</td>\n",
              "      <td>2012</td>\n",
              "      <td>61</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     cik  fyear  count_para  fraud  fyear_bf\n",
              "1     20   1996          31    1.0    1995.0\n",
              "2     20   1997          34    0.0    1996.0\n",
              "3     20   1998          49    0.0    1997.0\n",
              "4     20   1999          40    0.0    1998.0\n",
              "5     20   2000          34    0.0    1999.0\n",
              "6     20   2001          38    0.0    2000.0\n",
              "7     20   2002          52    0.0    2001.0\n",
              "8     20   2003          61    0.0    2002.0\n",
              "9     20   2004          80    0.0    2003.0\n",
              "10    20   2005          71    0.0    2004.0\n",
              "11    20   2006          75    0.0    2005.0\n",
              "12    20   2007          79    0.0    2006.0\n",
              "13    20   2008          81    0.0    2007.0\n",
              "14    20   2009          78    0.0    2008.0\n",
              "16  1750   1995          23    0.0    1994.0\n",
              "17  1750   1996          25    0.0    1995.0\n",
              "18  1750   1997          28    0.0    1996.0\n",
              "19  1750   1998          28    0.0    1997.0\n",
              "20  1750   1999          25    0.0    1998.0\n",
              "21  1750   2000          36    0.0    1999.0\n",
              "22  1750   2001          44    0.0    2000.0\n",
              "23  1750   2002          55    0.0    2001.0\n",
              "24  1750   2003          50    0.0    2002.0\n",
              "25  1750   2004          49    0.0    2003.0\n",
              "26  1750   2005         175    0.0    2004.0\n",
              "27  1750   2006          59    0.0    2005.0\n",
              "28  1750   2007          60    0.0    2006.0\n",
              "29  1750   2008          67    0.0    2007.0\n",
              "30  1750   2009          65    1.0    2008.0\n",
              "31  1750   2010          57    0.0    2009.0\n",
              "32  1750   2011          76    0.0    2010.0\n",
              "33  1750   2012          61    0.0    2011.0"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PaWyXYU-gi-",
        "outputId": "49918270-02e9-407f-bf15-463e51cad153"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32, 5)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJd5o_nUBbuR",
        "outputId": "03edeb6a-8b34-40d6-8a31-c339319b7483",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------\n",
            "fraud\n",
            "------------\n",
            "\n",
            "fold 0 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "simple_siamese(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(768, 256, kernel_size=(10, 50), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): ReLU()\n",
              "  )\n",
              "  (fc): Linear(in_features=1152, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 2665\n",
            "used     : 3478\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 1996., 1995.],\n",
            "        [  20., 2005., 2004.],\n",
            "        [  20., 2008., 2007.],\n",
            "        [1750., 2002., 2001.],\n",
            "        [  20., 2002., 2001.],\n",
            "        [1750., 2003., 2002.],\n",
            "        [1750., 1996., 1995.],\n",
            "        [  20., 2006., 2005.]], dtype=torch.float64)\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 1264\n",
            "used     : 4879\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 360\n",
            "used     : 5783\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 163\n",
            "used     : 5980\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 1998., 1997.],\n",
            "        [1750., 1997., 1996.],\n",
            "        [1750., 2004., 2003.],\n",
            "        [1750., 2012., 2011.],\n",
            "        [1750., 2011., 2010.],\n",
            "        [1750., 2007., 2006.],\n",
            "        [  20., 2001., 2000.],\n",
            "        [  20., 2003., 2002.]], dtype=torch.float64)\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 62\n",
            "used     : 6081\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 38\n",
            "used     : 6105\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 38\n",
            "used     : 6105\n",
            "val 1 free gpu None\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 41\n",
            "used     : 6102\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 49\n",
            "used     : 6094\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 49\n",
            "used     : 6094\n",
            "val 1 free gpu None\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 30\n",
            "used     : 6113\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 25\n",
            "used     : 6118\n",
            "val 3 free gpu None\n",
            "Epoch 1\t Train Loss: 15.2675\t Val Loss 40.8636\t Val Acc: 0.3125\t Val F1: 15.3846\n",
            "model saved\n",
            "total    : 6144\n",
            "free     : 19\n",
            "used     : 6124\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2003., 2002.],\n",
            "        [1750., 2003., 2002.],\n",
            "        [  20., 1996., 1995.],\n",
            "        [  20., 2001., 2000.],\n",
            "        [  20., 2006., 2005.],\n",
            "        [1750., 2011., 2010.],\n",
            "        [  20., 2002., 2001.],\n",
            "        [1750., 2012., 2011.]], dtype=torch.float64)\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 25\n",
            "used     : 6118\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 25\n",
            "used     : 6118\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 2004., 2003.],\n",
            "        [1750., 2007., 2006.],\n",
            "        [  20., 1998., 1997.],\n",
            "        [  20., 2005., 2004.],\n",
            "        [1750., 1996., 1995.],\n",
            "        [1750., 1997., 1996.],\n",
            "        [1750., 2002., 2001.],\n",
            "        [  20., 2008., 2007.]], dtype=torch.float64)\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 19\n",
            "used     : 6124\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 20\n",
            "used     : 6123\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 20\n",
            "used     : 6123\n",
            "val 1 free gpu None\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 1 free gpu None\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 3 free gpu None\n",
            "Epoch 2\t Train Loss: 18.7301\t Val Loss 68.3539\t Val Acc: 0.3125\t Val F1: 15.3846\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 1998., 1997.],\n",
            "        [1750., 2004., 2003.],\n",
            "        [  20., 2006., 2005.],\n",
            "        [  20., 2002., 2001.],\n",
            "        [  20., 2008., 2007.],\n",
            "        [  20., 2005., 2004.],\n",
            "        [1750., 2007., 2006.],\n",
            "        [1750., 1996., 1995.]], dtype=torch.float64)\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 22\n",
            "used     : 6121\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 25\n",
            "used     : 6118\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 25\n",
            "used     : 6118\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2001., 2000.],\n",
            "        [1750., 2002., 2001.],\n",
            "        [1750., 2012., 2011.],\n",
            "        [  20., 2003., 2002.],\n",
            "        [  20., 1996., 1995.],\n",
            "        [1750., 1997., 1996.],\n",
            "        [1750., 2011., 2010.],\n",
            "        [1750., 2003., 2002.]], dtype=torch.float64)\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "val 1 free gpu None\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 26\n",
            "used     : 6117\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 26\n",
            "used     : 6117\n",
            "val 1 free gpu None\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 26\n",
            "used     : 6117\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 26\n",
            "used     : 6117\n",
            "val 3 free gpu None\n",
            "Epoch 3\t Train Loss: 0.7494\t Val Loss 94.4549\t Val Acc: 0.2500\t Val F1: 14.2857\n",
            "total    : 6144\n",
            "free     : 26\n",
            "used     : 6117\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2003., 2002.],\n",
            "        [1750., 2011., 2010.],\n",
            "        [  20., 2008., 2007.],\n",
            "        [1750., 1997., 1996.],\n",
            "        [  20., 2005., 2004.],\n",
            "        [1750., 2004., 2003.],\n",
            "        [  20., 2001., 2000.],\n",
            "        [1750., 1996., 1995.]], dtype=torch.float64)\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 35\n",
            "used     : 6108\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 19\n",
            "used     : 6124\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 19\n",
            "used     : 6124\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2006., 2005.],\n",
            "        [  20., 1998., 1997.],\n",
            "        [1750., 2007., 2006.],\n",
            "        [  20., 1996., 1995.],\n",
            "        [1750., 2012., 2011.],\n",
            "        [1750., 2002., 2001.],\n",
            "        [1750., 2003., 2002.],\n",
            "        [  20., 2002., 2001.]], dtype=torch.float64)\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 1 free gpu None\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "val 1 free gpu None\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "val 3 free gpu None\n",
            "Epoch 4\t Train Loss: 3.1860\t Val Loss 112.6132\t Val Acc: 0.2500\t Val F1: 14.2857\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 1997., 1996.],\n",
            "        [1750., 2003., 2002.],\n",
            "        [  20., 1996., 1995.],\n",
            "        [  20., 2003., 2002.],\n",
            "        [  20., 2002., 2001.],\n",
            "        [  20., 2001., 2000.],\n",
            "        [1750., 2011., 2010.],\n",
            "        [1750., 2002., 2001.]], dtype=torch.float64)\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 1996., 1995.],\n",
            "        [1750., 2007., 2006.],\n",
            "        [  20., 2006., 2005.],\n",
            "        [1750., 2012., 2011.],\n",
            "        [1750., 2004., 2003.],\n",
            "        [  20., 2008., 2007.],\n",
            "        [  20., 2005., 2004.],\n",
            "        [  20., 1998., 1997.]], dtype=torch.float64)\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "val 1 free gpu None\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 24\n",
            "used     : 6119\n",
            "val 1 free gpu None\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 36\n",
            "used     : 6107\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 36\n",
            "used     : 6107\n",
            "val 3 free gpu None\n",
            "Epoch 5\t Train Loss: 1.6666\t Val Loss 136.5096\t Val Acc: 0.3125\t Val F1: 15.3846\n",
            "total    : 6144\n",
            "free     : 36\n",
            "used     : 6107\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2001., 2000.],\n",
            "        [  20., 2005., 2004.],\n",
            "        [  20., 1998., 1997.],\n",
            "        [  20., 2008., 2007.],\n",
            "        [  20., 2002., 2001.],\n",
            "        [1750., 2011., 2010.],\n",
            "        [1750., 2004., 2003.],\n",
            "        [1750., 2007., 2006.]], dtype=torch.float64)\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 36\n",
            "used     : 6107\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 36\n",
            "used     : 6107\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 36\n",
            "used     : 6107\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 2003., 2002.],\n",
            "        [1750., 1997., 1996.],\n",
            "        [  20., 1996., 1995.],\n",
            "        [  20., 2006., 2005.],\n",
            "        [  20., 2003., 2002.],\n",
            "        [1750., 2012., 2011.],\n",
            "        [1750., 2002., 2001.],\n",
            "        [1750., 1996., 1995.]], dtype=torch.float64)\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 1 free gpu None\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "val 1 free gpu None\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 15\n",
            "used     : 6128\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 14\n",
            "used     : 6129\n",
            "val 3 free gpu None\n",
            "Epoch 6\t Train Loss: 0.0105\t Val Loss 152.6915\t Val Acc: 0.3125\t Val F1: 15.3846\n",
            "\n",
            "\n",
            "early stopping at epoch 6\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "simple_siamese(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(768, 256, kernel_size=(10, 50), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): ReLU()\n",
              "  )\n",
              "  (fc): Linear(in_features=1152, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 16\n",
            "used     : 6127\n",
            "val 1 free gpu None\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 15\n",
            "used     : 6128\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "val 1 free gpu None\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 35\n",
            "used     : 6108\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 35\n",
            "used     : 6108\n",
            "val 3 free gpu None\n",
            "Precision: 0.0833, Recall: 1.0000, F1: 0.1538, Loss: 40.8636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.27      0.42        15\n",
            "           1       0.08      1.00      0.15         1\n",
            "\n",
            "    accuracy                           0.31        16\n",
            "   macro avg       0.54      0.63      0.29        16\n",
            "weighted avg       0.94      0.31      0.40        16\n",
            "\n",
            "total    : 6144\n",
            "free     : 3639\n",
            "used     : 2504\n",
            "\n",
            "fold 1 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "simple_siamese(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(768, 256, kernel_size=(10, 50), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): ReLU()\n",
              "  )\n",
              "  (fc): Linear(in_features=1152, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 3245\n",
            "used     : 2898\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 1997., 1996.],\n",
            "        [  20., 2009., 2008.],\n",
            "        [1750., 1998., 1997.],\n",
            "        [1750., 2001., 2000.],\n",
            "        [  20., 2004., 2003.],\n",
            "        [1750., 2005., 2004.],\n",
            "        [1750., 1999., 1998.],\n",
            "        [1750., 1995., 1994.]], dtype=torch.float64)\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 886\n",
            "used     : 5257\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 23\n",
            "used     : 6120\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 1083\n",
            "used     : 5060\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 1999., 1998.],\n",
            "        [1750., 2000., 1999.],\n",
            "        [1750., 2006., 2005.],\n",
            "        [1750., 2010., 2009.],\n",
            "        [1750., 2009., 2008.],\n",
            "        [1750., 2008., 2007.],\n",
            "        [  20., 2000., 1999.],\n",
            "        [  20., 2007., 2006.]], dtype=torch.float64)\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 431\n",
            "used     : 5712\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 32\n",
            "used     : 6111\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 30\n",
            "used     : 6113\n",
            "val 1 free gpu None\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "val 1 free gpu None\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 11\n",
            "used     : 6132\n",
            "val 3 free gpu None\n",
            "Epoch 1\t Train Loss: 12.7081\t Val Loss 39.2074\t Val Acc: 0.1875\t Val F1: 13.3333\n",
            "model saved\n",
            "total    : 6144\n",
            "free     : 13\n",
            "used     : 6130\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2007., 2006.],\n",
            "        [1750., 2005., 2004.],\n",
            "        [  20., 1997., 1996.],\n",
            "        [  20., 2000., 1999.],\n",
            "        [1750., 1995., 1994.],\n",
            "        [1750., 2009., 2008.],\n",
            "        [  20., 2004., 2003.],\n",
            "        [1750., 2010., 2009.]], dtype=torch.float64)\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 39\n",
            "used     : 6104\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 40\n",
            "used     : 6103\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 40\n",
            "used     : 6103\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 2006., 2005.],\n",
            "        [1750., 2008., 2007.],\n",
            "        [  20., 1999., 1998.],\n",
            "        [  20., 2009., 2008.],\n",
            "        [1750., 1999., 1998.],\n",
            "        [1750., 2000., 1999.],\n",
            "        [1750., 2001., 2000.],\n",
            "        [1750., 1998., 1997.]], dtype=torch.float64)\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 34\n",
            "used     : 6109\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 34\n",
            "used     : 6109\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 34\n",
            "used     : 6109\n",
            "val 1 free gpu None\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 14\n",
            "used     : 6129\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 15\n",
            "used     : 6128\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 15\n",
            "used     : 6128\n",
            "val 1 free gpu None\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 37\n",
            "used     : 6106\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 37\n",
            "used     : 6106\n",
            "val 3 free gpu None\n",
            "Epoch 2\t Train Loss: 12.7137\t Val Loss 71.9652\t Val Acc: 0.1250\t Val F1: 12.5000\n",
            "total    : 6144\n",
            "free     : 37\n",
            "used     : 6106\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 1999., 1998.],\n",
            "        [1750., 2006., 2005.],\n",
            "        [1750., 1995., 1994.],\n",
            "        [  20., 2004., 2003.],\n",
            "        [1750., 1998., 1997.],\n",
            "        [  20., 2009., 2008.],\n",
            "        [1750., 2008., 2007.],\n",
            "        [1750., 1999., 1998.]], dtype=torch.float64)\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 37\n",
            "used     : 6106\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 37\n",
            "used     : 6106\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 37\n",
            "used     : 6106\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2000., 1999.],\n",
            "        [1750., 2001., 2000.],\n",
            "        [1750., 2010., 2009.],\n",
            "        [  20., 2007., 2006.],\n",
            "        [  20., 1997., 1996.],\n",
            "        [1750., 2000., 1999.],\n",
            "        [1750., 2009., 2008.],\n",
            "        [1750., 2005., 2004.]], dtype=torch.float64)\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 17\n",
            "used     : 6126\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 25\n",
            "used     : 6118\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 25\n",
            "used     : 6118\n",
            "val 1 free gpu None\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 49\n",
            "used     : 6094\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 50\n",
            "used     : 6093\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 50\n",
            "used     : 6093\n",
            "val 1 free gpu None\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 65\n",
            "used     : 6078\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 72\n",
            "used     : 6071\n",
            "val 3 free gpu None\n",
            "Epoch 3\t Train Loss: 2.6749\t Val Loss 100.0625\t Val Acc: 0.1875\t Val F1: 13.3333\n",
            "total    : 6144\n",
            "free     : 72\n",
            "used     : 6071\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2007., 2006.],\n",
            "        [1750., 2009., 2008.],\n",
            "        [1750., 1998., 1997.],\n",
            "        [1750., 2000., 1999.],\n",
            "        [  20., 2009., 2008.],\n",
            "        [1750., 2006., 2005.],\n",
            "        [  20., 2000., 1999.],\n",
            "        [1750., 1999., 1998.]], dtype=torch.float64)\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 37\n",
            "used     : 6106\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 35\n",
            "used     : 6108\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 35\n",
            "used     : 6108\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 1995., 1994.],\n",
            "        [  20., 1999., 1998.],\n",
            "        [1750., 2008., 2007.],\n",
            "        [  20., 1997., 1996.],\n",
            "        [1750., 2010., 2009.],\n",
            "        [1750., 2001., 2000.],\n",
            "        [1750., 2005., 2004.],\n",
            "        [  20., 2004., 2003.]], dtype=torch.float64)\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 46\n",
            "used     : 6097\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 52\n",
            "used     : 6091\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 52\n",
            "used     : 6091\n",
            "val 1 free gpu None\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 40\n",
            "used     : 6103\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 41\n",
            "used     : 6102\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 41\n",
            "used     : 6102\n",
            "val 1 free gpu None\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 42\n",
            "used     : 6101\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "val 3 free gpu None\n",
            "Epoch 4\t Train Loss: 0.9091\t Val Loss 112.6552\t Val Acc: 0.1250\t Val F1: 12.5000\n",
            "total    : 6144\n",
            "free     : 29\n",
            "used     : 6114\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 2000., 1999.],\n",
            "        [1750., 2005., 2004.],\n",
            "        [  20., 1997., 1996.],\n",
            "        [  20., 2007., 2006.],\n",
            "        [  20., 2004., 2003.],\n",
            "        [  20., 2000., 1999.],\n",
            "        [1750., 2009., 2008.],\n",
            "        [1750., 2001., 2000.]], dtype=torch.float64)\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 40\n",
            "used     : 6103\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 38\n",
            "used     : 6105\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 38\n",
            "used     : 6105\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 1999., 1998.],\n",
            "        [1750., 2008., 2007.],\n",
            "        [1750., 1995., 1994.],\n",
            "        [1750., 2010., 2009.],\n",
            "        [1750., 2006., 2005.],\n",
            "        [1750., 1998., 1997.],\n",
            "        [  20., 2009., 2008.],\n",
            "        [  20., 1999., 1998.]], dtype=torch.float64)\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 39\n",
            "used     : 6104\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 38\n",
            "used     : 6105\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 38\n",
            "used     : 6105\n",
            "val 1 free gpu None\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 53\n",
            "used     : 6090\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 59\n",
            "used     : 6084\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 59\n",
            "used     : 6084\n",
            "val 1 free gpu None\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 51\n",
            "used     : 6092\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 72\n",
            "used     : 6071\n",
            "val 3 free gpu None\n",
            "Epoch 5\t Train Loss: 0.5594\t Val Loss 134.2721\t Val Acc: 0.1250\t Val F1: 12.5000\n",
            "total    : 6144\n",
            "free     : 72\n",
            "used     : 6071\n",
            "1 free gpu None\n",
            "b_input_key tensor([[  20., 2000., 1999.],\n",
            "        [  20., 2009., 2008.],\n",
            "        [  20., 1999., 1998.],\n",
            "        [1750., 1998., 1997.],\n",
            "        [  20., 2004., 2003.],\n",
            "        [1750., 2009., 2008.],\n",
            "        [1750., 2006., 2005.],\n",
            "        [1750., 2008., 2007.]], dtype=torch.float64)\n",
            "20.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([40, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([78, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([81, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([40, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([80, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([61, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2009.0 2008.0\n",
            "1 token_embeddings torch.Size([65, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([67, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([59, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([175, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([67, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 45\n",
            "used     : 6098\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 56\n",
            "used     : 6087\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 56\n",
            "used     : 6087\n",
            "1 free gpu None\n",
            "b_input_key tensor([[1750., 2005., 2004.],\n",
            "        [1750., 2000., 1999.],\n",
            "        [  20., 1997., 1996.],\n",
            "        [1750., 1995., 1994.],\n",
            "        [  20., 2007., 2006.],\n",
            "        [1750., 2010., 2009.],\n",
            "        [1750., 2001., 2000.],\n",
            "        [1750., 1999., 1998.]], dtype=torch.float64)\n",
            "1750.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([175, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([49, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2000.0 1999.0\n",
            "1 token_embeddings torch.Size([36, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([34, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([31, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1995.0 1994.0\n",
            "1 token_embeddings torch.Size([23, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([79, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([75, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2010.0 2009.0\n",
            "1 token_embeddings torch.Size([57, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([65, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([44, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([36, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1999.0 1998.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([28, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 56\n",
            "used     : 6087\n",
            "2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 57\n",
            "used     : 6086\n",
            "3 free gpu None\n",
            "torch.Size([8, 2]) torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 57\n",
            "used     : 6086\n",
            "val 1 free gpu None\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 48\n",
            "used     : 6095\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 60\n",
            "used     : 6083\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 60\n",
            "used     : 6083\n",
            "val 1 free gpu None\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 48\n",
            "used     : 6095\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 52\n",
            "used     : 6091\n",
            "val 3 free gpu None\n",
            "Epoch 6\t Train Loss: 0.6860\t Val Loss 146.7159\t Val Acc: 0.1875\t Val F1: 13.3333\n",
            "\n",
            "\n",
            "early stopping at epoch 6\n",
            "\n",
            "load the best model ... \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "simple_siamese(\n",
              "  (conv): Sequential(\n",
              "    (0): Conv2d(768, 256, kernel_size=(10, 50), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): ReLU()\n",
              "  )\n",
              "  (fc): Linear(in_features=1152, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total    : 6144\n",
            "free     : 52\n",
            "used     : 6091\n",
            "val 1 free gpu None\n",
            "1750.0 2011.0 2010.0\n",
            "1 token_embeddings torch.Size([76, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([57, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1998.0 1997.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2012.0 2011.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([76, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([61, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([52, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([31, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([41, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1996.0 1995.0\n",
            "1 token_embeddings torch.Size([25, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([23, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 1997.0 1996.0\n",
            "1 token_embeddings torch.Size([28, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([25, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2007.0 2006.0\n",
            "1 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([59, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 43\n",
            "used     : 6100\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 54\n",
            "used     : 6089\n",
            "val 3 free gpu None\n",
            "total    : 6144\n",
            "free     : 54\n",
            "used     : 6089\n",
            "val 1 free gpu None\n",
            "1750.0 2003.0 2002.0\n",
            "1 token_embeddings torch.Size([50, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([55, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2004.0 2003.0\n",
            "1 token_embeddings torch.Size([49, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([50, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([52, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([38, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2008.0 2007.0\n",
            "1 token_embeddings torch.Size([81, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([79, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2001.0 2000.0\n",
            "1 token_embeddings torch.Size([38, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([34, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2005.0 2004.0\n",
            "1 token_embeddings torch.Size([71, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([80, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "1750.0 2002.0 2001.0\n",
            "1 token_embeddings torch.Size([55, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([44, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "20.0 2006.0 2005.0\n",
            "1 token_embeddings torch.Size([75, 100, 768])\n",
            "2 token_embeddings torch.Size([60, 100, 768])\n",
            "1 token_embeddings_bf torch.Size([71, 100, 768])\n",
            "2 token_embeddings_bf torch.Size([60, 100, 768])\n",
            "total    : 6144\n",
            "free     : 44\n",
            "used     : 6099\n",
            "val 2 free gpu None\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 768, 60, 100])\n",
            "torch.Size([8, 128, 3, 3])\n",
            "torch.Size([8, 1152])\n",
            "model output torch.Size([8, 2])\n",
            "total    : 6144\n",
            "free     : 46\n",
            "used     : 6097\n",
            "val 3 free gpu None\n",
            "Precision: 0.0714, Recall: 1.0000, F1: 0.1333, Loss: 39.2074\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.13      0.24        15\n",
            "           1       0.07      1.00      0.13         1\n",
            "\n",
            "    accuracy                           0.19        16\n",
            "   macro avg       0.54      0.57      0.18        16\n",
            "weighted avg       0.94      0.19      0.23        16\n",
            "\n",
            "total    : 6144\n",
            "free     : 2746\n",
            "used     : 3397\n"
          ]
        }
      ],
      "source": [
        "for col in label_cols:\n",
        "    print(\"\\n------------\")\n",
        "    print(col)\n",
        "    print(\"------------\")\n",
        "\n",
        "    y = df[col].astype(int).values\n",
        "    x_key = df[['cik', 'fyear', 'fyear_bf']].values\n",
        "\n",
        "    fold = 0\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=2, random_state=0, shuffle=True)\n",
        "\n",
        "    for train_index, test_index in skf.split(x_key, y):\n",
        "\n",
        "        print(\"\\nfold {} \\n\".format(fold))\n",
        "\n",
        "        fold += 1\n",
        "        X_train, X_test = x_key[train_index], x_key[test_index]\n",
        "        X_train = torch.tensor(X_train)\n",
        "        X_test = torch.tensor(X_test)\n",
        "\n",
        "        Y_train, Y_test = y[train_index], y[test_index]\n",
        "\n",
        "        Y_train = pd.get_dummies(Y_train).values\n",
        "        Y_train = torch.tensor(Y_train)\n",
        "\n",
        "        Y_test = pd.get_dummies(Y_test).values\n",
        "        Y_test = torch.tensor(Y_test)\n",
        "\n",
        "        train_dataset = TensorDataset(X_train, Y_train)\n",
        "        val_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "        train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
        "            batch_size=batch_size  # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "        validation_dataloader = DataLoader(\n",
        "            val_dataset,  # The validation samples.\n",
        "            sampler=RandomSampler(\n",
        "                val_dataset),  # Pull out batches sequentially.\n",
        "            batch_size=batch_size  # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "        if class_weight == None:\n",
        "            pass\n",
        "        else:\n",
        "            train_sample_weight = np.array(\n",
        "                [class_weight if i[1] == 1 else 1 for i in Y_train])\n",
        "            test_sample_weight = np.array(\n",
        "                [class_weight if i[1] == 1 else 1 for i in Y_test])\n",
        "\n",
        "        model_name = \"./model/simple_siamese_\" + str(fold)\n",
        "        #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
        "        model = simple_siamese(emb_dim, wrd_len, num_filters, kernel_sizes,\\\n",
        "                               kernel_sizes2, num_classes=num_classes, dropout_rate = dropout_rate)\n",
        "        model.to(device)\n",
        "\n",
        "\n",
        "        model, training_stats = train_model(model, num_classes, train_dataloader, validation_dataloader, \\\n",
        "                                                        model_path = model_name, class_weight = class_weight,\\\n",
        "                                                        optimizer=None, scheduler=None, epochs = 20)\n",
        "\n",
        "        print(\"load the best model ... \")\n",
        "\n",
        "        model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "        # show performance of best model\n",
        "        model.eval()\n",
        "        pred_labels, true_labels,avg_val_loss = model_eval(model, \\\n",
        "                                                validation_dataloader, num_classes, class_weight = class_weight)\n",
        "\n",
        "        pred_bools = np.argmax(pred_labels, axis = 1)\n",
        "        true_bools = np.argmax(true_labels, axis = 1)\n",
        "\n",
        "        p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
        "        #val_f1 = f1_score(true_bools,pred_bools, average = None)*100\n",
        "        #val_f1 = val_f1[1] # return f1 for  class 1\n",
        "        val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
        "\n",
        "        print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}'.format(p[1], r[1], f[1], avg_val_loss))\n",
        "        print(classification_report(true_bools, pred_bools) )\n",
        "\n",
        "\n",
        "        result.append([col, fold, p[1], r[1], f[1], training_stats[-1][\"Best epoch\"]])\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        get_free_gpu()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dufU1Axr2s0d",
        "outputId": "9242987c-bbef-4210-9fc1-c1e0952112ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['fraud', 1, 0.08333333333333333, 1.0, 0.15384615384615385, 1],\n",
              " ['fraud', 2, 0.07142857142857142, 1.0, 0.13333333333333333, 1]]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxwPwb852s3Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "313.054px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}