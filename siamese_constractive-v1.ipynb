{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import sys, os\n",
    "cur_path = os.path.join('/research/jujun/text_change')\n",
    "os.chdir(cur_path)\n",
    "\n",
    "import random, pickle\n",
    "import numpy as np\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss, MSELoss\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, \\\n",
    "                                f1_score, accuracy_score, precision_recall_fscore_support\n",
    "# import tensorflow as tf\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from numba import cuda \n",
    "\n",
    "# from pynvml import *\n",
    "def get_free_gpu():\n",
    "    print('\\n')\n",
    "    # nvmlInit()\n",
    "    # h = nvmlDeviceGetHandleByIndex(0)\n",
    "    # info = nvmlDeviceGetMemoryInfo(h)\n",
    "    # print(f'total    : {info.total // 1024 ** 2}')\n",
    "    # print(f'free     : {info.free// 1024 ** 2}')\n",
    "    # print(f'used     : {info.used// 1024 ** 2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_wordvector(sentences, tokenizer, bert_model, max_len=100):\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    max_len = max_len\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        #padding='max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    bert_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids.to(device), attention_masks.to(device))   \n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    \n",
    "    # get the last four layers\n",
    "    token_embeddings = torch.stack(hidden_states[-4:], dim=0) \n",
    "    #print(token_embeddings.size())\n",
    "\n",
    "    # permute axis\n",
    "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
    "    #print(token_embeddings.size())\n",
    "\n",
    "    # take the mean of the last 4 layers\n",
    "    token_embeddings = token_embeddings.mean(axis=2)\n",
    "\n",
    "    #print(token_embeddings.size())\n",
    "    input_ids.detach().to('cpu')\n",
    "    attention_masks.detach().to('cpu')\n",
    "    token_embeddings.detach().to('cpu')\n",
    "    del input_ids\n",
    "    return token_embeddings, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(cik, fyear, fyear_bf, tokenizer, bert_model, para_map, para_len, wrd_len=100):\n",
    "    # print(cik, fyear, fyear_bf)\n",
    "    df = pd.concat({k: pd.Series(v) for k, v in para_map[cik].items()})\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['fyear','pid','text']\n",
    "\n",
    "    input = df[df.fyear == fyear].text.values\n",
    "    input_bf = df[df.fyear == fyear_bf].text.values\n",
    "\n",
    "    #get embedding for input\n",
    "    token_embeddings, masks = get_pretrained_wordvector(input, tokenizer, bert_model, max_len = wrd_len)\n",
    "    token_embeddings = token_embeddings.to(device) * masks.unsqueeze(-1).to(device) # (atc_num_para, #wrd_len, #dim)\n",
    "    # padding paragraphs\n",
    "    # print('1 token_embeddings',token_embeddings.size())\n",
    "    pad_num = para_len - token_embeddings.size()[0]\n",
    "    if pad_num>0:\n",
    "        token_embeddings = F.pad(input=token_embeddings, pad=(0,0,0,0,0,pad_num))\n",
    "        # print('2 token_embeddings',token_embeddings.size())\n",
    "    elif pad_num<0:\n",
    "        token_embeddings = token_embeddings[0:para_len]\n",
    "        # print('2 token_embeddings',token_embeddings.size())\n",
    "    else:\n",
    "        token_embeddings = token_embeddings\n",
    "\n",
    "    #get embedding for input_bf\n",
    "    token_embeddings_bf, masks_bf = get_pretrained_wordvector(input_bf, tokenizer, bert_model, max_len = wrd_len)\n",
    "    token_embeddings_bf = token_embeddings_bf.to(device) * masks_bf.unsqueeze(-1).to(device) # (atc_num_para, #wrd_len, #dim)\n",
    "    # padding paragraphs\n",
    "    # print('1 token_embeddings_bf',token_embeddings_bf.size())\n",
    "    pad_num_bf = para_len - token_embeddings_bf.size()[0]\n",
    "    #print('pad_num_bf', pad_num_bf)\n",
    "    if pad_num_bf>0:\n",
    "        # print('>0')\n",
    "        token_embeddings_bf = F.pad(input=token_embeddings_bf, pad=(0,0,0,0,0,pad_num_bf))\n",
    "        # print('2 token_embeddings_bf',token_embeddings_bf.size())\n",
    "    elif pad_num_bf<0:\n",
    "        # print('<0')\n",
    "        token_embeddings_bf = token_embeddings_bf[0:para_len]\n",
    "        # print('2 token_embeddings_bf',token_embeddings_bf.size())\n",
    "    else:\n",
    "        token_embeddings_bf = token_embeddings_bf\n",
    "\n",
    "    return token_embeddings, token_embeddings_bf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "class simple_siamese(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.wrd_len = config.wrd_len\n",
    "        self.num_filters = config.num_filters\n",
    "        self.kernel_sizes = config.kernel_sizes\n",
    "        self.kernel_sizes2 = config.kernel_sizes2\n",
    "        self.kernel_sizes3 = config.kernel_sizes3\n",
    "        self.dropout_rate = config.dropout_rate\n",
    "        self.num_classes = config.num_classes\n",
    "        self.test_mode = config.test_mode\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(768, 128, kernel_size = self.kernel_sizes), # input (#batch, 768, num_para->30, num_words->50) # kernal size = 10  # output: (#batch, 128, 30, 40)\n",
    "            nn.Conv2d(128, 64,  kernel_size = self.kernel_sizes2), # input (#batch, 768, num_para->30, num_words->50) # kernal size = 10  # output: (#batch, 128, 30, 40)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((1,3), padding=0),  # input (#batch, 128, 30, 40) #output (#batch, 128, 30, 13)\n",
    "            # nn.MaxPool1d(3, padding=0),  # input (#batch, 128, 30, 40) #output (#batch, 128, 30, 13)\n",
    "            # nn.Conv2d(128, 64,  kernel_size = kernel_sizes2), # input (#batch, 256, num_para->10, num_words->10) # kernal size = 5\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.MaxPool2d((1,1), padding=0),\n",
    "            # nn.ReLU(), \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32,  kernel_size = self.kernel_sizes2), # input (#batch, 768, num_para->30, num_words->50) # kernal size = 10  # output: (#batch, 128, 30, 40)\n",
    "            nn.Conv2d(32, 16,  kernel_size = self.kernel_sizes3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2,2), padding=0),\n",
    "        )\n",
    "\n",
    "        \n",
    "        linear_size = 64\n",
    "        self.fc1 = nn.Linear(2112, linear_size)\n",
    "        self.fc2 = nn.Linear(linear_size, int(self.num_classes))\n",
    "        self.norl = nn.BatchNorm1d(linear_size)\n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "        \n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        #permute input to make it fit cnn\n",
    "        x1 = torch.permute(input1, (0,3,1,2))\n",
    "        x2 = torch.permute(input2, (0,3,1,2))\n",
    "        # print(x1.size())\n",
    "        # print(x2.size())\n",
    "\n",
    "        x1 = self.conv1(x1)\n",
    "        x2 = self.conv1(x2)\n",
    "        if self.test_mode:\n",
    "            print('---conv1 output---')\n",
    "            print(x1.size())\n",
    "            print(x2.size())\n",
    "        # absolute distance    \n",
    "        # x = torch.abs(torch.sub(x1,x2))\n",
    "        # euclidean distance\n",
    "        x = torch.cdist(x1, x2, p=2)\n",
    "\n",
    "        \n",
    "        # print(x.size())\n",
    "        x = self.conv2(x)\n",
    "        if self.test_mode:\n",
    "            print('---conv2 output---')\n",
    "            print(x.size())\n",
    "        \n",
    "        x = torch.reshape(x,(x.size()[0],-1))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        # x = self.norl(x)\n",
    "        logit = self.fc2(x)\n",
    "        # print('model output',logit.size())\n",
    "\n",
    "        x1 = torch.reshape(x1,(x1.size()[0],-1))\n",
    "        x2 = torch.reshape(x2,(x2.size()[0],-1))\n",
    "\n",
    "        return logit, x1, x2   \n",
    "        # return x1, x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global __pred_probs\n",
    "global __labels_bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1080 Ti\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "simple_siamese                           [64, 2]                   128\n",
       "├─Sequential: 1-1                        [64, 64, 28, 17]          --\n",
       "│    └─Conv2d: 2-1                       [64, 128, 32, 55]         983,168\n",
       "│    └─Conv2d: 2-2                       [64, 64, 28, 53]          122,944\n",
       "│    └─ReLU: 2-3                         [64, 64, 28, 53]          --\n",
       "│    └─MaxPool2d: 2-4                    [64, 64, 28, 17]          --\n",
       "├─Sequential: 1-2                        [64, 64, 28, 17]          (recursive)\n",
       "│    └─Conv2d: 2-5                       [64, 128, 32, 55]         (recursive)\n",
       "│    └─Conv2d: 2-6                       [64, 64, 28, 53]          (recursive)\n",
       "│    └─ReLU: 2-7                         [64, 64, 28, 53]          --\n",
       "│    └─MaxPool2d: 2-8                    [64, 64, 28, 17]          --\n",
       "├─Sequential: 1-3                        [64, 16, 11, 12]          --\n",
       "│    └─Conv2d: 2-9                       [64, 32, 24, 26]          30,752\n",
       "│    └─Conv2d: 2-10                      [64, 16, 22, 24]          4,624\n",
       "│    └─ReLU: 2-11                        [64, 16, 22, 24]          --\n",
       "│    └─MaxPool2d: 2-12                   [64, 16, 11, 12]          --\n",
       "├─Dropout: 1-4                           [64, 2112]                --\n",
       "├─Linear: 1-5                            [64, 64]                  135,232\n",
       "├─Dropout: 1-6                           [64, 64]                  --\n",
       "├─Linear: 1-7                            [64, 2]                   130\n",
       "==========================================================================================\n",
       "Total params: 1,276,978\n",
       "Trainable params: 1,276,978\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 246.23\n",
       "==========================================================================================\n",
       "Input size (MB): 805.31\n",
       "Forward/backward pass size (MB): 178.55\n",
       "Params size (MB): 5.11\n",
       "Estimated Total Size (MB): 988.97\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class config:\n",
    "    def __init__(self):\n",
    "        self.emb_dim = 768\n",
    "        self.wrd_len = 64  # 100\n",
    "        self.para_len = 32  # 60\n",
    "        self.num_filters = 128\n",
    "        self.kernel_sizes = (1, 10)\n",
    "        self.kernel_sizes2 = (5, 3)  # (2,2)\n",
    "        self.kernel_sizes3 = (3, 3)\n",
    "        self.dropout_rate = 0.2\n",
    "        self.num_classes = 2.0\n",
    "        self.num_labels = 2\n",
    "        self.batch_size = 64\n",
    "        self.para_map = None\n",
    "        self.class_weight = 1\n",
    "        self.test_mode = False\n",
    "\n",
    "    def set_parm_map(self, para_map):\n",
    "        self.para_map = para_map\n",
    "\n",
    "    @staticmethod\n",
    "    def test_model(model, model_config):\n",
    "        # If there's a GPU available...\n",
    "        if torch.cuda.is_available():\n",
    "            # Tell PyTorch to use the GPU.\n",
    "            id = 1\n",
    "            torch.cuda.set_device(1)\n",
    "            device = torch.device(\"cuda\")\n",
    "            print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "            print('We will use the GPU:', torch.cuda.get_device_name(id))\n",
    "            print(torch.cuda.current_device())\n",
    "        # If not...\n",
    "        else:\n",
    "            print('No GPU available, using the CPU instead.')\n",
    "            device = torch.device(\"cpu\")\n",
    "        display(summary(model, [(model_config.batch_size, model_config.para_len, model_config.wrd_len,\n",
    "                768), (model_config.batch_size, model_config.para_len, model_config.wrd_len, 768)]))\n",
    "\n",
    "\n",
    "siamese_config = config()\n",
    "model = simple_siamese(siamese_config)\n",
    "config.test_model(model=model, model_config=siamese_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, validation_dataloader, num_labels, class_weight=None):\n",
    "    #tokenized_texts = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    threshold = 0.5\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        # print('val 1 free gpu',get_free_gpu())\n",
    "        b_input_key = batch[0]\n",
    "        b_labels = batch[1].to(device)\n",
    "\n",
    "\n",
    "        #convert key to text embedding\n",
    "        tk_batch = []\n",
    "        tk_batch_bf = []\n",
    "        #print('val batch',batch)\n",
    "        for t in b_input_key.detach().to('cpu').numpy():\n",
    "            tk, tk_bf = get_text_embedding(t[0], t[1], t[2], tokenizer, bert_model, para_map, para_len, wrd_len=wrd_len)\n",
    "            if tk.size()[0] == para_len:              \n",
    "                tk_batch.append(tk)\n",
    "                tk_batch_bf.append(tk_bf)\n",
    "            else:\n",
    "                print('token size error')\n",
    "                break\n",
    "            \n",
    "\n",
    "        tk_batch = torch.stack(tk_batch)\n",
    "        tk_batch = tk_batch.to(device)\n",
    "\n",
    "        tk_batch_bf = torch.stack(tk_batch_bf)\n",
    "        tk_batch_bf = tk_batch_bf.to(device)\n",
    "        # print('val 2 free gpu',get_free_gpu())\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            logits, x1, x2 = model(tk_batch, tk_batch_bf)\n",
    "            cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "            sim = cos_sim(x1,x2)\n",
    "            sim = sim.reshape(-1,1)\n",
    "            #loss_func = BCELoss()\n",
    "            #val_loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "\n",
    "            tk_batch.detach().to('cpu')\n",
    "            del tk_batch\n",
    "            tk_batch_bf.detach().to('cpu')\n",
    "            del tk_batch_bf           \n",
    "            # print('val 3 free gpu',get_free_gpu())\n",
    "            \n",
    "            if class_weight != None:\n",
    "                pos_weight = torch.tensor(class_weight).to(device)\n",
    "                # weights = torch.tensor([pos_weight]).to(device)\n",
    "                ct_loss = nn.CrossEntropyLoss() #weight = weights\n",
    "                loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "            else:\n",
    "                ct_loss = nn.CrossEntropyLoss()\n",
    "                loss_func = BCEWithLogitsLoss()\n",
    "\n",
    "            global set_ct_loss\n",
    "            if set_ct_loss == True:\n",
    "                val_loss =  loss_func(logits,b_labels.type_as(logits)) \\\n",
    "                    -  ct_loss(sim, torch.argmax(b_labels,axis=1).type_as(sim).reshape(-1,1))  #convert labels to float for calculation\n",
    "            else: \n",
    "                val_loss =  loss_func(logits,b_labels.type_as(logits))\n",
    "\n",
    "            total_eval_loss += val_loss.item()\n",
    "            \n",
    "\n",
    "            pred_label = torch.softmax(logits, dim=1)\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "            pred_label = pred_label.to('cpu').numpy()\n",
    "\n",
    "            #tokenized_texts.append(b_input_ids)\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "\n",
    "    # Flatten outputs\n",
    "    pred_labels = np.vstack(pred_labels)\n",
    "    true_labels = np.vstack(true_labels)\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    return  pred_labels, true_labels, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, config,  train_dataloader, validation_dataloader, model_path,\\\n",
    "                             optimizer=None, scheduler=None, epochs = 10, \\\n",
    "                             class_weight = None, patience = 5):\n",
    "\n",
    "    seed_val = 1234\n",
    "\n",
    "    threshold = 0.5\n",
    "    #model_path = 'best_model.model'  # save the best model\n",
    "\n",
    "    para_len = config.para_len\n",
    "    wrd_len = config.wrd_len\n",
    "    para_map = config.para_map\n",
    "    class_weight = config.class_weight\n",
    "    num_labels = config.num_labels\n",
    "    verbose_mode = True\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    best_score = -0.5\n",
    "    best_epoch = 0\n",
    "    cnt = 0\n",
    "\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    if optimizer == None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        train_true_labels = []\n",
    "        train_pred_labels = []\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            \n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: (cik, fyear, fyear_bf)\n",
    "            #   [1]: labels\n",
    "            \n",
    "            # print('1 free gpu',get_free_gpu())\n",
    "            b_input_key = batch[0] # batch_size * (cik, fyear, fyear_bf)\n",
    "            b_labels = batch[1].to(device)\n",
    "            \n",
    "            \n",
    "            #convert key to text embedding\n",
    "            tk_batch = []\n",
    "            tk_batch_bf = []\n",
    "            #print('b_input_key',b_input_key)\n",
    "            time_start_tk = time.time()\n",
    "            for t in b_input_key.detach().to('cpu').numpy():\n",
    "                tk, tk_bf = get_text_embedding(t[0], t[1], t[2], tokenizer, bert_model, para_map, para_len, wrd_len=wrd_len)\n",
    "                if tk.size()[0] == para_len:              \n",
    "                    tk_batch.append(tk)\n",
    "                    tk_batch_bf.append(tk_bf)\n",
    "                    # print(len(tk_batch), len(tk_batch_bf))\n",
    "                else:\n",
    "                    print('token size error')\n",
    "                    break\n",
    "            # print(len(tk_batch), len(tk_batch_bf))\n",
    "            # print(\"----- token %s seconds -----\" % (time.time() - time_start_tk))\n",
    "                \n",
    "            tk_batch = torch.stack(tk_batch)\n",
    "            tk_batch = tk_batch.to(device)\n",
    "            \n",
    "            tk_batch_bf = torch.stack(tk_batch_bf)\n",
    "            tk_batch_bf = tk_batch_bf.to(device)\n",
    "            #  print('2 free gpu',get_free_gpu())\n",
    "            \n",
    "\n",
    "            time_start_batch_train = time.time()\n",
    "            logits, x1, x2 = model(tk_batch,tk_batch_bf)\n",
    "            cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "            sim = cos_sim(x1,x2)\n",
    "            sim = sim.reshape(-1,1)\n",
    "            #print(\"logits shape: \", b_input_ids.size(), b_labels.size(), logits.shape())\n",
    "            #loss_func = BCELoss()\n",
    "            #loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "\n",
    "            # add class weight\n",
    "            if class_weight != None:\n",
    "                pos_weight = torch.tensor(class_weight).to(device)\n",
    "                weights = torch.tensor([pos_weight]).to(device)\n",
    "                ct_loss = nn.CrossEntropyLoss()#weight = weights\n",
    "                loss_func = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "            else:\n",
    "                ct_loss = nn.CrossEntropyLoss()\n",
    "                loss_func = BCEWithLogitsLoss()\n",
    "            \n",
    "            tk_batch.detach().to('cpu')\n",
    "            del tk_batch\n",
    "            tk_batch_bf.detach().to('cpu')\n",
    "            del tk_batch_bf\n",
    "            \n",
    "            # print('3 free gpu',get_free_gpu())\n",
    "            # print(logits.size(), b_labels.size())\n",
    "#             loss = loss_func(\n",
    "#                 logits.view(-1, num_labels),\n",
    "#                 b_labels.type_as(logits).view(\n",
    "#                     -1, num_labels))  \n",
    "            # convert labels to float for calculation\n",
    "            # global my_ct_loss, my_sim, my_label\n",
    "            # my_sim = sim\n",
    "            # my_label = b_labels\n",
    "            # my_ct_loss = ct_loss(sim, torch.argmax(b_labels,axis=1).type_as(logits).reshape(-1,1)) \n",
    "            global set_ct_loss\n",
    "            global lista \n",
    "\n",
    "            if verbose_mode:\n",
    "                print(\"logits: \", logits)\n",
    "                print(\"b_labels.type_as(logits): \", b_labels.type_as(logits))\n",
    "                \n",
    "                train_pred_bools = torch.argmax(logits, axis=1)\n",
    "                train_pred_bools = train_pred_bools.to('cpu').numpy()\n",
    "                train_true_bools = torch.argmax(b_labels.type_as(logits), axis=1)\n",
    "                train_true_bools = train_true_bools.to('cpu').numpy()\n",
    "                # print(train_pred_bools.shape, train_true_bools.shape)\n",
    "\n",
    "                train_true_labels += train_true_bools.tolist()\n",
    "                train_pred_labels += train_pred_bools.tolist()\n",
    "                print(\"train_pred_bools\", train_pred_bools)\n",
    "                print(\"train_true_bools\", train_true_bools)\n",
    "                \n",
    "\n",
    "            if set_ct_loss == True:\n",
    "                loss =  loss_func(logits,b_labels.type_as(logits)) \\\n",
    "                    -  ct_loss(sim, torch.argmax(b_labels,axis=1).type_as(sim).reshape(-1,1))  #convert labels to float for calculation\n",
    "            else: \n",
    "                loss =  loss_func(logits, b_labels.type_as(logits))\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            # print(f\"train step loss: {step} -- {loss}\")\n",
    "            # print(f\"train step total_train_loss: {step} -- {total_train_loss}\")\n",
    "\n",
    "            model.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate.\n",
    "            if scheduler != None:\n",
    "                scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = time.time() - t0\n",
    "        print(\"Total training_time took {0:.2f} minutes \".format(training_time/60))\n",
    "\n",
    "        # calculate the total accrurcy in this epoch\n",
    "        # print(train_true_labels[0:1])\n",
    "        global lista\n",
    "        global listb\n",
    "        lista = train_true_labels\n",
    "        listb = train_pred_labels\n",
    "        train_true_labels =  np.array(train_true_labels)\n",
    "        train_pred_labels = np.array(train_pred_labels)\n",
    "        print('training acc', (train_true_labels == train_pred_labels).sum(),len(train_true_labels) )\n",
    "        train_acc = (train_true_labels == train_pred_labels).sum()/len(train_true_labels)\n",
    "\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        testing = True\n",
    "\n",
    "        if testing:\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\")\n",
    "\n",
    "            t1 = time.time()\n",
    "\n",
    "            # Put the model in evaluation mode--the dropout layers behave differently\n",
    "            # during evaluation.\n",
    "            model.eval()\n",
    "\n",
    "            pred_labels, true_labels, avg_val_loss = model_eval(\n",
    "                model,  validation_dataloader, num_labels, class_weight=class_weight)\n",
    "\n",
    "            global val_label_save\n",
    "            global val_true_label_save\n",
    "            val_label_save.append(pred_labels)\n",
    "            val_true_label_save.append(true_labels)\n",
    "\n",
    "\n",
    "            pred_bools = np.argmax(pred_labels, axis=1)\n",
    "            true_bools = np.argmax(true_labels, axis=1)\n",
    "\n",
    "            val_f1 = f1_score(true_bools, pred_bools, average=None) * 100\n",
    "            val_f1 = val_f1[1]  # return f1 for  class 1\n",
    "            val_acc = (pred_bools == true_bools).astype(int).sum() / len(pred_bools)\n",
    "            val_auc = roc_auc_score(true_bools, pred_labels[:,1])\n",
    "\n",
    "            #print('Validation Accuracy: {0:.4f}, F1: {1:.4f}, Loss: {2:.4f}'.format(val_f1, val_acc, avg_val_loss))\n",
    "            #print(classification_report(np.array(true_labels), pred_bools, target_names=label_cols) )\n",
    "            print(\"Epoch {0}\\t Train Loss: {1:.4f}\\t  Train ACC: {2:.4f}\\t Val Loss {3:.4f}\\t Val Acc: {4:.4f}\\t Val F1: {5:.4f}\\t Val AUC: {6:.4f}\".\\\n",
    "                format(epoch_i +1, avg_train_loss, train_acc, avg_val_loss, val_acc, val_f1, val_auc))\n",
    "\n",
    "            # Measure how long the validation run took.\n",
    "            validation_time = time.time() - t1\n",
    "            print(\"Total val_time took {0:.2f} minutes \".format(validation_time/60))\n",
    "\n",
    "            #print(\"  Validation Loss: {0:.2f}\".format(val_f1_accuracy))\n",
    "            #print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "            # Record all statistics from this epoch.\n",
    "            training_stats.append({\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': val_f1,\n",
    "                'Valid. AUC':val_auc,\n",
    "                'Best F1': best_score,\n",
    "                'Best epoch': best_epoch\n",
    "                #'Training Time': training_time,\n",
    "                #'Validation Time': validation_time\n",
    "            })\n",
    "\n",
    "            # early stopping\n",
    "            if val_f1 > best_score:\n",
    "                best_score = val_f1\n",
    "                best_epoch = epoch_i + 1\n",
    "                torch.save(copy.deepcopy(model.state_dict()), model_path)\n",
    "                print(\"model saved\")\n",
    "                cnt = 0\n",
    "            else:\n",
    "                cnt += 1\n",
    "                if cnt == patience:\n",
    "                    print(\"\\n\")\n",
    "                    print(\"early stopping at epoch {0}\".format(epoch_i + 1))\n",
    "                    break\n",
    "\n",
    "            print(\"\")\n",
    "            #print(\"Training complete!\")\n",
    "\n",
    "            print(\"Total training took {0:.2f} minutes\".format((time.time()-total_t0)/60))\n",
    "        else:\n",
    "            training_stats = 0\n",
    "            print(avg_train_loss)\n",
    "        \n",
    "    return model, training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1080 Ti\n",
      "1\n",
      "(200, 5)\n",
      "successfully load data ...\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      "fraud\n",
      "------------\n",
      "\n",
      "fold 0 \n",
      "\n",
      "train fraud 67 test fraud 33\n",
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.0990, -0.2323],\n",
      "        [ 0.0474, -0.2948],\n",
      "        [ 0.1105, -0.1732],\n",
      "        [ 0.0398, -0.1067],\n",
      "        [ 0.0486, -0.1090],\n",
      "        [ 0.0487, -0.0928],\n",
      "        [ 0.0345, -0.1114],\n",
      "        [ 0.0971, -0.1416],\n",
      "        [ 0.1183, -0.2894],\n",
      "        [ 0.0715, -0.2682],\n",
      "        [ 0.0533, -0.0965],\n",
      "        [ 0.0224, -0.2900],\n",
      "        [ 0.0426, -0.0986],\n",
      "        [ 0.0508, -0.0896],\n",
      "        [ 0.0831, -0.1854],\n",
      "        [ 0.0946, -0.1689],\n",
      "        [ 0.1213, -0.2546],\n",
      "        [ 0.1003, -0.2841],\n",
      "        [ 0.0862, -0.1819],\n",
      "        [ 0.0678, -0.2281],\n",
      "        [ 0.0308, -0.1988],\n",
      "        [ 0.2231, -0.1647],\n",
      "        [ 0.0631, -0.1540],\n",
      "        [ 0.0459, -0.1330],\n",
      "        [ 0.1070, -0.1203],\n",
      "        [ 0.0598, -0.2135],\n",
      "        [ 0.0478, -0.1036],\n",
      "        [ 0.0489, -0.0906],\n",
      "        [ 0.0471, -0.0930],\n",
      "        [ 0.0723, -0.1969],\n",
      "        [ 0.0334, -0.1891],\n",
      "        [-0.0058, -0.3112],\n",
      "        [ 0.0016, -0.2907],\n",
      "        [ 0.1773, -0.2399],\n",
      "        [-0.0213, -0.1090],\n",
      "        [ 0.0524, -0.1065],\n",
      "        [ 0.0355, -0.1759],\n",
      "        [-0.0124, -0.2937],\n",
      "        [ 0.1004, -0.3544],\n",
      "        [ 0.0328, -0.2231],\n",
      "        [ 0.1183, -0.2881],\n",
      "        [ 0.0315, -0.0921],\n",
      "        [ 0.0691, -0.1188],\n",
      "        [ 0.0193, -0.2028],\n",
      "        [ 0.0716, -0.1373],\n",
      "        [ 0.0305, -0.1239],\n",
      "        [ 0.1062, -0.1517],\n",
      "        [ 0.0870, -0.3113],\n",
      "        [ 0.1274, -0.3206],\n",
      "        [ 0.0964, -0.3132],\n",
      "        [ 0.1216, -0.2417],\n",
      "        [ 0.1077, -0.1640],\n",
      "        [ 0.1512, -0.1823],\n",
      "        [ 0.0243, -0.1250],\n",
      "        [ 0.0627, -0.2309],\n",
      "        [ 0.0475, -0.1083],\n",
      "        [ 0.0846, -0.2627],\n",
      "        [ 0.0478, -0.3160],\n",
      "        [ 0.0602, -0.1971],\n",
      "        [-0.0139, -0.1752],\n",
      "        [ 0.0614, -0.2656],\n",
      "        [ 0.1182, -0.2578],\n",
      "        [ 0.0684, -0.1460],\n",
      "        [ 0.1016, -0.2221]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0]\n",
      "logits:  tensor([[ 0.1081, -0.3613],\n",
      "        [ 0.0874, -0.2009],\n",
      "        [ 0.0968, -0.3021],\n",
      "        [ 0.0840, -0.3069],\n",
      "        [ 0.0789, -0.1729],\n",
      "        [ 0.1954, -0.2991],\n",
      "        [ 0.1476, -0.1344],\n",
      "        [ 0.1494, -0.1196],\n",
      "        [ 0.1292, -0.2489],\n",
      "        [ 0.0089, -0.1950],\n",
      "        [ 0.0643, -0.0882],\n",
      "        [ 0.0859, -0.2822],\n",
      "        [ 0.0839, -0.2456],\n",
      "        [ 0.0495, -0.1082],\n",
      "        [ 0.1275, -0.3195],\n",
      "        [ 0.1948, -0.3009],\n",
      "        [ 0.0548, -0.2072],\n",
      "        [ 0.0224, -0.2191],\n",
      "        [ 0.0961, -0.2662],\n",
      "        [ 0.1177, -0.2226],\n",
      "        [ 0.1012, -0.2766],\n",
      "        [ 0.0932, -0.3043],\n",
      "        [ 0.1433, -0.2179],\n",
      "        [ 0.1629, -0.2494],\n",
      "        [ 0.2368, -0.2144],\n",
      "        [ 0.0123, -0.2447],\n",
      "        [ 0.1202, -0.2195],\n",
      "        [ 0.0473, -0.1000],\n",
      "        [ 0.0715, -0.1860],\n",
      "        [ 0.0185, -0.1823],\n",
      "        [ 0.0711, -0.2589],\n",
      "        [ 0.1652, -0.2439],\n",
      "        [ 0.0698, -0.2955],\n",
      "        [ 0.0356, -0.2390],\n",
      "        [-0.0376, -0.3150],\n",
      "        [ 0.0017, -0.2749],\n",
      "        [ 0.0715, -0.1753],\n",
      "        [-0.0166, -0.1839],\n",
      "        [ 0.1429, -0.2504],\n",
      "        [ 0.0623, -0.1995],\n",
      "        [ 0.0525, -0.1056],\n",
      "        [ 0.1688, -0.2095],\n",
      "        [ 0.0648, -0.1078],\n",
      "        [ 0.0330, -0.1093],\n",
      "        [ 0.0567, -0.2644],\n",
      "        [ 0.0767, -0.2104],\n",
      "        [ 0.0824, -0.1573],\n",
      "        [ 0.1700, -0.1648],\n",
      "        [ 0.1170, -0.2282],\n",
      "        [ 0.1569, -0.2405],\n",
      "        [ 0.0577, -0.2546],\n",
      "        [ 0.1272, -0.3014],\n",
      "        [ 0.1439, -0.3117],\n",
      "        [ 0.0363, -0.0929],\n",
      "        [ 0.0528, -0.2128],\n",
      "        [ 0.1040, -0.1929],\n",
      "        [ 0.1061, -0.2874],\n",
      "        [ 0.0510, -0.2437],\n",
      "        [ 0.0463, -0.0826],\n",
      "        [ 0.0085, -0.0996],\n",
      "        [-0.0338, -0.1802],\n",
      "        [ 0.1066, -0.2910],\n",
      "        [ 0.0809, -0.1872],\n",
      "        [ 0.0315, -0.0721]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0]\n",
      "logits:  tensor([[ 0.1579, -0.3339],\n",
      "        [ 0.1166, -0.1327],\n",
      "        [ 0.0704, -0.3627],\n",
      "        [ 0.1244, -0.2411],\n",
      "        [ 0.1080, -0.2625]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [0 1 0 1 0]\n",
      "Total training_time took 0.73 minutes \n",
      "training acc 66 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 1\t Train Loss: 0.6863\t  Train ACC: 0.4962\t Val Loss 0.6634\t Val Acc: 0.5075\t Val F1: 0.0000\t Val AUC: 0.5882\n",
      "Total val_time took 0.33 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 1.07 minutes\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.1554, -0.2362],\n",
      "        [ 0.0923, -0.1426],\n",
      "        [ 0.0471, -0.1974],\n",
      "        [ 0.1755, -0.1971],\n",
      "        [ 0.0554, -0.0923],\n",
      "        [ 0.0823, -0.1293],\n",
      "        [ 0.1546, -0.2755],\n",
      "        [ 0.1492, -0.1123],\n",
      "        [ 0.0996, -0.1896],\n",
      "        [ 0.0746, -0.2333],\n",
      "        [ 0.0770, -0.2965],\n",
      "        [ 0.0808, -0.2227],\n",
      "        [ 0.1397, -0.2359],\n",
      "        [ 0.0509, -0.1144],\n",
      "        [ 0.0094, -0.2273],\n",
      "        [ 0.1344, -0.1439],\n",
      "        [ 0.1346, -0.3046],\n",
      "        [ 0.0755, -0.1535],\n",
      "        [ 0.1183, -0.1938],\n",
      "        [ 0.1121, -0.2405],\n",
      "        [ 0.0588, -0.0822],\n",
      "        [ 0.0706, -0.1581],\n",
      "        [ 0.1128, -0.2204],\n",
      "        [ 0.0929, -0.2202],\n",
      "        [ 0.0919, -0.2150],\n",
      "        [ 0.1287, -0.2325],\n",
      "        [ 0.0833, -0.3036],\n",
      "        [ 0.0477, -0.0978],\n",
      "        [ 0.0457, -0.1758],\n",
      "        [ 0.0597, -0.1089],\n",
      "        [ 0.1323, -0.2455],\n",
      "        [ 0.0683, -0.1074],\n",
      "        [ 0.0442, -0.1049],\n",
      "        [ 0.0492, -0.0994],\n",
      "        [ 0.0943, -0.0819],\n",
      "        [ 0.0228, -0.2462],\n",
      "        [ 0.0857, -0.2004],\n",
      "        [ 0.0098, -0.3227],\n",
      "        [ 0.0463, -0.0915],\n",
      "        [ 0.1126, -0.2206],\n",
      "        [ 0.1061, -0.2175],\n",
      "        [ 0.1043, -0.1853],\n",
      "        [ 0.1592, -0.2776],\n",
      "        [ 0.0418, -0.0794],\n",
      "        [-0.0131, -0.2470],\n",
      "        [ 0.1447, -0.2752],\n",
      "        [ 0.0367, -0.1867],\n",
      "        [ 0.1576, -0.3070],\n",
      "        [ 0.0431, -0.1087],\n",
      "        [ 0.0457, -0.0934],\n",
      "        [ 0.1131, -0.0405],\n",
      "        [ 0.0459, -0.1115],\n",
      "        [ 0.0640, -0.1044],\n",
      "        [ 0.0889, -0.2416],\n",
      "        [-0.1393, -0.1798],\n",
      "        [ 0.0961, -0.2799],\n",
      "        [ 0.0305, -0.3568],\n",
      "        [ 0.0790, -0.2432],\n",
      "        [ 0.0799, -0.2832],\n",
      "        [ 0.2021, -0.2720],\n",
      "        [-0.0165, -0.2913],\n",
      "        [ 0.1092, -0.2392],\n",
      "        [ 0.1360, -0.1507],\n",
      "        [ 0.0529, -0.0934]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1]\n",
      "logits:  tensor([[ 0.0722, -0.2833],\n",
      "        [ 0.0395, -0.0932],\n",
      "        [ 0.0402, -0.0802],\n",
      "        [ 0.0971, -0.2771],\n",
      "        [ 0.0872, -0.3300],\n",
      "        [ 0.0771, -0.2697],\n",
      "        [ 0.1648, -0.1920],\n",
      "        [ 0.0925, -0.1519],\n",
      "        [ 0.0664, -0.1007],\n",
      "        [ 0.0926, -0.2863],\n",
      "        [ 0.0717, -0.1551],\n",
      "        [ 0.0932, -0.2140],\n",
      "        [ 0.0895, -0.2305],\n",
      "        [ 0.0084, -0.1353],\n",
      "        [ 0.1117, -0.1937],\n",
      "        [ 0.0992, -0.1850],\n",
      "        [ 0.1072, -0.1639],\n",
      "        [ 0.0836, -0.2746],\n",
      "        [ 0.0311, -0.1120],\n",
      "        [ 0.1192, -0.2407],\n",
      "        [ 0.0508, -0.0887],\n",
      "        [ 0.1391, -0.1440],\n",
      "        [ 0.0849, -0.1272],\n",
      "        [ 0.0484, -0.0941],\n",
      "        [ 0.1093, -0.1840],\n",
      "        [ 0.0965, -0.2097],\n",
      "        [ 0.0629, -0.0914],\n",
      "        [ 0.0082, -0.2208],\n",
      "        [ 0.0756, -0.1871],\n",
      "        [ 0.0628, -0.2032],\n",
      "        [ 0.0713, -0.2575],\n",
      "        [ 0.1895, -0.2350],\n",
      "        [ 0.0898, -0.2029],\n",
      "        [ 0.0454, -0.1045],\n",
      "        [ 0.1049, -0.2014],\n",
      "        [ 0.1139, -0.2583],\n",
      "        [ 0.0777, -0.2506],\n",
      "        [ 0.0700, -0.2112],\n",
      "        [ 0.1114, -0.1711],\n",
      "        [ 0.0751, -0.1984],\n",
      "        [ 0.1019, -0.1398],\n",
      "        [ 0.0747, -0.2513],\n",
      "        [ 0.1305, -0.2578],\n",
      "        [ 0.0518, -0.1960],\n",
      "        [ 0.1458, -0.2388],\n",
      "        [ 0.0630, -0.1380],\n",
      "        [ 0.0666, -0.2578],\n",
      "        [ 0.0795, -0.1868],\n",
      "        [ 0.0093, -0.2460],\n",
      "        [ 0.1001, -0.1608],\n",
      "        [ 0.0629, -0.2227],\n",
      "        [ 0.0615, -0.1042],\n",
      "        [ 0.1249, -0.2815],\n",
      "        [ 0.0158, -0.2189],\n",
      "        [-0.0080, -0.1911],\n",
      "        [ 0.0031, -0.3265],\n",
      "        [ 0.0817, -0.1067],\n",
      "        [ 0.0185, -0.2676],\n",
      "        [ 0.1342, -0.1576],\n",
      "        [ 0.1336, -0.2936],\n",
      "        [ 0.1244, -0.2241],\n",
      "        [ 0.0887, -0.1310],\n",
      "        [ 0.1017, -0.2254],\n",
      "        [ 0.0817, -0.1684]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1\n",
      " 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1]\n",
      "logits:  tensor([[ 0.0346, -0.2541],\n",
      "        [ 0.0379, -0.2712],\n",
      "        [ 0.0660, -0.1066],\n",
      "        [ 0.0396, -0.0751],\n",
      "        [ 0.0381, -0.1078]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [1 1 1 1 1]\n",
      "Total training_time took 0.72 minutes \n",
      "training acc 66 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 2\t Train Loss: 0.7104\t  Train ACC: 0.4962\t Val Loss 0.7063\t Val Acc: 0.5075\t Val F1: 0.0000\t Val AUC: 0.6034\n",
      "Total val_time took 0.33 minutes \n",
      "\n",
      "Total training took 2.12 minutes\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.1178, -0.1568],\n",
      "        [ 0.0955, -0.3301],\n",
      "        [ 0.1224, -0.2076],\n",
      "        [ 0.0305, -0.1708],\n",
      "        [ 0.1875, -0.2321],\n",
      "        [ 0.0642, -0.1486],\n",
      "        [ 0.1372, -0.1943],\n",
      "        [ 0.0800, -0.1146],\n",
      "        [ 0.0995, -0.2708],\n",
      "        [-0.0042, -0.2018],\n",
      "        [ 0.0679, -0.2489],\n",
      "        [ 0.0516, -0.0985],\n",
      "        [ 0.0382, -0.2593],\n",
      "        [ 0.0516, -0.2760],\n",
      "        [ 0.1099, -0.1955],\n",
      "        [ 0.0298, -0.0972],\n",
      "        [ 0.0526, -0.0962],\n",
      "        [ 0.1056, -0.1484],\n",
      "        [-0.0405, -0.1357],\n",
      "        [ 0.1177, -0.0849],\n",
      "        [ 0.2043, -0.3256],\n",
      "        [ 0.1695, -0.1931],\n",
      "        [ 0.0962, -0.2016],\n",
      "        [ 0.0240, -0.2406],\n",
      "        [ 0.0496, -0.1063],\n",
      "        [ 0.0965, -0.2753],\n",
      "        [ 0.1304, -0.1279],\n",
      "        [ 0.0490, -0.2048],\n",
      "        [ 0.0625, -0.1585],\n",
      "        [ 0.1273, -0.2317],\n",
      "        [ 0.0424, -0.1008],\n",
      "        [ 0.0513, -0.2865],\n",
      "        [ 0.0222, -0.2806],\n",
      "        [ 0.0535, -0.1729],\n",
      "        [ 0.0797, -0.1100],\n",
      "        [ 0.0445, -0.0937],\n",
      "        [ 0.0611, -0.0944],\n",
      "        [-0.0041, -0.2564],\n",
      "        [ 0.1615, -0.1977],\n",
      "        [ 0.0412, -0.0885],\n",
      "        [ 0.0846, -0.2127],\n",
      "        [ 0.0322, -0.1581],\n",
      "        [ 0.0462, -0.1596],\n",
      "        [ 0.0970, -0.2875],\n",
      "        [ 0.0945, -0.1731],\n",
      "        [ 0.0112, -0.0612],\n",
      "        [ 0.0578, -0.0938],\n",
      "        [ 0.1312, -0.2262],\n",
      "        [ 0.1274, -0.2014],\n",
      "        [ 0.0940, -0.2129],\n",
      "        [ 0.0940, -0.1920],\n",
      "        [ 0.0416, -0.1979],\n",
      "        [ 0.0341, -0.1992],\n",
      "        [ 0.1328, -0.1187],\n",
      "        [ 0.1901, -0.2366],\n",
      "        [ 0.1373, -0.2239],\n",
      "        [ 0.0351, -0.0988],\n",
      "        [ 0.0496, -0.1343],\n",
      "        [ 0.0162, -0.1699],\n",
      "        [ 0.0417, -0.2136],\n",
      "        [ 0.0959, -0.1601],\n",
      "        [ 0.1060, -0.2620],\n",
      "        [ 0.0438, -0.0924],\n",
      "        [ 0.1214, -0.1991]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1\n",
      " 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0]\n",
      "logits:  tensor([[ 0.0406, -0.2758],\n",
      "        [ 0.1103, -0.1736],\n",
      "        [ 0.1389, -0.2442],\n",
      "        [ 0.0939, -0.2215],\n",
      "        [ 0.0705, -0.2166],\n",
      "        [ 0.1052, -0.2150],\n",
      "        [ 0.1506, -0.3725],\n",
      "        [ 0.0334, -0.2346],\n",
      "        [ 0.0706, -0.2067],\n",
      "        [ 0.1503, -0.1784],\n",
      "        [ 0.0470, -0.0774],\n",
      "        [ 0.1652, -0.2864],\n",
      "        [ 0.0418, -0.2236],\n",
      "        [ 0.1141, -0.0919],\n",
      "        [ 0.0635, -0.1535],\n",
      "        [ 0.0716, -0.2550],\n",
      "        [ 0.0597, -0.1842],\n",
      "        [ 0.0474, -0.2412],\n",
      "        [ 0.0194, -0.1958],\n",
      "        [ 0.1155, -0.1621],\n",
      "        [ 0.0501, -0.2296],\n",
      "        [ 0.0651, -0.2142],\n",
      "        [ 0.0987, -0.3466],\n",
      "        [ 0.1555, -0.1634],\n",
      "        [ 0.0354, -0.0972],\n",
      "        [ 0.0569, -0.0826],\n",
      "        [ 0.0553, -0.1941],\n",
      "        [ 0.0173, -0.1748],\n",
      "        [ 0.2517, -0.3101],\n",
      "        [-0.0077, -0.2127],\n",
      "        [ 0.1057, -0.2237],\n",
      "        [ 0.0398, -0.0901],\n",
      "        [ 0.0565, -0.1026],\n",
      "        [ 0.0558, -0.2081],\n",
      "        [ 0.0604, -0.3102],\n",
      "        [ 0.1379, -0.2754],\n",
      "        [ 0.0413, -0.1788],\n",
      "        [ 0.0052, -0.1955],\n",
      "        [ 0.0519, -0.1163],\n",
      "        [ 0.1256, -0.1531],\n",
      "        [ 0.0758, -0.0929],\n",
      "        [ 0.0460, -0.1702],\n",
      "        [ 0.1278, -0.1819],\n",
      "        [ 0.1118, -0.1666],\n",
      "        [ 0.0349, -0.2370],\n",
      "        [ 0.0957, -0.3058],\n",
      "        [ 0.0064, -0.0462],\n",
      "        [ 0.0556, -0.1062],\n",
      "        [ 0.1063, -0.0951],\n",
      "        [ 0.1353, -0.2116],\n",
      "        [ 0.1307, -0.2090],\n",
      "        [ 0.0938, -0.1411],\n",
      "        [ 0.0407, -0.1416],\n",
      "        [ 0.0416, -0.1342],\n",
      "        [-0.0612, -0.1757],\n",
      "        [ 0.1214, -0.1860],\n",
      "        [ 0.0762, -0.1429],\n",
      "        [ 0.0469, -0.2425],\n",
      "        [ 0.0464, -0.0949],\n",
      "        [ 0.0602, -0.1041],\n",
      "        [ 0.1840, -0.1088],\n",
      "        [ 0.1631, -0.1763],\n",
      "        [ 0.0439, -0.1123],\n",
      "        [ 0.0446, -0.0857]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
      " 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0]\n",
      "logits:  tensor([[ 0.0936, -0.2195],\n",
      "        [ 0.0620, -0.2589],\n",
      "        [ 0.0304, -0.0914],\n",
      "        [ 0.0954, -0.0944],\n",
      "        [ 0.0546, -0.0934]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [1 1 1 0 1]\n",
      "Total training_time took 0.73 minutes \n",
      "training acc 66 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 3\t Train Loss: 0.7030\t  Train ACC: 0.4962\t Val Loss 0.6829\t Val Acc: 0.5075\t Val F1: 0.0000\t Val AUC: 0.6141\n",
      "Total val_time took 0.34 minutes \n",
      "\n",
      "Total training took 3.19 minutes\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.0925, -0.1463],\n",
      "        [ 0.1148, -0.1456],\n",
      "        [ 0.0384, -0.1983],\n",
      "        [ 0.0486, -0.1028],\n",
      "        [ 0.0905, -0.1509],\n",
      "        [ 0.0867, -0.1580],\n",
      "        [ 0.0522, -0.1060],\n",
      "        [ 0.0910, -0.1242],\n",
      "        [ 0.0017, -0.1659],\n",
      "        [ 0.1002, -0.2036],\n",
      "        [ 0.0501, -0.1938],\n",
      "        [ 0.0524, -0.1900],\n",
      "        [ 0.0633, -0.0697],\n",
      "        [ 0.0736, -0.1153],\n",
      "        [ 0.0084, -0.1194],\n",
      "        [ 0.0206, -0.0638],\n",
      "        [ 0.0961, -0.1463],\n",
      "        [ 0.0895, -0.2017],\n",
      "        [ 0.0527, -0.1061],\n",
      "        [ 0.1446, -0.3453],\n",
      "        [ 0.1335, -0.1964],\n",
      "        [ 0.0476, -0.0893],\n",
      "        [ 0.0771, -0.2225],\n",
      "        [ 0.1184, -0.2122],\n",
      "        [ 0.0753, -0.1534],\n",
      "        [ 0.0432, -0.1373],\n",
      "        [ 0.0319, -0.1234],\n",
      "        [ 0.0417, -0.1824],\n",
      "        [-0.0251, -0.1573],\n",
      "        [ 0.0748, -0.1092],\n",
      "        [ 0.0546, -0.2003],\n",
      "        [ 0.0276, -0.2239],\n",
      "        [ 0.0717, -0.0789],\n",
      "        [ 0.0787, -0.2451],\n",
      "        [-0.0379, -0.1712],\n",
      "        [ 0.0775, -0.1291],\n",
      "        [ 0.1252, -0.0762],\n",
      "        [ 0.0675, -0.2116],\n",
      "        [ 0.1053, -0.2683],\n",
      "        [ 0.1215, -0.1811],\n",
      "        [ 0.0374, -0.0901],\n",
      "        [ 0.0281, -0.0867],\n",
      "        [ 0.1865, -0.1737],\n",
      "        [ 0.0358, -0.0996],\n",
      "        [ 0.0313, -0.1834],\n",
      "        [ 0.1069, -0.2342],\n",
      "        [ 0.0616, -0.0992],\n",
      "        [ 0.0954, -0.1034],\n",
      "        [ 0.1357, -0.2232],\n",
      "        [ 0.0653, -0.1925],\n",
      "        [ 0.1150, -0.2856],\n",
      "        [ 0.0441, -0.0987],\n",
      "        [ 0.0793, -0.2254],\n",
      "        [ 0.0502, -0.1727],\n",
      "        [ 0.1324, -0.2280],\n",
      "        [ 0.0406, -0.1076],\n",
      "        [ 0.1068, -0.2284],\n",
      "        [ 0.1248, -0.1173],\n",
      "        [ 0.0198, -0.1850],\n",
      "        [ 0.0776, -0.1969],\n",
      "        [-0.0116, -0.1373],\n",
      "        [ 0.1458, -0.1395],\n",
      "        [ 0.0556, -0.0976],\n",
      "        [ 0.0867, -0.1975]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1]\n",
      "logits:  tensor([[ 0.1233, -0.1726],\n",
      "        [ 0.0834, -0.2121],\n",
      "        [ 0.1028, -0.1046],\n",
      "        [ 0.0419, -0.1411],\n",
      "        [ 0.1013, -0.2071],\n",
      "        [ 0.0628, -0.1579],\n",
      "        [ 0.0505, -0.0970],\n",
      "        [ 0.1079, -0.0879],\n",
      "        [ 0.0477, -0.0993],\n",
      "        [ 0.0372, -0.1582],\n",
      "        [ 0.0942, -0.2615],\n",
      "        [ 0.1396, -0.2255],\n",
      "        [ 0.0389, -0.0971],\n",
      "        [ 0.0079, -0.2132],\n",
      "        [ 0.0388, -0.1372],\n",
      "        [ 0.0630, -0.1678],\n",
      "        [ 0.1286, -0.2230],\n",
      "        [ 0.0460, -0.2052],\n",
      "        [ 0.0348, -0.0773],\n",
      "        [ 0.0973, -0.2561],\n",
      "        [ 0.0538, -0.1028],\n",
      "        [ 0.0491, -0.1816],\n",
      "        [ 0.0729, -0.1732],\n",
      "        [-0.0200, -0.1039],\n",
      "        [ 0.1612, -0.1963],\n",
      "        [ 0.0661, -0.2154],\n",
      "        [ 0.0112, -0.1360],\n",
      "        [ 0.0133, -0.2420],\n",
      "        [ 0.0934, -0.1380],\n",
      "        [ 0.0470, -0.0933],\n",
      "        [-0.0407, -0.2262],\n",
      "        [ 0.0421, -0.1025],\n",
      "        [ 0.1318, -0.2096],\n",
      "        [ 0.1153, -0.1556],\n",
      "        [ 0.0982, -0.2233],\n",
      "        [ 0.0607, -0.2053],\n",
      "        [ 0.0136, -0.2318],\n",
      "        [ 0.0971, -0.2054],\n",
      "        [ 0.0191, -0.1825],\n",
      "        [ 0.0510, -0.0855],\n",
      "        [ 0.0145, -0.1673],\n",
      "        [ 0.0980, -0.0722],\n",
      "        [ 0.0953, -0.2316],\n",
      "        [ 0.0342, -0.1207],\n",
      "        [ 0.0381, -0.0811],\n",
      "        [ 0.0585, -0.1554],\n",
      "        [ 0.0263, -0.1481],\n",
      "        [ 0.0670, -0.0913],\n",
      "        [ 0.0312, -0.0804],\n",
      "        [ 0.0474, -0.0942],\n",
      "        [ 0.0583, -0.0535],\n",
      "        [ 0.0530, -0.0963],\n",
      "        [ 0.0627, -0.1483],\n",
      "        [ 0.0518, -0.1802],\n",
      "        [ 0.0050, -0.1557],\n",
      "        [ 0.0688, -0.1505],\n",
      "        [ 0.1301, -0.1623],\n",
      "        [ 0.0839, -0.1359],\n",
      "        [ 0.1408, -0.1526],\n",
      "        [ 0.0407, -0.0855],\n",
      "        [ 0.0508, -0.1859],\n",
      "        [ 0.0476, -0.1867],\n",
      "        [ 0.0829, -0.1388],\n",
      "        [ 0.0451, -0.1638]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0\n",
      " 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0]\n",
      "logits:  tensor([[ 0.1236, -0.2253],\n",
      "        [ 0.1271, -0.1618],\n",
      "        [ 0.0261, -0.0695],\n",
      "        [ 0.0457, -0.1751],\n",
      "        [-0.0022, -0.2601]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [1 0 1 1 1]\n",
      "Total training_time took 0.73 minutes \n",
      "training acc 66 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 4\t Train Loss: 0.7023\t  Train ACC: 0.4962\t Val Loss 0.6721\t Val Acc: 0.5075\t Val F1: 0.0000\t Val AUC: 0.6301\n",
      "Total val_time took 0.34 minutes \n",
      "\n",
      "Total training took 4.27 minutes\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0425, -0.1130],\n",
      "        [ 0.0898, -0.0893],\n",
      "        [ 0.0390, -0.0821],\n",
      "        [ 0.1004, -0.1440],\n",
      "        [ 0.0442, -0.1890],\n",
      "        [-0.0655, -0.0373],\n",
      "        [-0.0115, -0.0914],\n",
      "        [ 0.0219, -0.1425],\n",
      "        [ 0.1672, -0.1889],\n",
      "        [ 0.1287, -0.1175],\n",
      "        [ 0.0461, -0.0841],\n",
      "        [ 0.1172, -0.1880],\n",
      "        [ 0.1353, -0.2265],\n",
      "        [ 0.0015, -0.1043],\n",
      "        [ 0.0378, -0.1064],\n",
      "        [ 0.0325, -0.1357],\n",
      "        [ 0.0550, -0.2288],\n",
      "        [ 0.0823, -0.1040],\n",
      "        [-0.0773, -0.2050],\n",
      "        [ 0.0209, -0.2112],\n",
      "        [ 0.0455, -0.0808],\n",
      "        [-0.0589, -0.1561],\n",
      "        [ 0.0455, -0.2038],\n",
      "        [ 0.0724, -0.0904],\n",
      "        [ 0.1318, -0.1838],\n",
      "        [ 0.0441, -0.1438],\n",
      "        [ 0.0549, -0.2383],\n",
      "        [ 0.0565, -0.2139],\n",
      "        [ 0.0515, -0.1074],\n",
      "        [ 0.0464, -0.0833],\n",
      "        [ 0.0342, -0.0911],\n",
      "        [ 0.0108, -0.1598],\n",
      "        [ 0.1062, -0.1655],\n",
      "        [ 0.0449, -0.1377],\n",
      "        [ 0.0391, -0.0814],\n",
      "        [ 0.0197, -0.1451],\n",
      "        [ 0.0220, -0.2346],\n",
      "        [ 0.0301, -0.2068],\n",
      "        [-0.0135, -0.2030],\n",
      "        [ 0.0578, -0.1543],\n",
      "        [ 0.1004, -0.1966],\n",
      "        [ 0.0383, -0.1267],\n",
      "        [ 0.0357, -0.1872],\n",
      "        [ 0.0394, -0.0932],\n",
      "        [ 0.0092, -0.1250],\n",
      "        [ 0.1085, -0.1953],\n",
      "        [ 0.0347, -0.1236],\n",
      "        [-0.0058, -0.1768],\n",
      "        [ 0.0808, -0.1224],\n",
      "        [ 0.0452, -0.0884],\n",
      "        [ 0.0291, -0.1873],\n",
      "        [ 0.0442, -0.2474],\n",
      "        [ 0.1043, -0.0792],\n",
      "        [ 0.1099, -0.1834],\n",
      "        [ 0.0432, -0.1009],\n",
      "        [ 0.1043, -0.1030],\n",
      "        [ 0.0475, -0.2470],\n",
      "        [ 0.0310, -0.0750],\n",
      "        [ 0.0971, -0.1965],\n",
      "        [ 0.0481, -0.0814],\n",
      "        [ 0.0543, -0.0947],\n",
      "        [ 0.0472, -0.1019],\n",
      "        [ 0.1145, -0.1390],\n",
      "        [ 0.0883, -0.2300]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0]\n",
      "logits:  tensor([[ 0.0535, -0.0879],\n",
      "        [ 0.0438, -0.1467],\n",
      "        [ 0.1245, -0.1982],\n",
      "        [ 0.0476, -0.1035],\n",
      "        [ 0.1445, -0.2025],\n",
      "        [-0.0033, -0.1368],\n",
      "        [ 0.0079, -0.1739],\n",
      "        [ 0.1217, -0.2309],\n",
      "        [ 0.0174, -0.2786],\n",
      "        [ 0.0530, -0.1072],\n",
      "        [ 0.0921, -0.0766],\n",
      "        [-0.0609, -0.0942],\n",
      "        [ 0.0430, -0.1900],\n",
      "        [ 0.0086, -0.1670],\n",
      "        [ 0.0669, -0.1474],\n",
      "        [ 0.0462, -0.1357],\n",
      "        [ 0.0632, -0.0782],\n",
      "        [ 0.0290, -0.0555],\n",
      "        [ 0.0555, -0.1010],\n",
      "        [ 0.0488, -0.1022],\n",
      "        [ 0.0596, -0.0390],\n",
      "        [ 0.1080, -0.2181],\n",
      "        [ 0.1064, -0.1684],\n",
      "        [ 0.0217, -0.0982],\n",
      "        [-0.0167, -0.0967],\n",
      "        [ 0.0168, -0.1554],\n",
      "        [ 0.0884, -0.2096],\n",
      "        [ 0.0787, -0.1935],\n",
      "        [ 0.1069, -0.1735],\n",
      "        [ 0.0671, -0.1224],\n",
      "        [ 0.1143, -0.1044],\n",
      "        [ 0.0470, -0.0709],\n",
      "        [ 0.0519, -0.1248],\n",
      "        [ 0.1022, -0.3185],\n",
      "        [ 0.0362, -0.0829],\n",
      "        [ 0.0603, -0.1077],\n",
      "        [ 0.0698, -0.1205],\n",
      "        [ 0.0883, -0.1129],\n",
      "        [ 0.0443, -0.0886],\n",
      "        [ 0.1243, -0.1699],\n",
      "        [ 0.0130, -0.1997],\n",
      "        [ 0.0525, -0.0876],\n",
      "        [-0.0027, -0.0554],\n",
      "        [ 0.0823, -0.1447],\n",
      "        [-0.0280, -0.1144],\n",
      "        [ 0.0607, -0.1688],\n",
      "        [ 0.0722, -0.1683],\n",
      "        [ 0.0375, -0.0269],\n",
      "        [ 0.0356, -0.0858],\n",
      "        [ 0.0186, -0.0830],\n",
      "        [ 0.0033, -0.1425],\n",
      "        [ 0.0006, -0.1286],\n",
      "        [ 0.0395, -0.0918],\n",
      "        [ 0.0828, -0.1874],\n",
      "        [ 0.0497, -0.0821],\n",
      "        [ 0.0912, -0.2130],\n",
      "        [ 0.0555, -0.0826],\n",
      "        [ 0.0536, -0.1405],\n",
      "        [ 0.0527, -0.1245],\n",
      "        [ 0.0190, -0.2008],\n",
      "        [-0.0064, -0.0861],\n",
      "        [ 0.1171, -0.0887],\n",
      "        [ 0.1335, -0.1496],\n",
      "        [ 0.1073, -0.1414]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1]\n",
      "logits:  tensor([[ 0.0804, -0.1649],\n",
      "        [ 0.1311, -0.1161],\n",
      "        [ 0.0707, -0.1323],\n",
      "        [ 0.0609, -0.0806],\n",
      "        [ 0.0656, -0.1899]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [1 1 0 1 0]\n",
      "Total training_time took 0.72 minutes \n",
      "training acc 67 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 5\t Train Loss: 0.6968\t  Train ACC: 0.5038\t Val Loss 0.7000\t Val Acc: 0.5075\t Val F1: 0.0000\t Val AUC: 0.6381\n",
      "Total val_time took 0.34 minutes \n",
      "\n",
      "Total training took 5.33 minutes\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.0491, -0.0841],\n",
      "        [ 0.0374, -0.1044],\n",
      "        [ 0.0251, -0.1173],\n",
      "        [ 0.0225, -0.1063],\n",
      "        [ 0.0314, -0.0838],\n",
      "        [-0.0302, -0.1269],\n",
      "        [ 0.0527, -0.0962],\n",
      "        [ 0.0452, -0.2002],\n",
      "        [ 0.0238, -0.0994],\n",
      "        [ 0.0495, -0.0710],\n",
      "        [ 0.0822, -0.1048],\n",
      "        [ 0.0386, -0.1009],\n",
      "        [ 0.0662, -0.0658],\n",
      "        [ 0.0346, -0.1946],\n",
      "        [ 0.1164, -0.2936],\n",
      "        [ 0.0807, -0.1666],\n",
      "        [ 0.0227, -0.2142],\n",
      "        [ 0.1424, -0.1173],\n",
      "        [ 0.0372, -0.1773],\n",
      "        [ 0.1270, -0.0927],\n",
      "        [ 0.0594, -0.0816],\n",
      "        [ 0.0371, -0.0693],\n",
      "        [ 0.0384, -0.0920],\n",
      "        [ 0.0349, -0.0697],\n",
      "        [ 0.0193, -0.1975],\n",
      "        [ 0.0590, -0.1898],\n",
      "        [ 0.0072, -0.1049],\n",
      "        [-0.0153, -0.1141],\n",
      "        [ 0.0465, -0.0773],\n",
      "        [ 0.0301, -0.0757],\n",
      "        [ 0.0004, -0.0587],\n",
      "        [ 0.1444, -0.0520],\n",
      "        [ 0.0055, -0.0968],\n",
      "        [ 0.0077, -0.0918],\n",
      "        [ 0.0488, -0.1007],\n",
      "        [ 0.0399, -0.1164],\n",
      "        [ 0.0497, -0.1420],\n",
      "        [ 0.0341, -0.1350],\n",
      "        [ 0.0392, -0.1501],\n",
      "        [ 0.0965, -0.1222],\n",
      "        [ 0.0088, -0.1956],\n",
      "        [ 0.0368, -0.0836],\n",
      "        [ 0.0342, -0.0926],\n",
      "        [ 0.0533, -0.1618],\n",
      "        [ 0.0587, -0.1429],\n",
      "        [ 0.0939, -0.1837],\n",
      "        [ 0.1036, -0.1828],\n",
      "        [ 0.0597, -0.1744],\n",
      "        [ 0.1071, -0.2137],\n",
      "        [ 0.0569, -0.0646],\n",
      "        [-0.0090, -0.1541],\n",
      "        [ 0.0704, -0.0319],\n",
      "        [-0.0111, -0.0654],\n",
      "        [ 0.0814, -0.1242],\n",
      "        [-0.0401, -0.1182],\n",
      "        [ 0.0806, -0.1783],\n",
      "        [ 0.0553, -0.0947],\n",
      "        [ 0.0838, -0.0758],\n",
      "        [-0.0048, -0.0786],\n",
      "        [-0.0016, -0.0769],\n",
      "        [ 0.0469, -0.3063],\n",
      "        [ 0.0029, -0.1425],\n",
      "        [-0.0646, -0.0536],\n",
      "        [ 0.0277, -0.0696]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "train_true_bools [1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1]\n",
      "logits:  tensor([[ 0.0125, -0.1051],\n",
      "        [ 0.0496, -0.0821],\n",
      "        [ 0.0334, -0.1059],\n",
      "        [ 0.0533, -0.1011],\n",
      "        [ 0.1225, -0.1659],\n",
      "        [-0.0205, -0.1209],\n",
      "        [ 0.0392, -0.1285],\n",
      "        [-0.0180, -0.0897],\n",
      "        [ 0.0306, -0.1038],\n",
      "        [ 0.0050, -0.0489],\n",
      "        [ 0.0926, -0.1606],\n",
      "        [ 0.0179, -0.1149],\n",
      "        [ 0.0435, -0.0837],\n",
      "        [ 0.0195, -0.1565],\n",
      "        [ 0.0067, -0.0339],\n",
      "        [ 0.0275, -0.0780],\n",
      "        [ 0.0959, -0.0674],\n",
      "        [ 0.1037, -0.0309],\n",
      "        [-0.0010, -0.0586],\n",
      "        [-0.0167, -0.1308],\n",
      "        [-0.0362, -0.2135],\n",
      "        [ 0.0727, -0.2068],\n",
      "        [ 0.0363, -0.1559],\n",
      "        [ 0.0212, -0.0413],\n",
      "        [ 0.0459, -0.0911],\n",
      "        [ 0.0036, -0.1007],\n",
      "        [ 0.0687, -0.1358],\n",
      "        [ 0.0173, -0.1467],\n",
      "        [-0.0057, -0.1351],\n",
      "        [ 0.0407, -0.0985],\n",
      "        [ 0.0226, -0.2505],\n",
      "        [ 0.1271, -0.1535],\n",
      "        [ 0.0286, -0.1167],\n",
      "        [ 0.0143, -0.1460],\n",
      "        [-0.0312, -0.0418],\n",
      "        [ 0.0397, -0.0877],\n",
      "        [-0.0388, -0.0515],\n",
      "        [ 0.0481, -0.1059],\n",
      "        [ 0.0716, -0.0549],\n",
      "        [ 0.0656, -0.1196],\n",
      "        [ 0.0009, -0.1707],\n",
      "        [ 0.0354, -0.0933],\n",
      "        [-0.0086, -0.0589],\n",
      "        [ 0.0118, -0.2097],\n",
      "        [ 0.0311, -0.0567],\n",
      "        [ 0.1308, -0.1975],\n",
      "        [-0.0380, -0.0650],\n",
      "        [ 0.0210, -0.1642],\n",
      "        [ 0.1117, -0.1337],\n",
      "        [-0.0069, -0.1334],\n",
      "        [ 0.0340, -0.2145],\n",
      "        [ 0.0473, -0.0976],\n",
      "        [ 0.0374, -0.0839],\n",
      "        [-0.0289, -0.1366],\n",
      "        [ 0.0272, -0.1521],\n",
      "        [ 0.0055, -0.1023],\n",
      "        [ 0.1084, -0.2122],\n",
      "        [ 0.0439, -0.0859],\n",
      "        [ 0.0428, -0.0808],\n",
      "        [ 0.0696, -0.0764],\n",
      "        [ 0.0226, -0.2086],\n",
      "        [ 0.0601, -0.1390],\n",
      "        [ 0.0509, -0.0422],\n",
      "        [ 0.0078, -0.2440]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0]\n",
      "logits:  tensor([[ 0.0363, -0.0262],\n",
      "        [ 0.1137, -0.2007],\n",
      "        [ 0.0061, -0.0659],\n",
      "        [ 0.0589, -0.0817],\n",
      "        [ 0.0391, -0.0903]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [1 0 1 1 1]\n",
      "Total training_time took 0.73 minutes \n",
      "training acc 67 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 6\t Train Loss: 0.6932\t  Train ACC: 0.5038\t Val Loss 0.6971\t Val Acc: 0.5075\t Val F1: 0.0000\t Val AUC: 0.6239\n",
      "Total val_time took 0.33 minutes \n",
      "\n",
      "\n",
      "early stopping at epoch 6\n",
      "load the best model ... \n",
      "np.argmax for pred_labels [[0.53664213 0.46335793]\n",
      " [0.5802846  0.41971537]\n",
      " [0.5735223  0.42647767]\n",
      " [0.57629687 0.42370313]\n",
      " [0.5794076  0.42059246]\n",
      " [0.5967513  0.40324873]\n",
      " [0.5848176  0.41518244]\n",
      " [0.57929885 0.42070112]\n",
      " [0.575075   0.42492506]\n",
      " [0.5850349  0.4149651 ]\n",
      " [0.5858185  0.41418147]\n",
      " [0.57773584 0.4222642 ]\n",
      " [0.53614736 0.46385264]\n",
      " [0.5322258  0.4677742 ]\n",
      " [0.5843106  0.41568938]\n",
      " [0.58125216 0.41874784]\n",
      " [0.58305764 0.4169423 ]\n",
      " [0.57539266 0.42460734]\n",
      " [0.57658076 0.42341918]\n",
      " [0.57722086 0.42277914]\n",
      " [0.5761392  0.42386073]\n",
      " [0.5777034  0.42229655]\n",
      " [0.5730257  0.42697433]\n",
      " [0.5846335  0.41536647]\n",
      " [0.5816029  0.4183971 ]\n",
      " [0.5784675  0.42153248]\n",
      " [0.57068723 0.4293128 ]\n",
      " [0.58249384 0.41750613]\n",
      " [0.5802451  0.4197549 ]\n",
      " [0.57915044 0.42084962]\n",
      " [0.5820958  0.4179042 ]\n",
      " [0.5367132  0.46328682]\n",
      " [0.5852138  0.41478616]\n",
      " [0.5793164  0.42068356]\n",
      " [0.5370861  0.4629138 ]\n",
      " [0.57548183 0.42451817]\n",
      " [0.5778189  0.42218113]\n",
      " [0.5301625  0.4698375 ]\n",
      " [0.5796757  0.42032436]\n",
      " [0.57742697 0.42257303]\n",
      " [0.53604674 0.46395326]\n",
      " [0.5725598  0.42744023]\n",
      " [0.5843608  0.4156392 ]\n",
      " [0.5864205  0.41357955]\n",
      " [0.582918   0.417082  ]\n",
      " [0.5732238  0.42677617]\n",
      " [0.58311296 0.41688702]\n",
      " [0.57723725 0.42276272]\n",
      " [0.5351603  0.46483973]\n",
      " [0.56950414 0.43049586]\n",
      " [0.57210505 0.42789492]\n",
      " [0.5699265  0.4300735 ]\n",
      " [0.57918495 0.420815  ]\n",
      " [0.5352072  0.46479282]\n",
      " [0.5679413  0.43205872]\n",
      " [0.53691936 0.46308067]\n",
      " [0.5915738  0.40842628]\n",
      " [0.5836559  0.41634417]\n",
      " [0.5779562  0.42204383]\n",
      " [0.5789496  0.42105043]\n",
      " [0.53592014 0.46407986]\n",
      " [0.57591945 0.42408058]\n",
      " [0.57576865 0.42423135]\n",
      " [0.5749689  0.42503113]\n",
      " [0.57868946 0.4213105 ]\n",
      " [0.5352066  0.4647934 ]\n",
      " [0.58037776 0.4196222 ]]\n",
      "np.argmax for true_labels [[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n",
      "Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Loss: 0.6995, AUC: 0.5882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.67        34\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.51        67\n",
      "   macro avg       0.25      0.50      0.34        67\n",
      "weighted avg       0.26      0.51      0.34        67\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fold 1 \n",
      "\n",
      "train fraud 66 test fraud 34\n",
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  tensor([[-0.0556, -0.1258],\n",
      "        [-0.0933, -0.0981],\n",
      "        [-0.0806, -0.0910],\n",
      "        [ 0.0089, -0.0902],\n",
      "        [ 0.0120, -0.0590],\n",
      "        [-0.0836, -0.0691],\n",
      "        [-0.0801, -0.1523],\n",
      "        [-0.0796, -0.1188],\n",
      "        [-0.0381, -0.1481],\n",
      "        [-0.0392, -0.0800],\n",
      "        [-0.0224, -0.0622],\n",
      "        [-0.0740, -0.0422],\n",
      "        [-0.0737, -0.1280],\n",
      "        [-0.0914, -0.0640],\n",
      "        [-0.0859, -0.0727],\n",
      "        [-0.1215, -0.1582],\n",
      "        [-0.0495, -0.1215],\n",
      "        [-0.1221, -0.0829],\n",
      "        [-0.0243, -0.1587],\n",
      "        [-0.1162, -0.0831],\n",
      "        [-0.0756, -0.1310],\n",
      "        [-0.0705, -0.0942],\n",
      "        [-0.0485, -0.0994],\n",
      "        [-0.0630, -0.0862],\n",
      "        [-0.0898, -0.0640],\n",
      "        [-0.0396, -0.0949],\n",
      "        [-0.0950, -0.0690],\n",
      "        [-0.0614, -0.1988],\n",
      "        [-0.1021, -0.0639],\n",
      "        [ 0.0068, -0.1377],\n",
      "        [-0.0987, -0.0710],\n",
      "        [-0.0506, -0.0989],\n",
      "        [-0.0923, -0.0753],\n",
      "        [-0.0739, -0.0785],\n",
      "        [-0.0772, -0.0602],\n",
      "        [-0.0917, -0.0657],\n",
      "        [-0.0875, -0.1328],\n",
      "        [-0.0579, -0.1500],\n",
      "        [-0.0956, -0.0629],\n",
      "        [-0.0181, -0.0981],\n",
      "        [-0.0527, -0.1229],\n",
      "        [-0.0221, -0.1140],\n",
      "        [-0.0901, -0.1748],\n",
      "        [-0.0686, -0.0782],\n",
      "        [-0.0970, -0.0943],\n",
      "        [-0.0662, -0.1429],\n",
      "        [-0.0480, -0.1787],\n",
      "        [-0.0921, -0.0688],\n",
      "        [-0.0985, -0.0996],\n",
      "        [-0.0867, -0.0574],\n",
      "        [-0.0338, -0.2219],\n",
      "        [-0.0042, -0.0984],\n",
      "        [-0.0559, -0.1020],\n",
      "        [-0.0620, -0.1359],\n",
      "        [-0.0079, -0.1179],\n",
      "        [-0.0698, -0.1232],\n",
      "        [ 0.0313, -0.0747],\n",
      "        [-0.0838, -0.1261],\n",
      "        [-0.0744, -0.1226],\n",
      "        [-0.1070, -0.1781],\n",
      "        [-0.0746, -0.1217],\n",
      "        [-0.0825, -0.0687],\n",
      "        [ 0.0362, -0.1286],\n",
      "        [ 0.0136, -0.0651]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "train_true_bools [0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0]\n",
      "logits:  tensor([[-8.7593e-02, -6.7541e-02],\n",
      "        [-7.9103e-02, -1.0515e-01],\n",
      "        [-9.3568e-02, -8.8717e-02],\n",
      "        [-1.0680e-02, -1.1876e-01],\n",
      "        [-8.7895e-02, -7.0809e-02],\n",
      "        [-9.7618e-05, -1.1123e-02],\n",
      "        [ 1.1977e-02, -6.9580e-02],\n",
      "        [-5.2842e-02, -6.6408e-02],\n",
      "        [-3.6403e-02, -1.1706e-01],\n",
      "        [-3.2634e-02, -9.3437e-02],\n",
      "        [-8.9244e-02, -1.6172e-01],\n",
      "        [-8.9519e-02, -1.4230e-01],\n",
      "        [-6.4024e-02, -9.4943e-04],\n",
      "        [-6.6416e-02, -1.3924e-01],\n",
      "        [-6.5958e-02, -6.2140e-02],\n",
      "        [-7.1047e-02, -4.1545e-02],\n",
      "        [-2.3254e-02, -6.2581e-02],\n",
      "        [-7.9446e-02, -9.5133e-02],\n",
      "        [-2.7910e-02, -1.1413e-01],\n",
      "        [-6.2095e-02, -1.2306e-01],\n",
      "        [ 1.1059e-02, -1.6481e-01],\n",
      "        [-8.0809e-02, -7.0152e-02],\n",
      "        [ 8.7514e-03, -6.5597e-02],\n",
      "        [-6.0153e-02, -8.0519e-02],\n",
      "        [-7.3949e-02, -3.9166e-02],\n",
      "        [-2.5287e-02, -7.7665e-02],\n",
      "        [-1.1588e-01, -1.6416e-01],\n",
      "        [-5.6742e-02, -1.0499e-01],\n",
      "        [-9.2443e-02, -6.7551e-02],\n",
      "        [-2.7515e-02, -2.6208e-02],\n",
      "        [-1.0310e-01, -6.4336e-02],\n",
      "        [-1.2076e-01, -1.8688e-01],\n",
      "        [-1.9830e-02, -8.4522e-02],\n",
      "        [-4.5814e-02, -7.3129e-02],\n",
      "        [ 1.8155e-02, -8.1642e-02],\n",
      "        [-7.7963e-02, -1.1435e-01],\n",
      "        [-6.9778e-02, -9.9200e-02],\n",
      "        [-5.2916e-02, -1.5168e-01],\n",
      "        [-1.1716e-01, -1.4989e-01],\n",
      "        [-7.3039e-02, -5.0056e-02],\n",
      "        [-8.7656e-02, -7.7482e-02],\n",
      "        [ 1.1338e-02, -6.7404e-02],\n",
      "        [-9.0495e-02, -7.0421e-02],\n",
      "        [-2.8762e-03, -1.2405e-01],\n",
      "        [-2.0750e-02, -1.3845e-01],\n",
      "        [-3.3135e-02, -9.6391e-02],\n",
      "        [-7.0599e-02, -1.6833e-01],\n",
      "        [ 1.0018e-02, -3.1254e-02],\n",
      "        [-8.1306e-02, -1.3991e-01],\n",
      "        [-8.6854e-02, -6.9924e-02],\n",
      "        [-1.3307e-02, -4.6718e-02],\n",
      "        [-4.8449e-02, -1.1449e-01],\n",
      "        [-9.3964e-03, -1.0435e-01],\n",
      "        [-9.1460e-02, -1.5573e-01],\n",
      "        [-8.6216e-02, -6.5632e-02],\n",
      "        [-3.3894e-02, -1.0906e-01],\n",
      "        [-1.0232e-01, -1.0698e-01],\n",
      "        [-9.4170e-02, -1.1138e-01],\n",
      "        [-2.6410e-02, -1.6171e-01],\n",
      "        [-1.0137e-01, -1.6176e-01],\n",
      "        [-7.1044e-02, -5.1906e-02],\n",
      "        [ 6.0910e-02, -7.0626e-02],\n",
      "        [-3.0924e-02, -6.9251e-02],\n",
      "        [ 2.9642e-02, -1.0308e-01]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      "train_true_bools [1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0]\n",
      "logits:  tensor([[-0.0392, -0.0750],\n",
      "        [ 0.0163, -0.0425],\n",
      "        [-0.0518, -0.0588],\n",
      "        [-0.0835, -0.2217],\n",
      "        [-0.0070, -0.0364]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [0 1 0 1 0]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 74 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 1\t Train Loss: 0.6959\t  Train ACC: 0.5564\t Val Loss 0.6836\t Val Acc: 0.6119\t Val F1: 45.8333\t Val AUC: 0.6087\n",
      "Total val_time took 0.30 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 1.06 minutes\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0684, -0.0656],\n",
      "        [-0.1099, -0.0464],\n",
      "        [-0.0027, -0.0431],\n",
      "        [-0.1141, -0.0775],\n",
      "        [ 0.0295, -0.0208],\n",
      "        [-0.1269, -0.0852],\n",
      "        [-0.1204, -0.1281],\n",
      "        [-0.0466, -0.0993],\n",
      "        [ 0.0019, -0.1398],\n",
      "        [-0.0810, -0.0640],\n",
      "        [ 0.0130, -0.1090],\n",
      "        [ 0.0050, -0.0620],\n",
      "        [-0.0532, -0.1219],\n",
      "        [-0.0199, -0.0871],\n",
      "        [-0.0659, -0.1043],\n",
      "        [ 0.0517, -0.0785],\n",
      "        [-0.0198, -0.1330],\n",
      "        [-0.0970, -0.0707],\n",
      "        [-0.0741, -0.1369],\n",
      "        [ 0.0116, -0.0601],\n",
      "        [-0.0179, -0.0521],\n",
      "        [-0.0823, -0.0655],\n",
      "        [-0.1069, -0.0398],\n",
      "        [-0.0893, -0.0595],\n",
      "        [-0.0738, -0.1352],\n",
      "        [-0.0800, -0.1557],\n",
      "        [-0.0163,  0.0177],\n",
      "        [-0.0878, -0.1792],\n",
      "        [-0.0242, -0.0914],\n",
      "        [-0.0860, -0.0730],\n",
      "        [ 0.0084, -0.1417],\n",
      "        [-0.0847, -0.0710],\n",
      "        [ 0.0337, -0.0915],\n",
      "        [ 0.0109, -0.0455],\n",
      "        [-0.0971, -0.0701],\n",
      "        [-0.0843, -0.0614],\n",
      "        [-0.0347, -0.1396],\n",
      "        [ 0.0279, -0.0926],\n",
      "        [-0.0287, -0.0521],\n",
      "        [-0.0753, -0.0744],\n",
      "        [-0.0693, -0.0862],\n",
      "        [ 0.0041, -0.1107],\n",
      "        [-0.0652, -0.1026],\n",
      "        [-0.0840, -0.0663],\n",
      "        [-0.0770, -0.0715],\n",
      "        [-0.0790, -0.0769],\n",
      "        [-0.0113, -0.1350],\n",
      "        [-0.0819, -0.1687],\n",
      "        [ 0.0460, -0.0535],\n",
      "        [-0.0849, -0.0666],\n",
      "        [-0.0032, -0.0241],\n",
      "        [ 0.0185, -0.0631],\n",
      "        [-0.0029, -0.0574],\n",
      "        [-0.0276, -0.1306],\n",
      "        [-0.0064, -0.0343],\n",
      "        [-0.0955, -0.0676],\n",
      "        [-0.0873, -0.0606],\n",
      "        [ 0.0404,  0.0027],\n",
      "        [-0.0928, -0.0519],\n",
      "        [-0.0053, -0.0376],\n",
      "        [-0.0901, -0.0597],\n",
      "        [-0.0865, -0.0534],\n",
      "        [-0.0847, -0.0649],\n",
      "        [-0.0697, -0.0682]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1]\n",
      "train_true_bools [1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1]\n",
      "logits:  tensor([[ 0.0243, -0.0651],\n",
      "        [ 0.0506, -0.0925],\n",
      "        [-0.0712, -0.1046],\n",
      "        [-0.0683, -0.1680],\n",
      "        [ 0.0363, -0.0718],\n",
      "        [-0.0653, -0.1419],\n",
      "        [-0.0327, -0.0804],\n",
      "        [-0.0173, -0.0742],\n",
      "        [-0.0901, -0.0802],\n",
      "        [ 0.0069, -0.0580],\n",
      "        [ 0.0261, -0.0851],\n",
      "        [-0.0890, -0.0667],\n",
      "        [-0.0061, -0.0562],\n",
      "        [-0.0379, -0.1133],\n",
      "        [ 0.0567, -0.0940],\n",
      "        [-0.0032, -0.0401],\n",
      "        [-0.0400, -0.0980],\n",
      "        [-0.0453, -0.0942],\n",
      "        [-0.0062, -0.1190],\n",
      "        [-0.0274, -0.0640],\n",
      "        [-0.0535, -0.0937],\n",
      "        [-0.0443, -0.1035],\n",
      "        [-0.0151, -0.1518],\n",
      "        [-0.0427, -0.0563],\n",
      "        [ 0.0609, -0.0433],\n",
      "        [-0.0571, -0.0535],\n",
      "        [-0.1067, -0.0986],\n",
      "        [-0.0325, -0.1624],\n",
      "        [ 0.0027, -0.0469],\n",
      "        [ 0.0183, -0.0991],\n",
      "        [-0.0484, -0.1021],\n",
      "        [-0.0337, -0.1036],\n",
      "        [-0.0812, -0.1139],\n",
      "        [-0.0879, -0.0625],\n",
      "        [ 0.0039, -0.1143],\n",
      "        [-0.0154, -0.1452],\n",
      "        [-0.0294, -0.1473],\n",
      "        [-0.0134, -0.0214],\n",
      "        [-0.0675, -0.1382],\n",
      "        [-0.0367, -0.0524],\n",
      "        [-0.0934, -0.0702],\n",
      "        [-0.0244, -0.0828],\n",
      "        [-0.0517, -0.1132],\n",
      "        [ 0.0210, -0.0650],\n",
      "        [-0.0642, -0.1417],\n",
      "        [ 0.0015, -0.1492],\n",
      "        [-0.0267, -0.1122],\n",
      "        [-0.0357, -0.1177],\n",
      "        [-0.0597, -0.0883],\n",
      "        [-0.0228, -0.0751],\n",
      "        [ 0.0229, -0.0366],\n",
      "        [-0.0566, -0.0793],\n",
      "        [-0.0343, -0.0640],\n",
      "        [-0.0029, -0.0825],\n",
      "        [ 0.0825, -0.0611],\n",
      "        [ 0.0213, -0.0747],\n",
      "        [-0.0377, -0.0341],\n",
      "        [-0.0413, -0.0919],\n",
      "        [-0.0576, -0.0865],\n",
      "        [-0.0964, -0.0603],\n",
      "        [-0.0472, -0.1478],\n",
      "        [-0.0291, -0.0978],\n",
      "        [-0.0157, -0.1315],\n",
      "        [-0.0630, -0.0215]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1]\n",
      "train_true_bools [1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1\n",
      " 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1]\n",
      "logits:  tensor([[-0.0457, -0.1129],\n",
      "        [-0.0404, -0.1300],\n",
      "        [-0.0242, -0.1123],\n",
      "        [ 0.0212, -0.0524],\n",
      "        [ 0.0454, -0.0616]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0]\n",
      "train_true_bools [1 1 1 1 1]\n",
      "Total training_time took 0.75 minutes \n",
      "training acc 76 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 2\t Train Loss: 0.6991\t  Train ACC: 0.5714\t Val Loss 0.6947\t Val Acc: 0.6119\t Val F1: 45.8333\t Val AUC: 0.6203\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 2.12 minutes\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.0134, -0.0783],\n",
      "        [-0.0829, -0.0668],\n",
      "        [ 0.0278, -0.0419],\n",
      "        [-0.0517, -0.0771],\n",
      "        [-0.0186, -0.1646],\n",
      "        [-0.0892, -0.0872],\n",
      "        [-0.0805, -0.1203],\n",
      "        [ 0.0571, -0.0781],\n",
      "        [-0.0679, -0.0787],\n",
      "        [-0.0062, -0.0507],\n",
      "        [-0.0965, -0.0650],\n",
      "        [ 0.0037, -0.0233],\n",
      "        [-0.0311, -0.0915],\n",
      "        [-0.0371, -0.0329],\n",
      "        [ 0.0056, -0.0538],\n",
      "        [-0.0104, -0.1212],\n",
      "        [-0.0095, -0.2129],\n",
      "        [-0.1085, -0.0351],\n",
      "        [-0.0575, -0.0689],\n",
      "        [-0.0502, -0.0877],\n",
      "        [-0.0376, -0.0892],\n",
      "        [ 0.0137, -0.1006],\n",
      "        [-0.0060, -0.0470],\n",
      "        [-0.0560, -0.1221],\n",
      "        [-0.0330, -0.0636],\n",
      "        [ 0.0038, -0.0928],\n",
      "        [-0.0120, -0.1132],\n",
      "        [ 0.0161, -0.1544],\n",
      "        [-0.0018, -0.0207],\n",
      "        [-0.0716, -0.0971],\n",
      "        [-0.0350, -0.1284],\n",
      "        [ 0.0250, -0.0390],\n",
      "        [-0.0929, -0.0601],\n",
      "        [-0.1079, -0.0572],\n",
      "        [-0.0966, -0.0629],\n",
      "        [-0.0434, -0.0889],\n",
      "        [-0.0308, -0.0993],\n",
      "        [-0.0859, -0.0615],\n",
      "        [-0.0743, -0.1276],\n",
      "        [ 0.0472, -0.1551],\n",
      "        [-0.0083, -0.0725],\n",
      "        [-0.0225, -0.1486],\n",
      "        [-0.0050, -0.1440],\n",
      "        [-0.0049, -0.1721],\n",
      "        [-0.0892, -0.0687],\n",
      "        [ 0.0088, -0.1129],\n",
      "        [ 0.0367, -0.1753],\n",
      "        [-0.0166, -0.1190],\n",
      "        [-0.0655, -0.1082],\n",
      "        [ 0.0222, -0.0502],\n",
      "        [-0.0035, -0.1079],\n",
      "        [ 0.0260, -0.0805],\n",
      "        [-0.0816, -0.0665],\n",
      "        [ 0.0382, -0.0676],\n",
      "        [-0.0327, -0.1169],\n",
      "        [-0.0423, -0.0166],\n",
      "        [ 0.0248, -0.1266],\n",
      "        [-0.0242, -0.0893],\n",
      "        [ 0.0027, -0.1080],\n",
      "        [ 0.0318,  0.0407],\n",
      "        [ 0.0307, -0.0907],\n",
      "        [-0.0873, -0.0738],\n",
      "        [ 0.0021, -0.0396],\n",
      "        [ 0.0579, -0.1143]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0]\n",
      "train_true_bools [0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1\n",
      " 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0]\n",
      "logits:  tensor([[-0.0360, -0.0948],\n",
      "        [-0.0305, -0.0515],\n",
      "        [-0.0336, -0.1012],\n",
      "        [-0.1239, -0.1106],\n",
      "        [-0.0140,  0.0147],\n",
      "        [-0.0244, -0.0223],\n",
      "        [ 0.0007, -0.0706],\n",
      "        [-0.0654, -0.1143],\n",
      "        [-0.0248, -0.0693],\n",
      "        [-0.0186, -0.0869],\n",
      "        [ 0.0256, -0.1251],\n",
      "        [ 0.0091, -0.1166],\n",
      "        [-0.0087, -0.1086],\n",
      "        [ 0.0691,  0.0089],\n",
      "        [-0.0155, -0.0628],\n",
      "        [-0.0103, -0.1391],\n",
      "        [-0.0242, -0.0575],\n",
      "        [-0.0356, -0.0707],\n",
      "        [ 0.0740, -0.1194],\n",
      "        [ 0.0326, -0.0861],\n",
      "        [ 0.0525, -0.0220],\n",
      "        [ 0.0164, -0.0526],\n",
      "        [ 0.0423,  0.0032],\n",
      "        [-0.0949, -0.0633],\n",
      "        [-0.0862, -0.0647],\n",
      "        [-0.0915, -0.0737],\n",
      "        [-0.0919, -0.0695],\n",
      "        [-0.0699, -0.1404],\n",
      "        [ 0.0399, -0.0430],\n",
      "        [-0.0306, -0.1668],\n",
      "        [ 0.0053, -0.0880],\n",
      "        [ 0.0284,  0.0018],\n",
      "        [ 0.0046, -0.0215],\n",
      "        [-0.0610, -0.2064],\n",
      "        [-0.0733, -0.0638],\n",
      "        [-0.0094, -0.0773],\n",
      "        [ 0.0052, -0.1208],\n",
      "        [ 0.0012, -0.0445],\n",
      "        [-0.0591, -0.0019],\n",
      "        [ 0.0104,  0.0177],\n",
      "        [ 0.0035, -0.0708],\n",
      "        [-0.0389, -0.0869],\n",
      "        [ 0.0843, -0.0130],\n",
      "        [-0.0963, -0.0618],\n",
      "        [ 0.0177, -0.0911],\n",
      "        [ 0.0346, -0.0272],\n",
      "        [-0.0855, -0.1104],\n",
      "        [ 0.0013, -0.0714],\n",
      "        [-0.0526, -0.0183],\n",
      "        [-0.0433, -0.1051],\n",
      "        [-0.0311, -0.0703],\n",
      "        [-0.0816, -0.1412],\n",
      "        [-0.0813, -0.0692],\n",
      "        [ 0.0158, -0.0249],\n",
      "        [-0.0644, -0.1059],\n",
      "        [ 0.0901, -0.1330],\n",
      "        [-0.0840, -0.0363],\n",
      "        [ 0.0777, -0.0513],\n",
      "        [ 0.0010, -0.1245],\n",
      "        [-0.0933, -0.0619],\n",
      "        [-0.1001, -0.0745],\n",
      "        [ 0.0554, -0.0704],\n",
      "        [-0.0841, -0.0783],\n",
      "        [ 0.0471, -0.0272]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0]\n",
      "train_true_bools [0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
      " 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0]\n",
      "logits:  tensor([[-0.0609, -0.0596],\n",
      "        [ 0.0287, -0.1085],\n",
      "        [ 0.0051, -0.0524],\n",
      "        [-0.0311, -0.1383],\n",
      "        [-0.0896, -0.0609]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 0 1]\n",
      "train_true_bools [1 1 1 0 1]\n",
      "Total training_time took 0.75 minutes \n",
      "training acc 78 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 3\t Train Loss: 0.6930\t  Train ACC: 0.5865\t Val Loss 0.6910\t Val Acc: 0.6119\t Val F1: 45.8333\t Val AUC: 0.6275\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 3.19 minutes\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0770, -0.0659],\n",
      "        [-0.0797, -0.0571],\n",
      "        [-0.0281, -0.1507],\n",
      "        [-0.0244, -0.0721],\n",
      "        [ 0.0554, -0.0775],\n",
      "        [-0.0979, -0.0536],\n",
      "        [-0.0949, -0.0630],\n",
      "        [-0.0885, -0.0536],\n",
      "        [-0.0289,  0.0043],\n",
      "        [ 0.0189, -0.0431],\n",
      "        [ 0.0419, -0.1192],\n",
      "        [-0.0389, -0.0398],\n",
      "        [-0.0497, -0.1015],\n",
      "        [ 0.0162, -0.1478],\n",
      "        [-0.0446, -0.0206],\n",
      "        [-0.0937, -0.0692],\n",
      "        [-0.0380, -0.0320],\n",
      "        [-0.0881, -0.0655],\n",
      "        [-0.0822, -0.0139],\n",
      "        [ 0.0139, -0.0791],\n",
      "        [ 0.0046, -0.0818],\n",
      "        [-0.0675, -0.0560],\n",
      "        [ 0.0037,  0.0207],\n",
      "        [-0.0461, -0.0605],\n",
      "        [ 0.0730, -0.0376],\n",
      "        [ 0.0111, -0.0370],\n",
      "        [-0.0291, -0.1107],\n",
      "        [-0.0136, -0.0013],\n",
      "        [-0.0857, -0.0750],\n",
      "        [-0.0271, -0.1157],\n",
      "        [-0.0895, -0.0659],\n",
      "        [-0.0319, -0.0495],\n",
      "        [-0.0654, -0.0865],\n",
      "        [-0.0722, -0.0933],\n",
      "        [-0.0292, -0.0955],\n",
      "        [-0.0435, -0.0749],\n",
      "        [-0.0625, -0.1304],\n",
      "        [-0.0557, -0.0882],\n",
      "        [-0.0111, -0.0807],\n",
      "        [-0.0576, -0.0279],\n",
      "        [ 0.0379, -0.0899],\n",
      "        [ 0.0215, -0.0275],\n",
      "        [ 0.0345, -0.1214],\n",
      "        [-0.0819, -0.0749],\n",
      "        [-0.0607, -0.0839],\n",
      "        [-0.0908, -0.0645],\n",
      "        [-0.0119, -0.0613],\n",
      "        [-0.0006, -0.1134],\n",
      "        [ 0.0219, -0.0393],\n",
      "        [ 0.0113, -0.0055],\n",
      "        [-0.0966, -0.0563],\n",
      "        [-0.0126, -0.0155],\n",
      "        [-0.0892, -0.0642],\n",
      "        [-0.0049, -0.0249],\n",
      "        [-0.0465, -0.1272],\n",
      "        [-0.0127, -0.0145],\n",
      "        [ 0.0097, -0.0946],\n",
      "        [-0.0655, -0.0038],\n",
      "        [ 0.0614, -0.0591],\n",
      "        [-0.0072, -0.0726],\n",
      "        [-0.0475, -0.1101],\n",
      "        [-0.0401, -0.1376],\n",
      "        [-0.0470, -0.0832],\n",
      "        [-0.0848, -0.0625]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1]\n",
      "train_true_bools [1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1]\n",
      "logits:  tensor([[ 0.0168, -0.0984],\n",
      "        [-0.0856, -0.0577],\n",
      "        [-0.0825, -0.1250],\n",
      "        [-0.0852, -0.0698],\n",
      "        [-0.0540, -0.0768],\n",
      "        [-0.0714, -0.0567],\n",
      "        [-0.0016, -0.1125],\n",
      "        [-0.0346, -0.1077],\n",
      "        [-0.0249, -0.0403],\n",
      "        [-0.0831, -0.0579],\n",
      "        [-0.0477, -0.0727],\n",
      "        [-0.0138, -0.0539],\n",
      "        [-0.0864, -0.0633],\n",
      "        [-0.0313, -0.0433],\n",
      "        [ 0.0003, -0.0900],\n",
      "        [ 0.0323, -0.0235],\n",
      "        [-0.0565, -0.0772],\n",
      "        [ 0.0172, -0.0463],\n",
      "        [-0.0293, -0.1344],\n",
      "        [-0.0440, -0.0555],\n",
      "        [-0.0836, -0.0636],\n",
      "        [-0.0602, -0.0559],\n",
      "        [ 0.0245, -0.1089],\n",
      "        [-0.0081, -0.0932],\n",
      "        [ 0.0250, -0.0011],\n",
      "        [-0.0285, -0.1067],\n",
      "        [-0.0753, -0.0861],\n",
      "        [-0.0294, -0.0764],\n",
      "        [-0.0409, -0.0750],\n",
      "        [-0.0531, -0.0155],\n",
      "        [-0.0112, -0.1003],\n",
      "        [-0.0003, -0.0758],\n",
      "        [-0.0987, -0.0515],\n",
      "        [-0.0183, -0.0906],\n",
      "        [-0.0839, -0.0770],\n",
      "        [ 0.0527, -0.0552],\n",
      "        [ 0.0300, -0.1338],\n",
      "        [-0.0871, -0.0981],\n",
      "        [-0.1137, -0.0778],\n",
      "        [-0.0187, -0.1046],\n",
      "        [-0.0589, -0.0691],\n",
      "        [-0.0545, -0.0628],\n",
      "        [-0.0156,  0.0026],\n",
      "        [ 0.0111, -0.0431],\n",
      "        [ 0.0605, -0.1165],\n",
      "        [ 0.0021, -0.0923],\n",
      "        [-0.0073,  0.0157],\n",
      "        [-0.0243, -0.0668],\n",
      "        [ 0.0307, -0.0655],\n",
      "        [-0.0922, -0.0661],\n",
      "        [-0.0780, -0.1795],\n",
      "        [-0.0063,  0.0030],\n",
      "        [ 0.0695, -0.0921],\n",
      "        [ 0.0210, -0.0468],\n",
      "        [-0.0476, -0.1383],\n",
      "        [-0.0438, -0.0474],\n",
      "        [ 0.0117, -0.0926],\n",
      "        [-0.0739, -0.1281],\n",
      "        [-0.0038, -0.1086],\n",
      "        [-0.0255, -0.0668],\n",
      "        [ 0.0219, -0.0923],\n",
      "        [-0.0227, -0.1105],\n",
      "        [-0.0521, -0.0493],\n",
      "        [-0.0334, -0.0244]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      "train_true_bools [0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0\n",
      " 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0]\n",
      "logits:  tensor([[-0.0769, -0.0441],\n",
      "        [-0.0184, -0.0978],\n",
      "        [-0.0617, -0.0292],\n",
      "        [ 0.0457, -0.0965],\n",
      "        [-0.0145, -0.0847]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 0 0]\n",
      "train_true_bools [1 0 1 1 1]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 85 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 4\t Train Loss: 0.6913\t  Train ACC: 0.6391\t Val Loss 0.6898\t Val Acc: 0.6119\t Val F1: 45.8333\t Val AUC: 0.6266\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 4.26 minutes\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0095, -0.0865],\n",
      "        [-0.0461, -0.0130],\n",
      "        [ 0.0055, -0.0487],\n",
      "        [-0.0026, -0.0829],\n",
      "        [ 0.0069, -0.0912],\n",
      "        [-0.0946, -0.0769],\n",
      "        [ 0.0300,  0.0184],\n",
      "        [-0.0269, -0.1016],\n",
      "        [-0.0956, -0.0637],\n",
      "        [-0.0574, -0.1133],\n",
      "        [ 0.0060,  0.0214],\n",
      "        [-0.0369, -0.1169],\n",
      "        [-0.0324, -0.0654],\n",
      "        [-0.0145, -0.0762],\n",
      "        [-0.0199, -0.0574],\n",
      "        [-0.0903, -0.0633],\n",
      "        [-0.0851, -0.0610],\n",
      "        [ 0.0264, -0.0188],\n",
      "        [-0.0416,  0.0416],\n",
      "        [-0.0643, -0.0652],\n",
      "        [-0.0315, -0.0980],\n",
      "        [-0.0457, -0.0052],\n",
      "        [-0.0162, -0.0330],\n",
      "        [ 0.0248, -0.0559],\n",
      "        [-0.0917, -0.0767],\n",
      "        [ 0.0159, -0.0511],\n",
      "        [-0.0353, -0.0952],\n",
      "        [-0.1100, -0.0212],\n",
      "        [-0.0103, -0.0158],\n",
      "        [ 0.0201, -0.0330],\n",
      "        [ 0.0221, -0.0729],\n",
      "        [ 0.0223, -0.0110],\n",
      "        [-0.0046,  0.0184],\n",
      "        [-0.0042,  0.0050],\n",
      "        [-0.0138, -0.0850],\n",
      "        [-0.0214, -0.0076],\n",
      "        [-0.0566, -0.0391],\n",
      "        [-0.0590, -0.0605],\n",
      "        [-0.0929, -0.1072],\n",
      "        [-0.0225, -0.0763],\n",
      "        [-0.0325, -0.0451],\n",
      "        [-0.1055, -0.0466],\n",
      "        [ 0.0045, -0.1100],\n",
      "        [-0.0874, -0.0650],\n",
      "        [-0.0633, -0.1093],\n",
      "        [-0.0928, -0.1285],\n",
      "        [-0.0983, -0.0012],\n",
      "        [-0.0192, -0.0554],\n",
      "        [-0.0805, -0.0603],\n",
      "        [-0.0475, -0.0230],\n",
      "        [-0.0869, -0.0589],\n",
      "        [-0.0648, -0.0886],\n",
      "        [-0.0067, -0.0156],\n",
      "        [-0.0118,  0.0130],\n",
      "        [-0.0599, -0.0581],\n",
      "        [-0.0511, -0.0622],\n",
      "        [-0.0454, -0.0628],\n",
      "        [-0.0875, -0.0551],\n",
      "        [-0.0916, -0.0739],\n",
      "        [-0.1044, -0.0948],\n",
      "        [-0.0438, -0.0317],\n",
      "        [-0.0409, -0.0805],\n",
      "        [-0.0721, -0.0633],\n",
      "        [ 0.0188, -0.0448]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1\n",
      " 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0]\n",
      "train_true_bools [0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0]\n",
      "logits:  tensor([[-5.2213e-02, -4.1755e-02],\n",
      "        [-9.1787e-02, -6.3629e-02],\n",
      "        [ 4.6654e-03, -2.4249e-02],\n",
      "        [-1.0478e-01, -1.0054e-01],\n",
      "        [ 1.5753e-03, -5.1009e-02],\n",
      "        [-1.3611e-02, -5.8074e-03],\n",
      "        [-5.8175e-02, -2.8873e-02],\n",
      "        [-5.7561e-03, -1.2277e-01],\n",
      "        [-3.3676e-02, -1.0032e-02],\n",
      "        [ 1.7579e-02, -6.8070e-02],\n",
      "        [-5.4710e-02, -4.5036e-02],\n",
      "        [-1.2665e-02, -1.1304e-01],\n",
      "        [-1.3839e-03, -1.8085e-02],\n",
      "        [-1.9395e-02, -1.0730e-01],\n",
      "        [-1.2429e-02, -1.4122e-01],\n",
      "        [-3.6055e-02, -7.8037e-02],\n",
      "        [ 5.8296e-03, -9.3127e-02],\n",
      "        [-1.3291e-02,  3.1901e-03],\n",
      "        [-8.8309e-02, -6.0260e-02],\n",
      "        [-7.1404e-02, -8.7780e-02],\n",
      "        [-4.8344e-03, -3.9409e-02],\n",
      "        [-8.0211e-02, -5.2842e-02],\n",
      "        [ 4.0141e-02, -8.9794e-02],\n",
      "        [-8.5723e-02, -6.4212e-02],\n",
      "        [-5.3601e-02, -2.7164e-02],\n",
      "        [-1.9163e-03, -6.4564e-02],\n",
      "        [-9.3702e-02, -7.6031e-02],\n",
      "        [-8.0160e-02, -2.3802e-02],\n",
      "        [-7.0436e-02, -3.8581e-02],\n",
      "        [-7.0990e-02, -3.9746e-02],\n",
      "        [ 6.3536e-02, -1.0023e-01],\n",
      "        [-1.6141e-02,  2.5842e-03],\n",
      "        [-5.1897e-02, -8.7970e-02],\n",
      "        [-6.0508e-02, -1.7810e-02],\n",
      "        [-2.2602e-02, -6.1476e-02],\n",
      "        [-1.1393e-01, -1.2071e-02],\n",
      "        [ 3.7359e-03,  4.7327e-02],\n",
      "        [ 2.3555e-02, -7.3786e-02],\n",
      "        [-6.4762e-02, -5.3166e-02],\n",
      "        [ 1.3428e-02, -4.6807e-02],\n",
      "        [-9.2985e-02, -6.7199e-02],\n",
      "        [-9.2288e-02, -6.5619e-02],\n",
      "        [ 1.0128e-02, -7.1971e-02],\n",
      "        [-5.1080e-02, -1.0438e-01],\n",
      "        [-7.1658e-02, -1.1080e-01],\n",
      "        [-3.4222e-02, -2.3881e-02],\n",
      "        [-1.0613e-01, -4.9378e-02],\n",
      "        [-7.1795e-02, -4.8553e-02],\n",
      "        [-6.3031e-02, -5.9632e-02],\n",
      "        [-2.4401e-02, -1.4015e-01],\n",
      "        [ 2.6714e-02, -6.0436e-02],\n",
      "        [-5.0303e-03, -1.3586e-02],\n",
      "        [-9.1146e-02, -5.6351e-02],\n",
      "        [-1.3519e-01, -9.5608e-02],\n",
      "        [-8.1334e-02, -1.3071e-01],\n",
      "        [ 2.8677e-05, -8.0825e-02],\n",
      "        [ 2.2754e-02,  2.1526e-03],\n",
      "        [-9.3549e-02, -7.0866e-02],\n",
      "        [-6.1233e-02, -6.6766e-02],\n",
      "        [-4.4453e-02, -4.6325e-02],\n",
      "        [-4.4175e-02, -5.7718e-02],\n",
      "        [-3.0660e-02, -7.3146e-02],\n",
      "        [-6.4110e-02, -9.5899e-02],\n",
      "        [-8.9149e-02,  6.1447e-03]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1]\n",
      "train_true_bools [0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 1]\n",
      "logits:  tensor([[-0.0619, -0.0117],\n",
      "        [-0.0466, -0.0489],\n",
      "        [-0.0555, -0.0539],\n",
      "        [ 0.0033, -0.0630],\n",
      "        [-0.0084, -0.0438]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 0 0]\n",
      "train_true_bools [1 1 0 1 0]\n",
      "Total training_time took 0.77 minutes \n",
      "training acc 83 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 5\t Train Loss: 0.6899\t  Train ACC: 0.6241\t Val Loss 0.6914\t Val Acc: 0.5821\t Val F1: 48.1481\t Val AUC: 0.6257\n",
      "Total val_time took 0.33 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 5.36 minutes\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0694,  0.0265],\n",
      "        [-0.0749, -0.0471],\n",
      "        [-0.0290, -0.0620],\n",
      "        [-0.0750, -0.0554],\n",
      "        [-0.0601, -0.0426],\n",
      "        [-0.0777, -0.0608],\n",
      "        [-0.0892, -0.0532],\n",
      "        [-0.0752, -0.0656],\n",
      "        [ 0.0528, -0.1142],\n",
      "        [-0.0967, -0.0612],\n",
      "        [-0.0666, -0.0679],\n",
      "        [-0.0373, -0.0305],\n",
      "        [-0.0832, -0.0986],\n",
      "        [-0.0530, -0.0473],\n",
      "        [ 0.0319, -0.0856],\n",
      "        [-0.0949, -0.0630],\n",
      "        [-0.0343, -0.0178],\n",
      "        [-0.0738, -0.0662],\n",
      "        [ 0.0132,  0.0121],\n",
      "        [-0.0352, -0.0947],\n",
      "        [-0.0895, -0.0537],\n",
      "        [-0.0661, -0.0613],\n",
      "        [-0.0901, -0.0260],\n",
      "        [-0.0566,  0.0068],\n",
      "        [ 0.0099, -0.0438],\n",
      "        [-0.0672, -0.0115],\n",
      "        [-0.0612, -0.0721],\n",
      "        [-0.0207, -0.0478],\n",
      "        [-0.0874, -0.0536],\n",
      "        [-0.0227, -0.1044],\n",
      "        [-0.0826, -0.0575],\n",
      "        [-0.0472, -0.0626],\n",
      "        [-0.0407, -0.0764],\n",
      "        [ 0.0309, -0.1253],\n",
      "        [-0.0838, -0.1105],\n",
      "        [-0.0460, -0.0448],\n",
      "        [-0.0300, -0.0643],\n",
      "        [-0.0977, -0.0799],\n",
      "        [-0.0493,  0.0231],\n",
      "        [-0.1001, -0.0670],\n",
      "        [-0.0169, -0.0699],\n",
      "        [-0.0186, -0.0009],\n",
      "        [-0.0873, -0.0589],\n",
      "        [ 0.0072, -0.0461],\n",
      "        [-0.0451, -0.0112],\n",
      "        [-0.0201, -0.0519],\n",
      "        [-0.0487, -0.0741],\n",
      "        [-0.0012, -0.1006],\n",
      "        [-0.0446, -0.0611],\n",
      "        [-0.0429, -0.0009],\n",
      "        [-0.0827, -0.0669],\n",
      "        [-0.0880, -0.0551],\n",
      "        [-0.0254, -0.0874],\n",
      "        [-0.0249, -0.0538],\n",
      "        [-0.0224, -0.0110],\n",
      "        [-0.0198, -0.0580],\n",
      "        [-0.0030,  0.0100],\n",
      "        [-0.1256, -0.0742],\n",
      "        [-0.0148, -0.0924],\n",
      "        [-0.0713, -0.0497],\n",
      "        [-0.0149, -0.0773],\n",
      "        [-0.0821, -0.0665],\n",
      "        [-0.0272, -0.0387],\n",
      "        [-0.0776, -0.0593]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0\n",
      " 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1]\n",
      "train_true_bools [1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1]\n",
      "logits:  tensor([[-5.7326e-02, -3.9505e-02],\n",
      "        [-3.4412e-02, -3.6542e-02],\n",
      "        [-2.7981e-02, -5.4454e-03],\n",
      "        [-9.9140e-02, -6.6849e-02],\n",
      "        [-4.8301e-02, -9.2160e-02],\n",
      "        [ 2.7386e-03, -6.9767e-02],\n",
      "        [-4.7274e-02,  4.3883e-02],\n",
      "        [-6.4003e-02, -4.2546e-02],\n",
      "        [-2.1418e-02, -1.0257e-01],\n",
      "        [-8.6078e-02, -1.2655e-02],\n",
      "        [-8.5902e-02, -5.4427e-02],\n",
      "        [-4.1010e-02, -4.3381e-02],\n",
      "        [-8.8773e-02, -4.2609e-02],\n",
      "        [ 8.6616e-03, -5.3020e-02],\n",
      "        [-9.0861e-02,  1.6705e-02],\n",
      "        [ 1.3411e-02, -5.8027e-02],\n",
      "        [-1.0091e-01, -6.5194e-02],\n",
      "        [ 2.0010e-02, -4.1304e-02],\n",
      "        [-7.4628e-02, -1.0255e-02],\n",
      "        [-5.3594e-03, -2.8491e-02],\n",
      "        [-5.5975e-02, -8.7559e-02],\n",
      "        [-9.7871e-03, -1.0732e-01],\n",
      "        [ 3.6883e-02, -4.7741e-02],\n",
      "        [-1.1503e-01,  7.2353e-03],\n",
      "        [-7.5179e-02, -2.4181e-02],\n",
      "        [ 4.8671e-02, -1.0996e-03],\n",
      "        [-6.8396e-03, -5.7647e-02],\n",
      "        [-1.1185e-01, -7.1349e-02],\n",
      "        [-4.7500e-02, -8.7967e-02],\n",
      "        [-3.6827e-02, -7.5629e-02],\n",
      "        [-5.1075e-02, -5.9119e-02],\n",
      "        [-1.3073e-02, -6.0948e-02],\n",
      "        [ 4.6686e-02,  3.6841e-02],\n",
      "        [-2.1341e-02, -7.3853e-03],\n",
      "        [-1.2471e-02, -1.3836e-02],\n",
      "        [-5.9294e-02, -3.3590e-02],\n",
      "        [-7.9128e-02, -5.2372e-02],\n",
      "        [ 2.8411e-02, -6.2136e-02],\n",
      "        [-1.3058e-01, -6.5322e-02],\n",
      "        [-5.4661e-02, -2.2923e-02],\n",
      "        [-3.5918e-02, -9.2105e-02],\n",
      "        [-7.6971e-02, -5.9585e-02],\n",
      "        [-7.7293e-02, -6.4872e-02],\n",
      "        [-2.9157e-02, -3.4741e-02],\n",
      "        [-2.3788e-02,  4.4433e-02],\n",
      "        [-6.3775e-02, -9.6071e-02],\n",
      "        [-7.0409e-02, -3.6126e-02],\n",
      "        [-1.5565e-02,  1.3368e-02],\n",
      "        [-5.2423e-02, -1.2202e-01],\n",
      "        [-6.7959e-02, -1.0628e-01],\n",
      "        [ 1.1295e-02, -6.9175e-02],\n",
      "        [-1.5057e-02,  8.7952e-03],\n",
      "        [ 1.0020e-04, -6.2248e-02],\n",
      "        [-8.3560e-02, -6.9964e-02],\n",
      "        [ 7.6048e-03, -4.1066e-03],\n",
      "        [-7.5676e-02, -1.3326e-01],\n",
      "        [-9.2532e-02, -1.7534e-02],\n",
      "        [-8.7697e-02, -7.5951e-02],\n",
      "        [-2.2486e-02, -2.8932e-02],\n",
      "        [ 3.0060e-02, -1.0885e-02],\n",
      "        [ 6.0639e-03, -1.9503e-02],\n",
      "        [ 2.7357e-02, -5.3812e-02],\n",
      "        [-5.7709e-02, -7.3480e-02],\n",
      "        [-3.8046e-02, -7.9983e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1\n",
      " 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0]\n",
      "train_true_bools [1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 0]\n",
      "logits:  tensor([[-0.1003,  0.0247],\n",
      "        [-0.0706, -0.0817],\n",
      "        [-0.0002, -0.0167],\n",
      "        [ 0.0285, -0.0131],\n",
      "        [ 0.0063, -0.0075]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 0 0]\n",
      "train_true_bools [1 0 1 1 1]\n",
      "Total training_time took 0.77 minutes \n",
      "training acc 90 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 6\t Train Loss: 0.6886\t  Train ACC: 0.6767\t Val Loss 0.6929\t Val Acc: 0.6269\t Val F1: 62.6866\t Val AUC: 0.6070\n",
      "Total val_time took 0.33 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 6.45 minutes\n",
      "\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0117, -0.0691],\n",
      "        [-0.0176, -0.0252],\n",
      "        [-0.0930, -0.0590],\n",
      "        [-0.0494, -0.0859],\n",
      "        [-0.0443, -0.0589],\n",
      "        [-0.0750, -0.0769],\n",
      "        [-0.0521,  0.0657],\n",
      "        [-0.0567, -0.1012],\n",
      "        [-0.0292, -0.0806],\n",
      "        [-0.0117, -0.1112],\n",
      "        [-0.0124, -0.0231],\n",
      "        [ 0.0241, -0.0632],\n",
      "        [-0.0862, -0.0619],\n",
      "        [-0.0126, -0.0531],\n",
      "        [-0.0844,  0.0216],\n",
      "        [-0.0446, -0.0999],\n",
      "        [-0.0542, -0.0490],\n",
      "        [-0.0971, -0.0214],\n",
      "        [-0.0950, -0.0721],\n",
      "        [-0.0830, -0.0594],\n",
      "        [-0.0670,  0.0310],\n",
      "        [-0.0604, -0.0057],\n",
      "        [-0.0266, -0.0740],\n",
      "        [ 0.0064, -0.0347],\n",
      "        [-0.0821, -0.1274],\n",
      "        [-0.1260, -0.0494],\n",
      "        [-0.0194,  0.0059],\n",
      "        [-0.0207, -0.0177],\n",
      "        [ 0.0186, -0.0457],\n",
      "        [-0.0137, -0.0918],\n",
      "        [-0.0124, -0.0220],\n",
      "        [-0.1004, -0.0292],\n",
      "        [ 0.0005, -0.0184],\n",
      "        [-0.0854, -0.0067],\n",
      "        [-0.0655, -0.0471],\n",
      "        [-0.1008, -0.0639],\n",
      "        [ 0.0387, -0.0209],\n",
      "        [-0.0426, -0.0389],\n",
      "        [-0.0361, -0.0518],\n",
      "        [-0.0426, -0.0426],\n",
      "        [ 0.0091, -0.0061],\n",
      "        [-0.0376, -0.1287],\n",
      "        [-0.0224, -0.0419],\n",
      "        [-0.0725, -0.0653],\n",
      "        [ 0.0203, -0.0602],\n",
      "        [-0.0953, -0.1034],\n",
      "        [-0.0570, -0.0578],\n",
      "        [-0.0733, -0.0544],\n",
      "        [-0.0304, -0.0624],\n",
      "        [-0.0814, -0.1282],\n",
      "        [-0.0439, -0.0689],\n",
      "        [-0.0846, -0.0550],\n",
      "        [-0.0010, -0.0353],\n",
      "        [-0.0012, -0.0443],\n",
      "        [-0.0457, -0.0481],\n",
      "        [-0.0139, -0.0811],\n",
      "        [-0.0835, -0.0576],\n",
      "        [-0.0263, -0.0292],\n",
      "        [-0.0438, -0.0472],\n",
      "        [-0.0130, -0.0492],\n",
      "        [-0.0578, -0.0103],\n",
      "        [-0.0345, -0.0978],\n",
      "        [-0.0678,  0.0273],\n",
      "        [-0.0977, -0.0688]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0\n",
      " 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1]\n",
      "train_true_bools [0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0\n",
      " 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1]\n",
      "logits:  tensor([[ 0.0302, -0.0015],\n",
      "        [ 0.0019, -0.0742],\n",
      "        [-0.0299, -0.0676],\n",
      "        [-0.0754, -0.0280],\n",
      "        [-0.0581, -0.0695],\n",
      "        [-0.0941, -0.0624],\n",
      "        [-0.0205, -0.0916],\n",
      "        [-0.0878, -0.0564],\n",
      "        [-0.0663, -0.0929],\n",
      "        [-0.0522, -0.0646],\n",
      "        [-0.0787, -0.0501],\n",
      "        [-0.0584,  0.0093],\n",
      "        [-0.0960, -0.0637],\n",
      "        [-0.0549, -0.0484],\n",
      "        [-0.0746, -0.0741],\n",
      "        [-0.0658, -0.0521],\n",
      "        [-0.0759, -0.0620],\n",
      "        [-0.0171, -0.0783],\n",
      "        [-0.0379, -0.0368],\n",
      "        [-0.0796, -0.0220],\n",
      "        [-0.0498, -0.0493],\n",
      "        [-0.0411, -0.0143],\n",
      "        [-0.0335, -0.0319],\n",
      "        [-0.0060,  0.0216],\n",
      "        [-0.0976, -0.1609],\n",
      "        [-0.1198,  0.0066],\n",
      "        [-0.0753,  0.0237],\n",
      "        [-0.0224, -0.0578],\n",
      "        [-0.1363, -0.0630],\n",
      "        [-0.1007, -0.0863],\n",
      "        [-0.0404, -0.0536],\n",
      "        [-0.0250, -0.0185],\n",
      "        [ 0.0154, -0.0330],\n",
      "        [-0.0661, -0.0301],\n",
      "        [-0.0908, -0.0604],\n",
      "        [-0.0696,  0.0106],\n",
      "        [-0.1084, -0.0540],\n",
      "        [-0.0958, -0.0925],\n",
      "        [-0.0725,  0.0017],\n",
      "        [-0.0134,  0.0071],\n",
      "        [-0.0467, -0.0515],\n",
      "        [-0.0697,  0.0135],\n",
      "        [-0.0691, -0.0125],\n",
      "        [ 0.0006, -0.0189],\n",
      "        [-0.0797,  0.0140],\n",
      "        [-0.0029, -0.0301],\n",
      "        [-0.1011, -0.0636],\n",
      "        [-0.0370, -0.0189],\n",
      "        [-0.0249, -0.0500],\n",
      "        [-0.0864, -0.0602],\n",
      "        [ 0.0123, -0.0881],\n",
      "        [-0.0563, -0.1066],\n",
      "        [-0.0614, -0.0392],\n",
      "        [-0.0833, -0.0544],\n",
      "        [-0.0228, -0.0542],\n",
      "        [-0.0184,  0.0387],\n",
      "        [-0.0378, -0.0816],\n",
      "        [-0.0316, -0.0342],\n",
      "        [ 0.0086, -0.0862],\n",
      "        [-0.1204, -0.0876],\n",
      "        [-0.1038, -0.0203],\n",
      "        [-0.0036, -0.0388],\n",
      "        [ 0.0059, -0.0605],\n",
      "        [-0.0066, -0.0420]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 0]\n",
      "train_true_bools [0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1\n",
      " 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1]\n",
      "logits:  tensor([[-0.1271,  0.0098],\n",
      "        [-0.0968, -0.0667],\n",
      "        [-0.0537, -0.0255],\n",
      "        [-0.0108, -0.0737],\n",
      "        [-0.0815, -0.0349]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 0 1]\n",
      "train_true_bools [1 1 1 0 1]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 100 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 7\t Train Loss: 0.6842\t  Train ACC: 0.7519\t Val Loss 0.6923\t Val Acc: 0.5821\t Val F1: 64.1026\t Val AUC: 0.5989\n",
      "Total val_time took 0.30 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 7.52 minutes\n",
      "\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0613, -0.0854],\n",
      "        [ 0.0212, -0.0556],\n",
      "        [-0.1206, -0.0488],\n",
      "        [ 0.0232, -0.0054],\n",
      "        [-0.0372, -0.0949],\n",
      "        [-0.0760, -0.0969],\n",
      "        [-0.0243, -0.0415],\n",
      "        [-0.0395, -0.0957],\n",
      "        [-0.0095, -0.0921],\n",
      "        [ 0.0131, -0.0846],\n",
      "        [-0.1309, -0.0644],\n",
      "        [-0.0497, -0.0971],\n",
      "        [-0.1246, -0.0182],\n",
      "        [-0.0268, -0.0281],\n",
      "        [-0.0834, -0.0559],\n",
      "        [-0.0696, -0.0711],\n",
      "        [-0.0498, -0.1180],\n",
      "        [-0.0051,  0.0307],\n",
      "        [-0.0122, -0.0429],\n",
      "        [-0.0578, -0.0651],\n",
      "        [-0.0263, -0.0211],\n",
      "        [-0.0892, -0.0046],\n",
      "        [-0.0982, -0.0147],\n",
      "        [-0.0421, -0.0807],\n",
      "        [-0.0259, -0.0340],\n",
      "        [-0.0906, -0.0546],\n",
      "        [ 0.0129, -0.0834],\n",
      "        [-0.0651, -0.0906],\n",
      "        [-0.0454, -0.0081],\n",
      "        [-0.0648, -0.0518],\n",
      "        [-0.0456, -0.0206],\n",
      "        [-0.0795,  0.0099],\n",
      "        [-0.0316,  0.0046],\n",
      "        [-0.0166, -0.0594],\n",
      "        [-0.0848, -0.0627],\n",
      "        [-0.0859, -0.0560],\n",
      "        [-0.0246, -0.0375],\n",
      "        [-0.0411, -0.1299],\n",
      "        [-0.0296, -0.0268],\n",
      "        [-0.0551,  0.0057],\n",
      "        [-0.1404, -0.0231],\n",
      "        [-0.0835, -0.0574],\n",
      "        [-0.0228, -0.0193],\n",
      "        [-0.0281, -0.1379],\n",
      "        [-0.0824, -0.0578],\n",
      "        [ 0.0202, -0.0262],\n",
      "        [-0.0928, -0.0459],\n",
      "        [-0.0633, -0.0542],\n",
      "        [ 0.0070, -0.0222],\n",
      "        [-0.0110, -0.0065],\n",
      "        [-0.0260, -0.0157],\n",
      "        [-0.0444, -0.0645],\n",
      "        [-0.0155, -0.0366],\n",
      "        [-0.0397, -0.0453],\n",
      "        [-0.0371, -0.0083],\n",
      "        [-0.0737, -0.0486],\n",
      "        [-0.0581, -0.0890],\n",
      "        [ 0.0282, -0.0353],\n",
      "        [-0.0038, -0.0820],\n",
      "        [-0.0314, -0.0064],\n",
      "        [-0.0560, -0.0356],\n",
      "        [ 0.0313, -0.0759],\n",
      "        [-0.0507, -0.0114],\n",
      "        [-0.1068, -0.0668]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0\n",
      " 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1]\n",
      "train_true_bools [1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1]\n",
      "logits:  tensor([[-0.0396, -0.0228],\n",
      "        [-0.0816, -0.0425],\n",
      "        [-0.0198, -0.0882],\n",
      "        [ 0.0401, -0.0746],\n",
      "        [ 0.0285, -0.0903],\n",
      "        [-0.0245, -0.0720],\n",
      "        [-0.0431,  0.0230],\n",
      "        [-0.0326, -0.0977],\n",
      "        [-0.0492, -0.0848],\n",
      "        [-0.0216, -0.0470],\n",
      "        [ 0.0113, -0.0777],\n",
      "        [ 0.0092, -0.0546],\n",
      "        [-0.0321, -0.0193],\n",
      "        [-0.0773, -0.0581],\n",
      "        [ 0.0373, -0.0637],\n",
      "        [-0.0223, -0.0361],\n",
      "        [-0.0295, -0.0396],\n",
      "        [-0.0271, -0.0077],\n",
      "        [-0.0788, -0.0169],\n",
      "        [-0.0016, -0.0946],\n",
      "        [-0.0290, -0.0671],\n",
      "        [-0.0165, -0.0092],\n",
      "        [ 0.0433,  0.0030],\n",
      "        [-0.0501, -0.0383],\n",
      "        [-0.0756, -0.0417],\n",
      "        [-0.0946, -0.0548],\n",
      "        [-0.0792, -0.0720],\n",
      "        [-0.0257, -0.0796],\n",
      "        [-0.0069, -0.0424],\n",
      "        [-0.0611, -0.0308],\n",
      "        [-0.0520, -0.0322],\n",
      "        [ 0.0248, -0.0665],\n",
      "        [-0.0004, -0.1072],\n",
      "        [-0.0414, -0.0222],\n",
      "        [-0.0931, -0.0511],\n",
      "        [-0.0288, -0.0127],\n",
      "        [-0.0344, -0.0055],\n",
      "        [-0.0773, -0.0544],\n",
      "        [-0.0470, -0.0355],\n",
      "        [-0.0257,  0.0070],\n",
      "        [-0.0781, -0.0274],\n",
      "        [-0.0397, -0.0636],\n",
      "        [-0.0496, -0.0534],\n",
      "        [-0.0243, -0.0433],\n",
      "        [-0.0978, -0.0652],\n",
      "        [-0.0380, -0.0549],\n",
      "        [-0.0221, -0.0760],\n",
      "        [-0.0807, -0.0369],\n",
      "        [-0.1002, -0.1094],\n",
      "        [-0.0882, -0.0679],\n",
      "        [-0.1055, -0.0633],\n",
      "        [-0.0737, -0.0487],\n",
      "        [-0.0444, -0.0059],\n",
      "        [-0.0002, -0.0519],\n",
      "        [-0.0635, -0.0769],\n",
      "        [-0.0770, -0.0660],\n",
      "        [-0.0903, -0.0583],\n",
      "        [-0.0452,  0.0275],\n",
      "        [-0.0639, -0.0899],\n",
      "        [-0.1027, -0.0943],\n",
      "        [-0.0681, -0.0052],\n",
      "        [ 0.0449,  0.0029],\n",
      "        [-0.0603, -0.1022],\n",
      "        [-0.0823, -0.0416]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1]\n",
      "train_true_bools [1 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0]\n",
      "logits:  tensor([[-0.1023, -0.0345],\n",
      "        [-0.0669, -0.0817],\n",
      "        [-0.0003, -0.0422],\n",
      "        [-0.1335, -0.0439],\n",
      "        [-0.0289, -0.0256]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 1 1]\n",
      "train_true_bools [1 1 1 1 1]\n",
      "Total training_time took 0.75 minutes \n",
      "training acc 92 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 8\t Train Loss: 0.6882\t  Train ACC: 0.6917\t Val Loss 0.6940\t Val Acc: 0.5224\t Val F1: 62.7907\t Val AUC: 0.5909\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 8.58 minutes\n",
      "\n",
      "======== Epoch 9 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0238,  0.0020],\n",
      "        [ 0.0153, -0.0603],\n",
      "        [-0.0324, -0.0331],\n",
      "        [-0.0528, -0.0069],\n",
      "        [-0.0509, -0.0590],\n",
      "        [-0.1003, -0.0303],\n",
      "        [ 0.0039, -0.0812],\n",
      "        [-0.0123, -0.0665],\n",
      "        [-0.0892, -0.0539],\n",
      "        [-0.0929, -0.0666],\n",
      "        [-0.0757, -0.0345],\n",
      "        [-0.0906, -0.0447],\n",
      "        [ 0.0095, -0.0043],\n",
      "        [-0.0359, -0.0875],\n",
      "        [ 0.0033, -0.0599],\n",
      "        [-0.0334, -0.0894],\n",
      "        [-0.0914,  0.0194],\n",
      "        [ 0.1031, -0.0685],\n",
      "        [-0.0310, -0.0443],\n",
      "        [-0.0908, -0.0502],\n",
      "        [-0.0031, -0.0137],\n",
      "        [-0.0981, -0.0634],\n",
      "        [-0.0935, -0.0574],\n",
      "        [-0.0348, -0.0096],\n",
      "        [-0.0038, -0.0166],\n",
      "        [-0.1217,  0.0028],\n",
      "        [-0.0559, -0.0846],\n",
      "        [-0.0625, -0.0071],\n",
      "        [-0.0067, -0.0278],\n",
      "        [-0.0489, -0.0570],\n",
      "        [-0.1167, -0.0465],\n",
      "        [-0.0881,  0.0213],\n",
      "        [-0.0917, -0.0599],\n",
      "        [-0.0060, -0.0143],\n",
      "        [-0.0175, -0.0421],\n",
      "        [-0.0070,  0.0001],\n",
      "        [-0.0267, -0.0347],\n",
      "        [-0.0557, -0.0173],\n",
      "        [-0.0833, -0.0556],\n",
      "        [-0.0962, -0.0641],\n",
      "        [-0.1006, -0.0529],\n",
      "        [-0.0266, -0.0511],\n",
      "        [ 0.0294, -0.0653],\n",
      "        [-0.0343, -0.0759],\n",
      "        [-0.0446, -0.1049],\n",
      "        [-0.0113, -0.0669],\n",
      "        [-0.0463, -0.0271],\n",
      "        [ 0.0257, -0.0283],\n",
      "        [ 0.0166,  0.0685],\n",
      "        [-0.0880, -0.0563],\n",
      "        [ 0.0065, -0.0527],\n",
      "        [-0.0358, -0.0574],\n",
      "        [-0.0859, -0.0599],\n",
      "        [-0.0771, -0.0842],\n",
      "        [-0.0622, -0.0568],\n",
      "        [-0.0348, -0.0494],\n",
      "        [-0.0805, -0.1102],\n",
      "        [-0.0273,  0.0347],\n",
      "        [-0.0741, -0.0058],\n",
      "        [-0.0458, -0.0319],\n",
      "        [-0.0023, -0.0326],\n",
      "        [-0.0700, -0.0434],\n",
      "        [-0.0810,  0.0218],\n",
      "        [-0.0471,  0.0016]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0\n",
      " 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1]\n",
      "train_true_bools [1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1]\n",
      "logits:  tensor([[-0.0698, -0.0343],\n",
      "        [-0.0259, -0.1064],\n",
      "        [-0.0187, -0.0079],\n",
      "        [ 0.0061, -0.0253],\n",
      "        [-0.0344,  0.0819],\n",
      "        [-0.0924, -0.0559],\n",
      "        [-0.0502, -0.1353],\n",
      "        [-0.0410, -0.0055],\n",
      "        [-0.0566,  0.0588],\n",
      "        [-0.0873, -0.0686],\n",
      "        [ 0.0016, -0.0875],\n",
      "        [-0.0058,  0.0034],\n",
      "        [ 0.0079, -0.0105],\n",
      "        [-0.0096, -0.0595],\n",
      "        [-0.0174,  0.0147],\n",
      "        [-0.0865, -0.0658],\n",
      "        [-0.0317, -0.0664],\n",
      "        [-0.0022, -0.0537],\n",
      "        [ 0.0003, -0.0343],\n",
      "        [-0.0159, -0.0650],\n",
      "        [-0.0402,  0.0011],\n",
      "        [-0.0289, -0.0596],\n",
      "        [-0.0306,  0.0066],\n",
      "        [-0.0306, -0.0187],\n",
      "        [-0.0494, -0.0455],\n",
      "        [-0.0527,  0.0047],\n",
      "        [-0.0515, -0.0290],\n",
      "        [-0.0404, -0.0085],\n",
      "        [-0.0520, -0.0410],\n",
      "        [-0.0525, -0.0973],\n",
      "        [-0.0807, -0.0614],\n",
      "        [-0.0865, -0.0553],\n",
      "        [-0.0692, -0.0573],\n",
      "        [-0.0868, -0.0476],\n",
      "        [-0.0464, -0.0266],\n",
      "        [-0.0527,  0.0018],\n",
      "        [-0.0912, -0.0611],\n",
      "        [-0.0292, -0.0042],\n",
      "        [-0.0424,  0.0195],\n",
      "        [-0.0611, -0.0397],\n",
      "        [-0.0250, -0.0361],\n",
      "        [-0.0511,  0.0035],\n",
      "        [-0.1121, -0.0157],\n",
      "        [-0.0314, -0.0718],\n",
      "        [-0.1192, -0.0455],\n",
      "        [ 0.0417,  0.0178],\n",
      "        [-0.0976, -0.0127],\n",
      "        [ 0.0671, -0.0773],\n",
      "        [-0.0864, -0.0473],\n",
      "        [-0.0357,  0.0850],\n",
      "        [-0.0416, -0.0113],\n",
      "        [-0.0222, -0.0489],\n",
      "        [-0.1259, -0.0558],\n",
      "        [-0.0414,  0.0527],\n",
      "        [-0.0614, -0.0667],\n",
      "        [-0.0021, -0.0352],\n",
      "        [-0.0644, -0.0715],\n",
      "        [-0.0398,  0.0373],\n",
      "        [-0.0537, -0.0110],\n",
      "        [-0.0882, -0.0015],\n",
      "        [-0.0539, -0.0764],\n",
      "        [-0.0943, -0.0541],\n",
      "        [-0.0806, -0.0581],\n",
      "        [-0.0517,  0.0312]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 0 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1]\n",
      "train_true_bools [1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 1\n",
      " 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1]\n",
      "logits:  tensor([[-0.0852, -0.0177],\n",
      "        [-0.0392,  0.0209],\n",
      "        [-0.0643, -0.0525],\n",
      "        [-0.0466, -0.0218],\n",
      "        [-0.0310, -0.0446]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 1 0]\n",
      "train_true_bools [1 1 1 0 0]\n",
      "Total training_time took 0.74 minutes \n",
      "training acc 97 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 9\t Train Loss: 0.6865\t  Train ACC: 0.7293\t Val Loss 0.6921\t Val Acc: 0.5373\t Val F1: 65.9341\t Val AUC: 0.5784\n",
      "Total val_time took 0.31 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 9.64 minutes\n",
      "\n",
      "======== Epoch 10 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-3.8744e-02, -2.9242e-03],\n",
      "        [-8.3431e-02, -4.7888e-02],\n",
      "        [ 1.9986e-02,  8.9820e-03],\n",
      "        [-7.6587e-02, -4.5855e-02],\n",
      "        [ 3.6781e-02,  3.7432e-02],\n",
      "        [-4.5213e-02, -9.0458e-02],\n",
      "        [-4.1052e-02, -5.2259e-02],\n",
      "        [-2.4111e-02, -4.6240e-02],\n",
      "        [-2.5840e-02, -2.7473e-02],\n",
      "        [-4.6507e-02, -3.8279e-02],\n",
      "        [-5.8533e-02, -8.5979e-03],\n",
      "        [-9.8044e-03, -2.7452e-02],\n",
      "        [-9.2923e-02, -5.4143e-02],\n",
      "        [-1.0211e-02, -1.0053e-01],\n",
      "        [-5.7957e-02, -1.2407e-01],\n",
      "        [-9.4758e-02, -5.4252e-02],\n",
      "        [-9.7978e-04,  1.5618e-02],\n",
      "        [-1.0340e-02, -7.7166e-02],\n",
      "        [-8.6642e-02, -1.5921e-02],\n",
      "        [-7.9158e-02, -5.4306e-02],\n",
      "        [ 5.1773e-03,  4.1756e-02],\n",
      "        [-1.5990e-02,  5.0664e-02],\n",
      "        [-8.2567e-02, -5.7785e-02],\n",
      "        [-5.5300e-03, -4.4980e-02],\n",
      "        [-2.9461e-02, -8.0236e-02],\n",
      "        [-8.5741e-02, -6.7994e-02],\n",
      "        [-9.9378e-02,  4.1907e-02],\n",
      "        [-4.5142e-02, -2.7507e-02],\n",
      "        [-3.4829e-02, -7.5549e-02],\n",
      "        [ 3.5759e-02,  2.6678e-02],\n",
      "        [-1.8443e-02,  1.8384e-03],\n",
      "        [-1.4001e-02, -3.7306e-02],\n",
      "        [-2.4586e-02, -2.1494e-02],\n",
      "        [-2.6934e-02, -3.4038e-02],\n",
      "        [-8.2107e-02, -6.1844e-02],\n",
      "        [-6.3972e-02,  1.5291e-02],\n",
      "        [-1.4103e-01, -8.3019e-02],\n",
      "        [-3.9869e-02, -1.6127e-02],\n",
      "        [-8.4776e-02, -5.9416e-02],\n",
      "        [ 6.1318e-05,  3.0847e-02],\n",
      "        [-3.5359e-02, -5.9582e-04],\n",
      "        [-8.5447e-02, -5.0029e-02],\n",
      "        [ 4.2502e-02, -6.8843e-02],\n",
      "        [-3.6386e-02,  3.8684e-02],\n",
      "        [-3.7995e-03, -1.5575e-02],\n",
      "        [-1.4520e-02, -5.2729e-02],\n",
      "        [-5.9940e-02, -3.7231e-02],\n",
      "        [-6.8622e-02, -9.6014e-02],\n",
      "        [-9.5416e-02, -5.6882e-02],\n",
      "        [-9.5217e-02, -6.8241e-02],\n",
      "        [-9.0063e-02, -5.6725e-02],\n",
      "        [ 2.9956e-03, -2.3200e-02],\n",
      "        [-1.5676e-02,  1.4156e-02],\n",
      "        [-7.7354e-02,  1.7664e-02],\n",
      "        [-1.2696e-03, -6.5860e-02],\n",
      "        [-6.1184e-02,  1.1608e-02],\n",
      "        [-8.8529e-02, -6.3465e-02],\n",
      "        [-6.1210e-02, -5.7757e-02],\n",
      "        [-3.3520e-02, -3.4469e-02],\n",
      "        [-2.0838e-02, -7.1391e-03],\n",
      "        [ 1.8418e-02, -6.3334e-02],\n",
      "        [-5.0197e-02, -6.6743e-02],\n",
      "        [-9.3841e-02,  1.7214e-03],\n",
      "        [ 2.4583e-02, -3.7043e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
      " 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 0]\n",
      "train_true_bools [1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0]\n",
      "logits:  tensor([[-2.6708e-02,  8.4919e-03],\n",
      "        [-8.8556e-02, -5.7644e-02],\n",
      "        [-2.2241e-02, -1.6424e-02],\n",
      "        [ 8.0032e-04, -1.0026e-01],\n",
      "        [-3.1225e-02,  5.7788e-02],\n",
      "        [-6.7850e-02, -3.0716e-02],\n",
      "        [-3.8740e-02, -1.4343e-02],\n",
      "        [-2.1882e-02, -1.4561e-02],\n",
      "        [-4.1779e-02, -4.7328e-02],\n",
      "        [-4.8005e-02, -2.2555e-02],\n",
      "        [-8.5529e-02,  5.8034e-03],\n",
      "        [-1.0579e-02,  4.8902e-02],\n",
      "        [-6.2507e-02, -1.7863e-02],\n",
      "        [ 1.3355e-02, -4.2443e-02],\n",
      "        [-2.0135e-02, -7.7628e-02],\n",
      "        [-7.1498e-02,  9.6534e-03],\n",
      "        [-4.8133e-02,  5.6877e-02],\n",
      "        [-9.7774e-02, -2.6361e-02],\n",
      "        [ 5.4214e-03, -6.9906e-02],\n",
      "        [-4.4697e-02,  9.7249e-03],\n",
      "        [-7.1165e-02, -2.3897e-02],\n",
      "        [-8.9722e-02, -5.3460e-02],\n",
      "        [-9.4189e-02,  1.2009e-02],\n",
      "        [-1.5749e-02, -5.2711e-02],\n",
      "        [-4.6456e-02, -4.6573e-02],\n",
      "        [-7.0202e-02, -2.0061e-02],\n",
      "        [-8.6317e-02, -6.3668e-02],\n",
      "        [-8.8485e-02, -5.6296e-02],\n",
      "        [-2.5549e-02, -4.0801e-03],\n",
      "        [-8.9345e-02,  3.4199e-03],\n",
      "        [-6.0652e-02, -8.0348e-02],\n",
      "        [-6.3691e-02, -2.5350e-03],\n",
      "        [-3.9167e-02, -5.0215e-02],\n",
      "        [ 5.7796e-03, -1.0370e-02],\n",
      "        [-3.3712e-02, -4.2993e-02],\n",
      "        [-1.1745e-01, -1.4229e-01],\n",
      "        [-7.9476e-02, -5.9973e-02],\n",
      "        [-3.9224e-02, -7.0170e-02],\n",
      "        [-5.6568e-02, -9.3034e-03],\n",
      "        [-1.2784e-04, -1.2726e-02],\n",
      "        [-1.5526e-02, -5.7375e-02],\n",
      "        [-8.6338e-02, -6.0001e-02],\n",
      "        [-5.7969e-02,  5.4498e-03],\n",
      "        [ 3.6477e-02,  1.6531e-02],\n",
      "        [-4.1566e-02, -3.9514e-02],\n",
      "        [-6.8596e-02,  1.2707e-02],\n",
      "        [-2.7948e-02,  9.0255e-03],\n",
      "        [-3.0755e-02, -2.7221e-03],\n",
      "        [-4.3403e-02, -2.5398e-02],\n",
      "        [-1.0677e-02, -6.6012e-03],\n",
      "        [-3.9343e-02,  6.2085e-02],\n",
      "        [-7.8398e-02,  1.0675e-03],\n",
      "        [-9.5309e-02, -6.0765e-02],\n",
      "        [-3.3579e-02, -5.2208e-02],\n",
      "        [ 1.1578e-02, -1.5677e-02],\n",
      "        [-8.2744e-02,  1.4229e-02],\n",
      "        [ 9.6982e-03, -6.2741e-02],\n",
      "        [-5.1331e-02, -6.0788e-02],\n",
      "        [-4.7284e-02, -4.2195e-02],\n",
      "        [-7.0415e-03,  1.9061e-02],\n",
      "        [-7.3648e-02,  5.5321e-02],\n",
      "        [-6.5153e-02,  3.5414e-02],\n",
      "        [-7.3697e-02,  2.2249e-02],\n",
      "        [-9.2209e-02, -5.8076e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1]\n",
      "train_true_bools [1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1\n",
      " 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1]\n",
      "logits:  tensor([[-0.0715, -0.0236],\n",
      "        [ 0.0542, -0.0481],\n",
      "        [-0.0131,  0.0598],\n",
      "        [-0.0577,  0.0377],\n",
      "        [-0.0329, -0.0347]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 1 0]\n",
      "train_true_bools [1 1 1 0 0]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 91 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 10\t Train Loss: 0.6909\t  Train ACC: 0.6842\t Val Loss 0.6930\t Val Acc: 0.5224\t Val F1: 65.9574\t Val AUC: 0.5668\n",
      "Total val_time took 0.31 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 10.71 minutes\n",
      "\n",
      "======== Epoch 11 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0082, -0.0165],\n",
      "        [-0.0504,  0.0048],\n",
      "        [-0.0269, -0.0065],\n",
      "        [-0.0223, -0.0426],\n",
      "        [-0.0580, -0.0636],\n",
      "        [ 0.0444, -0.0074],\n",
      "        [-0.0353,  0.0318],\n",
      "        [-0.0536,  0.0005],\n",
      "        [ 0.0212,  0.0278],\n",
      "        [-0.1435, -0.0034],\n",
      "        [-0.0390, -0.0695],\n",
      "        [-0.0331, -0.0444],\n",
      "        [-0.0891, -0.0739],\n",
      "        [-0.0278, -0.0624],\n",
      "        [-0.0033, -0.0249],\n",
      "        [ 0.0309,  0.0178],\n",
      "        [-0.0916, -0.0599],\n",
      "        [-0.0389, -0.0794],\n",
      "        [-0.0707, -0.0740],\n",
      "        [-0.0473,  0.0076],\n",
      "        [-0.1085, -0.0039],\n",
      "        [-0.0298,  0.0060],\n",
      "        [-0.0417, -0.0282],\n",
      "        [-0.0918, -0.0739],\n",
      "        [-0.0005, -0.0140],\n",
      "        [ 0.0160,  0.0234],\n",
      "        [-0.1223,  0.0239],\n",
      "        [-0.0529, -0.0336],\n",
      "        [-0.1366,  0.0066],\n",
      "        [-0.0790,  0.0476],\n",
      "        [-0.0845, -0.0625],\n",
      "        [-0.0529,  0.0505],\n",
      "        [-0.0985, -0.0674],\n",
      "        [-0.1149, -0.0778],\n",
      "        [-0.1077,  0.0011],\n",
      "        [-0.0119, -0.0407],\n",
      "        [-0.0989, -0.0075],\n",
      "        [-0.0943, -0.0694],\n",
      "        [-0.0068,  0.0009],\n",
      "        [-0.0316, -0.0021],\n",
      "        [-0.0812, -0.0595],\n",
      "        [-0.0631,  0.0226],\n",
      "        [-0.0435, -0.0778],\n",
      "        [-0.0227, -0.1009],\n",
      "        [-0.0387, -0.0312],\n",
      "        [ 0.0016, -0.0658],\n",
      "        [-0.0484, -0.0580],\n",
      "        [-0.0068, -0.0567],\n",
      "        [ 0.0088, -0.0067],\n",
      "        [-0.0245, -0.0196],\n",
      "        [-0.1119,  0.0251],\n",
      "        [-0.0815, -0.0182],\n",
      "        [-0.0076, -0.0217],\n",
      "        [-0.0801, -0.0366],\n",
      "        [-0.0087, -0.0210],\n",
      "        [ 0.0218, -0.0950],\n",
      "        [-0.0917, -0.0544],\n",
      "        [-0.0108, -0.0104],\n",
      "        [-0.0954, -0.0606],\n",
      "        [ 0.0189, -0.0840],\n",
      "        [-0.0172,  0.0566],\n",
      "        [-0.0953, -0.0337],\n",
      "        [ 0.0376, -0.0326],\n",
      "        [-0.0683, -0.0294]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1]\n",
      "train_true_bools [0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1]\n",
      "logits:  tensor([[-0.0885,  0.0430],\n",
      "        [-0.1294, -0.0281],\n",
      "        [-0.0327,  0.0129],\n",
      "        [-0.0109, -0.0410],\n",
      "        [-0.0415, -0.0761],\n",
      "        [-0.1078, -0.0270],\n",
      "        [-0.0858, -0.0570],\n",
      "        [-0.0902, -0.0474],\n",
      "        [-0.0928, -0.0277],\n",
      "        [-0.0877, -0.0578],\n",
      "        [-0.0061,  0.0380],\n",
      "        [-0.0621,  0.0204],\n",
      "        [-0.0242, -0.0048],\n",
      "        [-0.0689, -0.0943],\n",
      "        [-0.0054,  0.0238],\n",
      "        [-0.0568, -0.0664],\n",
      "        [ 0.0057, -0.1057],\n",
      "        [-0.0454,  0.0193],\n",
      "        [-0.0630, -0.0289],\n",
      "        [-0.0699, -0.0320],\n",
      "        [-0.0422, -0.0193],\n",
      "        [-0.0765, -0.0630],\n",
      "        [-0.0546, -0.0119],\n",
      "        [-0.0918, -0.0506],\n",
      "        [ 0.0227,  0.0063],\n",
      "        [-0.0657, -0.0591],\n",
      "        [-0.0779, -0.0547],\n",
      "        [-0.0512,  0.0033],\n",
      "        [-0.1184, -0.0381],\n",
      "        [ 0.0335, -0.0819],\n",
      "        [ 0.0154, -0.0365],\n",
      "        [-0.0995, -0.0290],\n",
      "        [-0.0603, -0.0235],\n",
      "        [ 0.0079,  0.0004],\n",
      "        [-0.0108, -0.0128],\n",
      "        [-0.0942, -0.0532],\n",
      "        [-0.0725,  0.0289],\n",
      "        [-0.0989, -0.0677],\n",
      "        [-0.0303, -0.0135],\n",
      "        [-0.0227, -0.0132],\n",
      "        [-0.0862, -0.0636],\n",
      "        [-0.0266, -0.0291],\n",
      "        [ 0.0096, -0.0384],\n",
      "        [-0.0118, -0.0229],\n",
      "        [-0.0819, -0.0415],\n",
      "        [-0.0372, -0.0434],\n",
      "        [-0.0995,  0.0315],\n",
      "        [-0.1126,  0.0728],\n",
      "        [-0.0888, -0.0617],\n",
      "        [-0.0293, -0.0742],\n",
      "        [-0.0483,  0.0106],\n",
      "        [-0.0914, -0.0501],\n",
      "        [-0.0616,  0.0584],\n",
      "        [-0.0516,  0.0144],\n",
      "        [ 0.0231,  0.0168],\n",
      "        [-0.0907, -0.0534],\n",
      "        [-0.0918, -0.0553],\n",
      "        [-0.0590,  0.0253],\n",
      "        [-0.0365, -0.0602],\n",
      "        [-0.0433, -0.0635],\n",
      "        [-0.1223, -0.0253],\n",
      "        [-0.0262, -0.0126],\n",
      "        [ 0.0074, -0.0331],\n",
      "        [-0.0180, -0.0777]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1\n",
      " 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 0]\n",
      "train_true_bools [1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 1\n",
      " 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0]\n",
      "logits:  tensor([[-0.0356,  0.0352],\n",
      "        [-0.0111,  0.0107],\n",
      "        [-0.0641, -0.0088],\n",
      "        [-0.0564, -0.0079],\n",
      "        [ 0.0214, -0.0184]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 1 0]\n",
      "train_true_bools [1 0 0 0 0]\n",
      "Total training_time took 0.75 minutes \n",
      "training acc 99 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 11\t Train Loss: 0.6880\t  Train ACC: 0.7444\t Val Loss 0.6896\t Val Acc: 0.5224\t Val F1: 66.6667\t Val AUC: 0.5624\n",
      "Total val_time took 0.32 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 11.78 minutes\n",
      "\n",
      "======== Epoch 12 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0966, -0.0646],\n",
      "        [-0.0538, -0.0593],\n",
      "        [ 0.0509, -0.0443],\n",
      "        [-0.0289,  0.0048],\n",
      "        [-0.0932, -0.0622],\n",
      "        [-0.0101, -0.0470],\n",
      "        [-0.0723,  0.0532],\n",
      "        [-0.0232,  0.0208],\n",
      "        [-0.0829, -0.0549],\n",
      "        [-0.0343,  0.0069],\n",
      "        [-0.0784, -0.0474],\n",
      "        [-0.0710,  0.0051],\n",
      "        [ 0.0026,  0.0087],\n",
      "        [-0.0108, -0.0262],\n",
      "        [-0.1100,  0.0357],\n",
      "        [-0.1003,  0.0013],\n",
      "        [-0.0437, -0.0316],\n",
      "        [ 0.0262, -0.0464],\n",
      "        [-0.0330, -0.0118],\n",
      "        [-0.0466, -0.0125],\n",
      "        [-0.0841, -0.0295],\n",
      "        [-0.0057,  0.0259],\n",
      "        [-0.1022, -0.0640],\n",
      "        [-0.0092,  0.0174],\n",
      "        [-0.0176, -0.0521],\n",
      "        [-0.0125, -0.0308],\n",
      "        [-0.0889, -0.0375],\n",
      "        [ 0.0043, -0.0418],\n",
      "        [-0.0603, -0.0226],\n",
      "        [ 0.0170, -0.0371],\n",
      "        [-0.0100, -0.0091],\n",
      "        [-0.0760,  0.0154],\n",
      "        [-0.0310, -0.0124],\n",
      "        [-0.1050, -0.0285],\n",
      "        [-0.0739,  0.0123],\n",
      "        [-0.0202,  0.0308],\n",
      "        [-0.0885, -0.0174],\n",
      "        [-0.0082, -0.0134],\n",
      "        [-0.0412, -0.0069],\n",
      "        [-0.0408, -0.0255],\n",
      "        [-0.0971,  0.0015],\n",
      "        [-0.0617, -0.0662],\n",
      "        [-0.0391, -0.0628],\n",
      "        [ 0.0046, -0.0248],\n",
      "        [-0.0875,  0.0125],\n",
      "        [ 0.0021, -0.0496],\n",
      "        [-0.0303, -0.1398],\n",
      "        [ 0.0278, -0.0083],\n",
      "        [-0.0186, -0.0077],\n",
      "        [-0.0971, -0.0489],\n",
      "        [-0.0161, -0.0054],\n",
      "        [-0.0652, -0.0147],\n",
      "        [-0.0347,  0.0032],\n",
      "        [-0.0875, -0.0511],\n",
      "        [-0.0506, -0.0431],\n",
      "        [-0.0941, -0.0596],\n",
      "        [ 0.0074,  0.0284],\n",
      "        [ 0.0403,  0.0277],\n",
      "        [-0.0497, -0.0730],\n",
      "        [-0.0959,  0.0406],\n",
      "        [-0.0892, -0.0723],\n",
      "        [-0.0266,  0.0048],\n",
      "        [-0.0025, -0.0502],\n",
      "        [-0.0746,  0.0086]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1]\n",
      "train_true_bools [1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1\n",
      " 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1]\n",
      "logits:  tensor([[-0.0847,  0.0149],\n",
      "        [-0.0746,  0.0302],\n",
      "        [-0.0407, -0.0284],\n",
      "        [-0.0434,  0.0069],\n",
      "        [-0.0455, -0.1030],\n",
      "        [-0.0990,  0.0258],\n",
      "        [-0.0744, -0.0470],\n",
      "        [-0.0064,  0.0530],\n",
      "        [ 0.0185, -0.0167],\n",
      "        [-0.0155,  0.0182],\n",
      "        [-0.0361,  0.0007],\n",
      "        [-0.0164, -0.0844],\n",
      "        [ 0.0681,  0.0360],\n",
      "        [ 0.0164,  0.0068],\n",
      "        [-0.0535, -0.0094],\n",
      "        [-0.0358, -0.0264],\n",
      "        [-0.0909, -0.0604],\n",
      "        [-0.0764,  0.0316],\n",
      "        [-0.0873, -0.0462],\n",
      "        [ 0.0107,  0.0199],\n",
      "        [-0.0556, -0.0595],\n",
      "        [-0.0452, -0.0306],\n",
      "        [-0.0122, -0.0091],\n",
      "        [-0.0486,  0.0488],\n",
      "        [-0.0627, -0.0949],\n",
      "        [-0.0528, -0.0135],\n",
      "        [-0.1169, -0.0854],\n",
      "        [-0.0789, -0.0600],\n",
      "        [-0.0475,  0.0378],\n",
      "        [-0.0132, -0.0160],\n",
      "        [-0.0634, -0.0403],\n",
      "        [-0.0392, -0.0770],\n",
      "        [-0.0239, -0.0452],\n",
      "        [-0.0524, -0.0190],\n",
      "        [-0.0906, -0.0485],\n",
      "        [-0.1320,  0.0543],\n",
      "        [-0.0852, -0.0272],\n",
      "        [ 0.0564,  0.0430],\n",
      "        [-0.0130,  0.0035],\n",
      "        [-0.0313, -0.0536],\n",
      "        [-0.1027, -0.0369],\n",
      "        [-0.0488, -0.0287],\n",
      "        [ 0.0032, -0.0057],\n",
      "        [-0.0272, -0.0052],\n",
      "        [ 0.0167, -0.0505],\n",
      "        [-0.0636, -0.0294],\n",
      "        [-0.0579,  0.0322],\n",
      "        [-0.1176,  0.0258],\n",
      "        [-0.0853, -0.0631],\n",
      "        [-0.0635,  0.0692],\n",
      "        [-0.0625, -0.0315],\n",
      "        [-0.0177,  0.0327],\n",
      "        [-0.0825, -0.0525],\n",
      "        [-0.0254, -0.0754],\n",
      "        [-0.0994, -0.0577],\n",
      "        [-0.0842,  0.0058],\n",
      "        [-0.0899, -0.0604],\n",
      "        [-0.0690,  0.0020],\n",
      "        [-0.0270,  0.0117],\n",
      "        [-0.0718,  0.0718],\n",
      "        [-0.0959, -0.0626],\n",
      "        [-0.0303, -0.0190],\n",
      "        [ 0.0058,  0.0101],\n",
      "        [-0.0843, -0.0574]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "train_true_bools [1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1]\n",
      "logits:  tensor([[ 0.0202, -0.1002],\n",
      "        [-0.0512, -0.0074],\n",
      "        [-0.0925, -0.0613],\n",
      "        [-0.0979, -0.0643],\n",
      "        [-0.0887, -0.0619]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 1 1 1 1]\n",
      "train_true_bools [0 1 0 1 0]\n",
      "Total training_time took 0.75 minutes \n",
      "training acc 91 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 12\t Train Loss: 0.6866\t  Train ACC: 0.6842\t Val Loss 0.6918\t Val Acc: 0.5522\t Val F1: 66.6667\t Val AUC: 0.5838\n",
      "Total val_time took 0.32 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 12.85 minutes\n",
      "\n",
      "======== Epoch 13 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-7.6205e-02, -5.1429e-02],\n",
      "        [ 1.4514e-02, -5.7968e-02],\n",
      "        [-8.6232e-02, -6.7226e-02],\n",
      "        [-9.5931e-02, -6.3251e-02],\n",
      "        [ 2.7004e-02,  1.4021e-02],\n",
      "        [-6.7625e-02, -2.2022e-02],\n",
      "        [ 4.6140e-02,  5.9463e-02],\n",
      "        [-6.8314e-02,  7.0065e-02],\n",
      "        [-9.4398e-02, -6.6348e-02],\n",
      "        [ 5.9004e-02, -2.6411e-03],\n",
      "        [-9.0546e-02, -5.9095e-02],\n",
      "        [-5.5514e-02,  2.0749e-03],\n",
      "        [-5.4411e-02, -2.8368e-02],\n",
      "        [-6.0456e-03, -2.6248e-02],\n",
      "        [ 5.5369e-04,  1.8556e-02],\n",
      "        [-1.5916e-02,  6.2933e-02],\n",
      "        [-4.2446e-02,  5.6814e-02],\n",
      "        [-7.2990e-02, -6.7619e-02],\n",
      "        [-4.6508e-02, -4.8769e-02],\n",
      "        [-9.3265e-02,  5.9012e-03],\n",
      "        [-5.8825e-02, -5.6421e-03],\n",
      "        [ 5.5617e-02,  1.6484e-02],\n",
      "        [-3.7821e-02, -4.4576e-02],\n",
      "        [ 2.9459e-02, -2.0799e-02],\n",
      "        [-4.7326e-02, -5.0087e-03],\n",
      "        [-4.3308e-02,  1.0179e-02],\n",
      "        [-9.0834e-02, -2.8627e-02],\n",
      "        [ 1.2985e-01, -3.2261e-02],\n",
      "        [-3.9640e-02,  5.2577e-02],\n",
      "        [-3.3224e-04, -9.8909e-03],\n",
      "        [ 8.1886e-02,  5.2506e-04],\n",
      "        [-4.3047e-02,  1.4326e-02],\n",
      "        [-8.5769e-02, -5.6226e-02],\n",
      "        [-3.8456e-02, -2.7330e-02],\n",
      "        [ 6.1375e-03, -6.4194e-02],\n",
      "        [ 9.5635e-03, -4.2970e-02],\n",
      "        [-6.0689e-03, -1.4481e-02],\n",
      "        [-1.0172e-02, -1.1035e-04],\n",
      "        [-1.5666e-02,  5.1190e-03],\n",
      "        [ 1.1011e-01, -4.4429e-02],\n",
      "        [-8.7918e-02, -2.2317e-02],\n",
      "        [-1.2994e-02,  1.8490e-02],\n",
      "        [ 4.9155e-02, -4.4542e-02],\n",
      "        [-9.3393e-02, -5.0772e-02],\n",
      "        [-1.4207e-02,  7.7851e-02],\n",
      "        [ 2.0810e-02,  4.7020e-03],\n",
      "        [ 6.7344e-03, -1.6621e-02],\n",
      "        [-9.0986e-02, -6.0277e-02],\n",
      "        [ 2.8147e-03,  3.4042e-02],\n",
      "        [-6.1802e-02, -6.5422e-02],\n",
      "        [ 4.6306e-02, -1.3079e-03],\n",
      "        [-8.3990e-02, -5.1708e-02],\n",
      "        [-2.7692e-02,  3.3061e-02],\n",
      "        [ 4.9901e-03, -7.7093e-02],\n",
      "        [-9.5902e-03, -4.7763e-02],\n",
      "        [-3.5173e-02,  5.1532e-02],\n",
      "        [-8.6408e-02, -5.9187e-02],\n",
      "        [ 4.8996e-03, -2.0898e-02],\n",
      "        [ 3.1858e-02, -2.5421e-02],\n",
      "        [-9.4340e-02, -2.4348e-03],\n",
      "        [ 2.4200e-02, -9.0905e-03],\n",
      "        [-6.9063e-03, -2.5530e-02],\n",
      "        [-5.2037e-02,  9.2219e-03],\n",
      "        [-7.8101e-02, -6.4568e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0\n",
      " 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1]\n",
      "train_true_bools [1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1\n",
      " 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0]\n",
      "logits:  tensor([[-0.0518,  0.0278],\n",
      "        [ 0.0066, -0.0583],\n",
      "        [-0.0104,  0.0467],\n",
      "        [-0.0560, -0.0109],\n",
      "        [ 0.0010,  0.0395],\n",
      "        [ 0.0356, -0.0175],\n",
      "        [-0.0089,  0.0260],\n",
      "        [-0.0919, -0.0652],\n",
      "        [ 0.0092, -0.0839],\n",
      "        [-0.0081, -0.0245],\n",
      "        [-0.0951, -0.0654],\n",
      "        [-0.1221,  0.0270],\n",
      "        [-0.0120, -0.0594],\n",
      "        [-0.0569, -0.0430],\n",
      "        [-0.0138, -0.0400],\n",
      "        [-0.0416, -0.0319],\n",
      "        [-0.0096,  0.0069],\n",
      "        [-0.0063,  0.0466],\n",
      "        [ 0.0022, -0.0698],\n",
      "        [-0.0161,  0.0153],\n",
      "        [-0.0434, -0.0678],\n",
      "        [ 0.0028,  0.0259],\n",
      "        [-0.0171,  0.0780],\n",
      "        [-0.0655, -0.0071],\n",
      "        [-0.0870,  0.0170],\n",
      "        [-0.0303,  0.0004],\n",
      "        [-0.0152, -0.0325],\n",
      "        [-0.0412,  0.0887],\n",
      "        [ 0.0257, -0.0304],\n",
      "        [-0.0129, -0.0159],\n",
      "        [-0.0300, -0.0796],\n",
      "        [-0.0920, -0.0504],\n",
      "        [-0.0929, -0.0589],\n",
      "        [-0.0221,  0.0620],\n",
      "        [ 0.0382,  0.0318],\n",
      "        [-0.0388,  0.0118],\n",
      "        [ 0.0015, -0.0232],\n",
      "        [-0.0357,  0.0228],\n",
      "        [ 0.0244, -0.0793],\n",
      "        [-0.0267,  0.0200],\n",
      "        [ 0.0095, -0.0249],\n",
      "        [-0.0182, -0.0529],\n",
      "        [-0.0624,  0.0115],\n",
      "        [-0.0236, -0.0056],\n",
      "        [ 0.0232,  0.0524],\n",
      "        [-0.0795, -0.0654],\n",
      "        [ 0.0117, -0.0264],\n",
      "        [-0.0715,  0.0138],\n",
      "        [-0.0487, -0.0094],\n",
      "        [ 0.0571, -0.0258],\n",
      "        [ 0.0026, -0.0323],\n",
      "        [-0.0261, -0.0862],\n",
      "        [-0.0804, -0.0616],\n",
      "        [ 0.0243, -0.0410],\n",
      "        [-0.0953, -0.0762],\n",
      "        [-0.0853, -0.0009],\n",
      "        [-0.0441,  0.0081],\n",
      "        [-0.0580, -0.0101],\n",
      "        [-0.0170,  0.0591],\n",
      "        [-0.0041, -0.0243],\n",
      "        [-0.0828, -0.0531],\n",
      "        [ 0.0214, -0.0103],\n",
      "        [-0.0654, -0.0701],\n",
      "        [-0.0817, -0.0215]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0\n",
      " 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1]\n",
      "train_true_bools [1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1]\n",
      "logits:  tensor([[-0.0664,  0.0175],\n",
      "        [ 0.0196, -0.0539],\n",
      "        [-0.0095, -0.0280],\n",
      "        [-0.0599, -0.0213],\n",
      "        [-0.0885, -0.0524]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 1 1]\n",
      "train_true_bools [1 1 0 1 1]\n",
      "Total training_time took 0.75 minutes \n",
      "training acc 99 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 13\t Train Loss: 0.6867\t  Train ACC: 0.7444\t Val Loss 0.6988\t Val Acc: 0.5522\t Val F1: 65.9091\t Val AUC: 0.5847\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 13.91 minutes\n",
      "\n",
      "======== Epoch 14 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.0101,  0.0027],\n",
      "        [ 0.0184,  0.0610],\n",
      "        [ 0.0171, -0.0567],\n",
      "        [-0.0016, -0.0333],\n",
      "        [-0.0033, -0.0165],\n",
      "        [-0.0092, -0.0433],\n",
      "        [-0.0589, -0.0323],\n",
      "        [ 0.0629,  0.0273],\n",
      "        [-0.0814, -0.0554],\n",
      "        [-0.0235, -0.0289],\n",
      "        [-0.1234,  0.0138],\n",
      "        [-0.0094,  0.0168],\n",
      "        [-0.0978, -0.0599],\n",
      "        [ 0.0289, -0.0184],\n",
      "        [-0.0028,  0.0315],\n",
      "        [ 0.0276, -0.0192],\n",
      "        [ 0.0332,  0.0018],\n",
      "        [ 0.0133, -0.0498],\n",
      "        [ 0.0170,  0.0453],\n",
      "        [-0.0182, -0.0424],\n",
      "        [ 0.0676,  0.0412],\n",
      "        [-0.0820,  0.0018],\n",
      "        [-0.0907, -0.0058],\n",
      "        [ 0.0087,  0.0328],\n",
      "        [ 0.0300, -0.0651],\n",
      "        [ 0.0148, -0.0981],\n",
      "        [ 0.0163, -0.0211],\n",
      "        [ 0.0076, -0.0421],\n",
      "        [-0.0939, -0.0495],\n",
      "        [-0.0656,  0.0741],\n",
      "        [-0.0688,  0.0466],\n",
      "        [ 0.0435, -0.0343],\n",
      "        [-0.0327,  0.0076],\n",
      "        [-0.0824, -0.0591],\n",
      "        [-0.0262,  0.0075],\n",
      "        [-0.0484, -0.0569],\n",
      "        [-0.0360, -0.0214],\n",
      "        [-0.0838, -0.0658],\n",
      "        [-0.0286, -0.0119],\n",
      "        [-0.0792, -0.0504],\n",
      "        [ 0.0216, -0.0372],\n",
      "        [-0.0823, -0.0566],\n",
      "        [-0.0680, -0.0561],\n",
      "        [-0.0796, -0.0438],\n",
      "        [ 0.0459, -0.0581],\n",
      "        [ 0.0052,  0.0407],\n",
      "        [-0.0915, -0.0500],\n",
      "        [ 0.0204, -0.0145],\n",
      "        [-0.0087,  0.0230],\n",
      "        [ 0.0216, -0.0332],\n",
      "        [-0.0031, -0.0103],\n",
      "        [ 0.0176, -0.0667],\n",
      "        [ 0.0467, -0.0037],\n",
      "        [-0.0661, -0.0407],\n",
      "        [-0.0275,  0.0006],\n",
      "        [-0.1113,  0.0465],\n",
      "        [-0.0073, -0.1048],\n",
      "        [-0.0040, -0.0308],\n",
      "        [-0.0737, -0.0193],\n",
      "        [-0.0719, -0.0098],\n",
      "        [-0.0208,  0.0296],\n",
      "        [-0.0100,  0.0635],\n",
      "        [-0.0190, -0.0308],\n",
      "        [-0.0906, -0.0562]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 1 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0 1\n",
      " 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1]\n",
      "train_true_bools [0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1]\n",
      "logits:  tensor([[-0.0909, -0.0504],\n",
      "        [-0.1132, -0.0455],\n",
      "        [ 0.0324, -0.0246],\n",
      "        [-0.1314,  0.0723],\n",
      "        [-0.0880,  0.0550],\n",
      "        [-0.0547,  0.0233],\n",
      "        [-0.0045,  0.0076],\n",
      "        [-0.0079,  0.0146],\n",
      "        [-0.0265, -0.0423],\n",
      "        [ 0.0305, -0.0173],\n",
      "        [ 0.0736, -0.0096],\n",
      "        [ 0.0354,  0.0121],\n",
      "        [-0.0321, -0.0589],\n",
      "        [-0.0277,  0.0176],\n",
      "        [-0.0513, -0.0199],\n",
      "        [-0.0121,  0.0107],\n",
      "        [-0.0419,  0.0360],\n",
      "        [-0.0140, -0.0549],\n",
      "        [-0.0622, -0.0064],\n",
      "        [-0.0188, -0.0408],\n",
      "        [-0.0342,  0.0299],\n",
      "        [-0.0074, -0.0381],\n",
      "        [-0.0424,  0.0696],\n",
      "        [-0.0575, -0.0450],\n",
      "        [-0.0855, -0.0531],\n",
      "        [-0.0631, -0.0416],\n",
      "        [ 0.0990, -0.0040],\n",
      "        [-0.0421, -0.0021],\n",
      "        [-0.0256,  0.0013],\n",
      "        [ 0.0035,  0.0163],\n",
      "        [-0.0338,  0.0305],\n",
      "        [-0.0479,  0.0264],\n",
      "        [ 0.0147, -0.0548],\n",
      "        [-0.0452,  0.0160],\n",
      "        [-0.0121,  0.0612],\n",
      "        [-0.0179,  0.0233],\n",
      "        [ 0.0459,  0.0117],\n",
      "        [-0.0280,  0.0738],\n",
      "        [ 0.0728,  0.0342],\n",
      "        [-0.0428,  0.0750],\n",
      "        [-0.0909, -0.0617],\n",
      "        [-0.0291, -0.0604],\n",
      "        [ 0.0574, -0.0367],\n",
      "        [-0.0694,  0.0343],\n",
      "        [-0.0848, -0.0693],\n",
      "        [-0.0531, -0.0015],\n",
      "        [ 0.0081, -0.0008],\n",
      "        [-0.1009, -0.0612],\n",
      "        [-0.0539,  0.0210],\n",
      "        [-0.0803, -0.0545],\n",
      "        [-0.1001,  0.0176],\n",
      "        [-0.0006, -0.0489],\n",
      "        [-0.0135,  0.0162],\n",
      "        [-0.0405,  0.0266],\n",
      "        [-0.0528, -0.0863],\n",
      "        [-0.0477, -0.0338],\n",
      "        [-0.0296, -0.0427],\n",
      "        [-0.0930, -0.0551],\n",
      "        [-0.0021,  0.0145],\n",
      "        [-0.1029, -0.0517],\n",
      "        [-0.0955, -0.0727],\n",
      "        [-0.0465, -0.0528],\n",
      "        [ 0.0432,  0.0487],\n",
      "        [ 0.0028, -0.0759]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0\n",
      " 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0]\n",
      "train_true_bools [1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1\n",
      " 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0]\n",
      "logits:  tensor([[-0.0724,  0.0332],\n",
      "        [-0.0097, -0.0863],\n",
      "        [-0.0250, -0.0098],\n",
      "        [-0.0332, -0.0005],\n",
      "        [-0.0176,  0.0147]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 1 1]\n",
      "train_true_bools [1 0 1 0 0]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 103 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 14\t Train Loss: 0.6848\t  Train ACC: 0.7744\t Val Loss 0.6931\t Val Acc: 0.5970\t Val F1: 67.4699\t Val AUC: 0.5909\n",
      "Total val_time took 0.31 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 14.98 minutes\n",
      "\n",
      "======== Epoch 15 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-9.6534e-02, -7.4566e-02],\n",
      "        [-3.5706e-02, -2.2475e-02],\n",
      "        [-8.2438e-02, -5.2405e-02],\n",
      "        [-8.6640e-02, -5.6428e-02],\n",
      "        [ 3.2433e-02, -5.7742e-05],\n",
      "        [-2.8124e-03,  4.8040e-02],\n",
      "        [ 1.6135e-02, -1.5601e-04],\n",
      "        [-4.2543e-02, -7.1771e-02],\n",
      "        [-3.4638e-02,  6.8296e-02],\n",
      "        [-7.1220e-02,  6.1500e-03],\n",
      "        [-8.6882e-02, -5.3861e-02],\n",
      "        [ 2.3427e-02, -4.1644e-02],\n",
      "        [ 1.7910e-02, -5.2518e-02],\n",
      "        [-8.8413e-03, -2.1213e-02],\n",
      "        [-9.4452e-02, -5.9407e-02],\n",
      "        [ 1.7150e-02,  2.2085e-02],\n",
      "        [-1.8891e-02, -6.6147e-02],\n",
      "        [-7.1912e-02,  3.9526e-04],\n",
      "        [ 3.5964e-02,  7.2047e-02],\n",
      "        [-4.4980e-03,  1.1463e-02],\n",
      "        [-4.1664e-02,  2.5812e-02],\n",
      "        [ 3.8827e-02, -8.7156e-03],\n",
      "        [-1.4338e-02,  4.3892e-02],\n",
      "        [-2.9553e-03,  3.2093e-02],\n",
      "        [ 6.5852e-02, -1.1122e-01],\n",
      "        [-2.1187e-03, -6.4336e-02],\n",
      "        [-4.2770e-02,  1.7532e-02],\n",
      "        [ 3.3898e-03, -8.6303e-03],\n",
      "        [ 1.6796e-02, -3.1747e-02],\n",
      "        [ 2.3746e-02,  5.2905e-02],\n",
      "        [ 4.5175e-03,  3.4194e-02],\n",
      "        [-1.0057e-01, -7.0866e-02],\n",
      "        [-8.5684e-02, -5.6402e-02],\n",
      "        [-9.8104e-03, -5.9319e-02],\n",
      "        [ 2.5553e-02, -7.8667e-02],\n",
      "        [ 2.8242e-02,  2.9503e-02],\n",
      "        [ 1.2915e-02,  4.6665e-02],\n",
      "        [-4.4721e-02,  3.5531e-02],\n",
      "        [-6.8922e-03, -3.1403e-02],\n",
      "        [-8.7959e-03, -5.3904e-02],\n",
      "        [-8.7468e-02, -5.6911e-02],\n",
      "        [ 8.9099e-04,  7.3558e-02],\n",
      "        [-8.7213e-02, -4.6039e-02],\n",
      "        [-1.3317e-02, -5.1314e-02],\n",
      "        [ 1.2788e-02, -3.1874e-02],\n",
      "        [-9.1201e-02, -5.7357e-02],\n",
      "        [ 1.8825e-02, -2.6630e-02],\n",
      "        [ 4.1996e-02,  3.8623e-02],\n",
      "        [ 4.2736e-02,  1.3410e-02],\n",
      "        [-1.0108e-03,  5.1653e-02],\n",
      "        [-6.3499e-02, -9.1516e-03],\n",
      "        [-9.3644e-02, -5.0686e-02],\n",
      "        [-5.6108e-02,  4.8210e-02],\n",
      "        [-5.7439e-02, -4.7386e-02],\n",
      "        [ 6.2767e-02,  3.7308e-02],\n",
      "        [-4.7862e-02,  4.8016e-02],\n",
      "        [-5.8805e-02, -1.0046e-02],\n",
      "        [-2.2563e-04, -3.0899e-02],\n",
      "        [-2.8212e-02, -3.0319e-02],\n",
      "        [-3.6774e-02, -2.7992e-02],\n",
      "        [-9.3146e-02,  3.2545e-02],\n",
      "        [ 4.0902e-02, -2.6202e-02],\n",
      "        [ 4.6962e-02, -4.7453e-02],\n",
      "        [ 7.6992e-02,  6.2828e-03]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0]\n",
      "train_true_bools [1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1\n",
      " 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 0]\n",
      "logits:  tensor([[-0.0185, -0.0443],\n",
      "        [-0.0847, -0.0454],\n",
      "        [-0.0838, -0.0581],\n",
      "        [-0.1146,  0.0387],\n",
      "        [-0.0028, -0.0321],\n",
      "        [-0.0931,  0.0095],\n",
      "        [ 0.0291, -0.0415],\n",
      "        [ 0.0169, -0.0340],\n",
      "        [ 0.0506,  0.0809],\n",
      "        [-0.0163,  0.0744],\n",
      "        [ 0.0365,  0.0316],\n",
      "        [-0.0332, -0.0312],\n",
      "        [-0.0423,  0.0418],\n",
      "        [-0.0932, -0.0472],\n",
      "        [-0.0924, -0.0611],\n",
      "        [-0.0391,  0.0265],\n",
      "        [ 0.0155,  0.0094],\n",
      "        [-0.0231,  0.0855],\n",
      "        [-0.0943, -0.0682],\n",
      "        [-0.0978, -0.0018],\n",
      "        [-0.0520,  0.0186],\n",
      "        [-0.0302,  0.0916],\n",
      "        [ 0.0221, -0.0213],\n",
      "        [-0.0375,  0.0772],\n",
      "        [ 0.0768,  0.0055],\n",
      "        [ 0.0294, -0.0259],\n",
      "        [ 0.0037, -0.0694],\n",
      "        [-0.0983, -0.0677],\n",
      "        [ 0.0052, -0.0729],\n",
      "        [-0.0648,  0.0022],\n",
      "        [-0.0679,  0.0382],\n",
      "        [ 0.0258, -0.0381],\n",
      "        [ 0.0011,  0.0507],\n",
      "        [-0.0362,  0.0232],\n",
      "        [ 0.0167,  0.0706],\n",
      "        [-0.0494,  0.0529],\n",
      "        [-0.0818, -0.0644],\n",
      "        [ 0.0022, -0.0275],\n",
      "        [ 0.0564,  0.0265],\n",
      "        [-0.0391, -0.0222],\n",
      "        [-0.0159,  0.1210],\n",
      "        [ 0.0025, -0.0229],\n",
      "        [ 0.0444, -0.0860],\n",
      "        [-0.0506, -0.0656],\n",
      "        [-0.0599, -0.0300],\n",
      "        [-0.0182, -0.0524],\n",
      "        [-0.0301,  0.0171],\n",
      "        [-0.0511,  0.0227],\n",
      "        [ 0.0661, -0.0048],\n",
      "        [-0.0455, -0.0010],\n",
      "        [ 0.0078, -0.0297],\n",
      "        [-0.1058,  0.0388],\n",
      "        [-0.0205,  0.0838],\n",
      "        [-0.0240,  0.0347],\n",
      "        [-0.0346,  0.1186],\n",
      "        [-0.0237,  0.0044],\n",
      "        [ 0.0289, -0.0007],\n",
      "        [-0.0418, -0.0208],\n",
      "        [ 0.0119,  0.0367],\n",
      "        [ 0.0052,  0.0407],\n",
      "        [ 0.0067, -0.0673],\n",
      "        [ 0.0049, -0.0450],\n",
      "        [ 0.0135,  0.0173],\n",
      "        [-0.0957, -0.0687]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1\n",
      " 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1]\n",
      "train_true_bools [0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0\n",
      " 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1]\n",
      "logits:  tensor([[-0.0373, -0.0616],\n",
      "        [-0.1179,  0.0083],\n",
      "        [-0.0218,  0.0363],\n",
      "        [-0.0298,  0.0398],\n",
      "        [ 0.0053, -0.0021]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 1 1 1 0]\n",
      "train_true_bools [1 1 1 1 0]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 106 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 15\t Train Loss: 0.6826\t  Train ACC: 0.7970\t Val Loss 0.6920\t Val Acc: 0.5970\t Val F1: 66.6667\t Val AUC: 0.6087\n",
      "Total val_time took 0.32 minutes \n",
      "\n",
      "Total training took 16.05 minutes\n",
      "\n",
      "======== Epoch 16 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0237,  0.0387],\n",
      "        [ 0.0131, -0.0033],\n",
      "        [-0.0034, -0.0117],\n",
      "        [-0.0393,  0.0889],\n",
      "        [ 0.0395, -0.0040],\n",
      "        [-0.0630,  0.0431],\n",
      "        [-0.0057, -0.0447],\n",
      "        [ 0.0351,  0.0588],\n",
      "        [ 0.0221,  0.0294],\n",
      "        [ 0.0731,  0.0103],\n",
      "        [-0.0107, -0.0567],\n",
      "        [ 0.0862, -0.0282],\n",
      "        [-0.0963, -0.0399],\n",
      "        [-0.0906,  0.0736],\n",
      "        [-0.0900, -0.0556],\n",
      "        [ 0.0608,  0.0731],\n",
      "        [ 0.0404, -0.0161],\n",
      "        [-0.0789, -0.0649],\n",
      "        [-0.0285, -0.0806],\n",
      "        [-0.0163,  0.0246],\n",
      "        [-0.1263,  0.0261],\n",
      "        [ 0.0014, -0.0469],\n",
      "        [-0.0182,  0.0274],\n",
      "        [-0.0670,  0.0866],\n",
      "        [-0.0880, -0.0071],\n",
      "        [ 0.0126, -0.0029],\n",
      "        [-0.0473, -0.0057],\n",
      "        [-0.0116, -0.0264],\n",
      "        [-0.0992, -0.0559],\n",
      "        [-0.0640, -0.0530],\n",
      "        [-0.0110, -0.0174],\n",
      "        [ 0.0093, -0.0041],\n",
      "        [-0.0704,  0.0499],\n",
      "        [-0.0458,  0.0390],\n",
      "        [-0.0435,  0.0769],\n",
      "        [-0.0116,  0.0596],\n",
      "        [-0.0808, -0.0609],\n",
      "        [ 0.0408, -0.0274],\n",
      "        [-0.0950, -0.0638],\n",
      "        [-0.0489,  0.0197],\n",
      "        [ 0.0130, -0.0534],\n",
      "        [-0.0740,  0.0206],\n",
      "        [-0.0812, -0.0596],\n",
      "        [ 0.0367, -0.0471],\n",
      "        [-0.0676, -0.0784],\n",
      "        [ 0.0651, -0.0166],\n",
      "        [-0.0211,  0.0032],\n",
      "        [ 0.0077,  0.0761],\n",
      "        [-0.0795, -0.0529],\n",
      "        [ 0.0104, -0.0454],\n",
      "        [-0.0571,  0.0998],\n",
      "        [-0.0654, -0.0156],\n",
      "        [-0.0854,  0.0243],\n",
      "        [ 0.1103, -0.1002],\n",
      "        [ 0.0083, -0.0631],\n",
      "        [-0.0161, -0.0293],\n",
      "        [-0.0249, -0.0514],\n",
      "        [-0.0965, -0.0558],\n",
      "        [-0.0678,  0.0448],\n",
      "        [-0.0876, -0.0591],\n",
      "        [-0.0013, -0.0230],\n",
      "        [-0.0909, -0.0629],\n",
      "        [-0.0235,  0.0197],\n",
      "        [ 0.0736,  0.0696]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
      " 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0]\n",
      "train_true_bools [1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0]\n",
      "logits:  tensor([[-0.0323,  0.0642],\n",
      "        [ 0.0316,  0.0413],\n",
      "        [-0.0239,  0.0313],\n",
      "        [-0.0611,  0.0270],\n",
      "        [-0.0871,  0.0430],\n",
      "        [-0.0529,  0.0154],\n",
      "        [-0.0332,  0.0246],\n",
      "        [-0.0618,  0.0315],\n",
      "        [ 0.0605, -0.0531],\n",
      "        [-0.0447,  0.0451],\n",
      "        [ 0.0011,  0.0230],\n",
      "        [-0.0377,  0.0236],\n",
      "        [-0.0288,  0.0366],\n",
      "        [-0.0210, -0.0228],\n",
      "        [-0.0065, -0.0156],\n",
      "        [-0.0929,  0.0423],\n",
      "        [-0.0513,  0.0053],\n",
      "        [-0.0873, -0.0618],\n",
      "        [-0.0960, -0.0613],\n",
      "        [ 0.0310, -0.0356],\n",
      "        [ 0.0386,  0.0069],\n",
      "        [-0.0942, -0.0619],\n",
      "        [-0.0108, -0.0436],\n",
      "        [-0.0507,  0.0858],\n",
      "        [-0.0090, -0.0082],\n",
      "        [-0.0725, -0.0663],\n",
      "        [-0.0240, -0.0241],\n",
      "        [-0.0077,  0.0325],\n",
      "        [-0.0007, -0.0003],\n",
      "        [-0.0485,  0.0287],\n",
      "        [ 0.0668, -0.0883],\n",
      "        [-0.0515,  0.0376],\n",
      "        [ 0.0622, -0.0349],\n",
      "        [ 0.0253, -0.0215],\n",
      "        [-0.0020,  0.0677],\n",
      "        [ 0.0152, -0.0701],\n",
      "        [ 0.0083,  0.0817],\n",
      "        [-0.0069,  0.0744],\n",
      "        [-0.0060, -0.1620],\n",
      "        [-0.0430,  0.0191],\n",
      "        [-0.0097,  0.0025],\n",
      "        [-0.1011, -0.0520],\n",
      "        [-0.0300,  0.0528],\n",
      "        [-0.0036, -0.0088],\n",
      "        [-0.0462,  0.0080],\n",
      "        [-0.0014,  0.0290],\n",
      "        [ 0.0088,  0.0279],\n",
      "        [-0.0941, -0.0675],\n",
      "        [-0.0856, -0.0599],\n",
      "        [-0.0220,  0.0122],\n",
      "        [ 0.0111, -0.0315],\n",
      "        [-0.0824, -0.0510],\n",
      "        [ 0.0487,  0.0330],\n",
      "        [ 0.0058, -0.0046],\n",
      "        [-0.0145, -0.0036],\n",
      "        [-0.0244, -0.0202],\n",
      "        [-0.0597, -0.0603],\n",
      "        [ 0.0633, -0.0191],\n",
      "        [-0.0158, -0.0034],\n",
      "        [ 0.0008, -0.0386],\n",
      "        [-0.0616,  0.0168],\n",
      "        [ 0.0112, -0.0324],\n",
      "        [ 0.0297,  0.0298],\n",
      "        [ 0.0524, -0.0290]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1\n",
      " 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0]\n",
      "train_true_bools [1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1\n",
      " 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      "logits:  tensor([[-0.0869,  0.0722],\n",
      "        [-0.0509, -0.0050],\n",
      "        [-0.0835, -0.0567],\n",
      "        [ 0.0616, -0.0707],\n",
      "        [ 0.0302, -0.0490]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 0 0]\n",
      "train_true_bools [1 1 1 0 0]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 109 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 16\t Train Loss: 0.6786\t  Train ACC: 0.8195\t Val Loss 0.6932\t Val Acc: 0.5970\t Val F1: 66.6667\t Val AUC: 0.6114\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 17.12 minutes\n",
      "\n",
      "======== Epoch 17 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-0.0070,  0.0320],\n",
      "        [-0.0640,  0.0476],\n",
      "        [-0.0168,  0.0027],\n",
      "        [ 0.0322, -0.0594],\n",
      "        [ 0.0026,  0.0624],\n",
      "        [-0.0175,  0.0255],\n",
      "        [ 0.0171, -0.0295],\n",
      "        [-0.0958, -0.0574],\n",
      "        [-0.0540,  0.0417],\n",
      "        [-0.0437,  0.0261],\n",
      "        [-0.0883, -0.0495],\n",
      "        [ 0.0157,  0.0474],\n",
      "        [ 0.0725, -0.0554],\n",
      "        [ 0.0194, -0.0740],\n",
      "        [-0.0272,  0.0750],\n",
      "        [ 0.0392, -0.0673],\n",
      "        [-0.0202,  0.0692],\n",
      "        [-0.0183,  0.0366],\n",
      "        [-0.0476, -0.0577],\n",
      "        [-0.0412, -0.0239],\n",
      "        [ 0.0634, -0.0171],\n",
      "        [ 0.0647, -0.0401],\n",
      "        [-0.0696, -0.0187],\n",
      "        [-0.0946, -0.0534],\n",
      "        [-0.0187,  0.0012],\n",
      "        [-0.0751,  0.0910],\n",
      "        [-0.0042, -0.0485],\n",
      "        [-0.0094, -0.0314],\n",
      "        [ 0.0278,  0.0303],\n",
      "        [-0.0852, -0.0429],\n",
      "        [-0.0495,  0.1342],\n",
      "        [ 0.0285, -0.0578],\n",
      "        [-0.0152,  0.0137],\n",
      "        [-0.0801, -0.0597],\n",
      "        [-0.0969, -0.0395],\n",
      "        [ 0.0215,  0.0884],\n",
      "        [-0.0226,  0.1098],\n",
      "        [-0.0305,  0.0079],\n",
      "        [-0.0158, -0.0606],\n",
      "        [ 0.0469,  0.0172],\n",
      "        [ 0.0095,  0.0509],\n",
      "        [-0.0060,  0.0281],\n",
      "        [ 0.0414, -0.0159],\n",
      "        [ 0.0646, -0.1148],\n",
      "        [ 0.0066,  0.0572],\n",
      "        [ 0.0917,  0.0173],\n",
      "        [ 0.0207,  0.0346],\n",
      "        [ 0.0170, -0.0038],\n",
      "        [-0.0562,  0.0123],\n",
      "        [ 0.0482,  0.0404],\n",
      "        [-0.0836, -0.0614],\n",
      "        [ 0.0364, -0.0246],\n",
      "        [ 0.0079,  0.0121],\n",
      "        [-0.0969, -0.0702],\n",
      "        [-0.0104, -0.0209],\n",
      "        [-0.0151, -0.0281],\n",
      "        [-0.0388,  0.0768],\n",
      "        [ 0.0174, -0.0496],\n",
      "        [-0.0276, -0.0747],\n",
      "        [ 0.0530, -0.0515],\n",
      "        [ 0.0044, -0.0019],\n",
      "        [ 0.0019, -0.0756],\n",
      "        [-0.0128, -0.0721],\n",
      "        [-0.0312,  0.0279]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1\n",
      " 1 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1]\n",
      "train_true_bools [1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 1 0 1\n",
      " 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1]\n",
      "logits:  tensor([[-1.9855e-02,  6.9004e-03],\n",
      "        [-5.0576e-02,  6.3846e-03],\n",
      "        [-6.0852e-02,  3.4062e-02],\n",
      "        [-3.6015e-02,  1.9623e-02],\n",
      "        [ 4.4347e-02, -5.3381e-03],\n",
      "        [-2.6893e-02,  1.1735e-02],\n",
      "        [-4.2342e-03,  1.0651e-02],\n",
      "        [-5.3577e-02, -3.3331e-02],\n",
      "        [-8.9366e-02, -5.1776e-02],\n",
      "        [-7.6467e-02, -6.0121e-02],\n",
      "        [-5.0892e-02,  3.7433e-02],\n",
      "        [-5.0252e-02, -1.0808e-02],\n",
      "        [ 3.1104e-02, -4.3003e-02],\n",
      "        [-9.3126e-02, -5.6185e-02],\n",
      "        [-6.5188e-02,  7.3197e-02],\n",
      "        [ 3.9679e-02,  2.5464e-02],\n",
      "        [ 2.3446e-02,  3.1681e-02],\n",
      "        [-7.8156e-02, -5.3589e-02],\n",
      "        [-5.4490e-02,  3.1218e-02],\n",
      "        [ 5.6942e-03, -3.6645e-02],\n",
      "        [-2.3748e-02,  2.3383e-03],\n",
      "        [-1.7496e-02, -1.7157e-02],\n",
      "        [-9.2235e-02, -5.8504e-02],\n",
      "        [ 8.1862e-02,  1.3587e-02],\n",
      "        [ 1.1725e-02,  8.2019e-03],\n",
      "        [ 8.4356e-02, -3.3579e-03],\n",
      "        [ 4.7962e-02, -1.4898e-02],\n",
      "        [ 6.6687e-02, -7.4766e-02],\n",
      "        [-3.3812e-02,  4.3517e-03],\n",
      "        [ 3.5956e-02, -4.5378e-02],\n",
      "        [-2.5062e-02, -3.7880e-02],\n",
      "        [-9.1976e-02, -5.5109e-02],\n",
      "        [-2.9570e-02, -3.1649e-02],\n",
      "        [ 8.8646e-02, -2.3102e-02],\n",
      "        [-5.3866e-02,  5.6494e-02],\n",
      "        [ 1.7307e-02, -3.1734e-02],\n",
      "        [-1.2758e-02,  4.6187e-04],\n",
      "        [-3.8359e-02, -2.3781e-02],\n",
      "        [-5.8858e-02,  4.1286e-02],\n",
      "        [-5.6272e-02,  7.6720e-02],\n",
      "        [ 8.3314e-02, -8.4423e-02],\n",
      "        [ 4.7843e-02, -2.6043e-02],\n",
      "        [ 1.4867e-02, -4.7191e-02],\n",
      "        [-3.3779e-02, -5.3700e-03],\n",
      "        [-8.8030e-02, -6.3273e-02],\n",
      "        [-4.3604e-02,  5.3637e-02],\n",
      "        [-1.0820e-01,  2.3587e-02],\n",
      "        [-8.1920e-02, -4.9968e-02],\n",
      "        [ 2.8946e-02,  1.3929e-02],\n",
      "        [-5.9314e-02,  3.4912e-02],\n",
      "        [ 7.0356e-05,  6.1370e-02],\n",
      "        [-5.4083e-02, -3.3086e-03],\n",
      "        [-8.0127e-02,  1.4624e-03],\n",
      "        [-2.7848e-02,  2.2861e-04],\n",
      "        [ 2.9135e-03,  1.3665e-02],\n",
      "        [-6.5494e-02,  6.0462e-02],\n",
      "        [-7.8775e-02, -5.9842e-02],\n",
      "        [ 4.3457e-03, -6.2597e-03],\n",
      "        [-2.2705e-02, -6.2465e-02],\n",
      "        [-4.0296e-03, -7.2729e-02],\n",
      "        [-9.0237e-02, -6.1394e-02],\n",
      "        [-4.5609e-03,  4.6278e-02],\n",
      "        [ 8.3100e-02,  5.4411e-02],\n",
      "        [-3.5053e-02,  4.8000e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1\n",
      " 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1]\n",
      "train_true_bools [0 1 1 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1\n",
      " 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1]\n",
      "logits:  tensor([[-0.1264, -0.0519],\n",
      "        [-0.0238, -0.0201],\n",
      "        [-0.0833, -0.0589],\n",
      "        [ 0.0395, -0.0243],\n",
      "        [ 0.0118,  0.0623]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 0 1]\n",
      "train_true_bools [1 0 1 0 1]\n",
      "Total training_time took 0.76 minutes \n",
      "training acc 108 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 17\t Train Loss: 0.6823\t  Train ACC: 0.8120\t Val Loss 0.6938\t Val Acc: 0.5970\t Val F1: 66.6667\t Val AUC: 0.6185\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 18.19 minutes\n",
      "\n",
      "======== Epoch 18 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 7.4869e-02, -3.6118e-02],\n",
      "        [-9.1054e-02, -5.9034e-02],\n",
      "        [-8.6053e-02,  4.4256e-02],\n",
      "        [ 3.6632e-03, -9.3358e-02],\n",
      "        [-6.6790e-02,  4.3455e-02],\n",
      "        [ 7.3059e-02,  1.4623e-02],\n",
      "        [-1.9382e-02, -4.4551e-02],\n",
      "        [-1.9507e-02,  1.5446e-02],\n",
      "        [-3.5767e-02,  1.8193e-02],\n",
      "        [-8.7049e-02,  9.5227e-02],\n",
      "        [-1.3595e-02, -1.1679e-02],\n",
      "        [ 7.2935e-02, -8.4706e-02],\n",
      "        [ 4.7906e-02, -2.1894e-02],\n",
      "        [ 5.6554e-02,  8.8670e-03],\n",
      "        [-8.3870e-02, -6.0368e-02],\n",
      "        [-9.4291e-02, -5.7164e-02],\n",
      "        [ 1.7147e-02, -4.9771e-02],\n",
      "        [-7.9276e-02, -5.9560e-02],\n",
      "        [ 1.6982e-02, -9.2967e-02],\n",
      "        [-5.3443e-02,  4.7138e-02],\n",
      "        [-8.8929e-03,  2.4351e-02],\n",
      "        [ 5.8959e-02, -2.5314e-02],\n",
      "        [-5.7770e-02, -1.4761e-03],\n",
      "        [-1.9127e-02, -4.6954e-02],\n",
      "        [-3.1367e-03, -5.5819e-02],\n",
      "        [-8.7413e-02, -5.5109e-02],\n",
      "        [-5.2316e-02,  2.2696e-02],\n",
      "        [-7.5247e-02,  2.6938e-02],\n",
      "        [ 9.3453e-03, -2.4547e-03],\n",
      "        [-8.7345e-02, -3.9631e-02],\n",
      "        [ 1.4065e-02, -1.2827e-02],\n",
      "        [ 3.6387e-02,  5.0260e-03],\n",
      "        [-5.0856e-02,  1.1451e-03],\n",
      "        [-2.9864e-02,  1.1397e-01],\n",
      "        [-1.7382e-02, -3.5283e-02],\n",
      "        [ 3.8953e-02, -3.4340e-02],\n",
      "        [-1.5783e-02, -2.0445e-03],\n",
      "        [-3.6014e-02, -2.1838e-02],\n",
      "        [-8.6932e-02, -6.7868e-02],\n",
      "        [ 6.4347e-02, -1.8230e-02],\n",
      "        [-3.9265e-02,  3.5086e-02],\n",
      "        [ 4.7041e-03, -3.4977e-03],\n",
      "        [-1.6398e-02, -2.2575e-02],\n",
      "        [-8.2591e-02, -5.2229e-02],\n",
      "        [ 9.5844e-03,  4.7393e-02],\n",
      "        [-2.2292e-02, -1.2441e-02],\n",
      "        [-3.8011e-02,  4.9608e-02],\n",
      "        [-2.4443e-03, -1.2745e-02],\n",
      "        [ 3.6367e-02, -1.5318e-05],\n",
      "        [ 4.0479e-02,  1.0650e-02],\n",
      "        [-1.0209e-02,  8.2078e-02],\n",
      "        [ 2.0733e-02,  9.6269e-03],\n",
      "        [-8.9425e-02, -5.9072e-02],\n",
      "        [-1.0166e-01,  6.5321e-02],\n",
      "        [-5.7049e-02, -5.8659e-02],\n",
      "        [-8.5494e-02,  5.6224e-02],\n",
      "        [-8.9973e-02, -6.1675e-02],\n",
      "        [ 1.0487e-02, -5.5342e-02],\n",
      "        [-9.1915e-02, -6.8374e-02],\n",
      "        [-8.4332e-02,  3.2396e-02],\n",
      "        [ 4.4044e-03,  2.1860e-02],\n",
      "        [ 3.6734e-02, -1.3390e-02],\n",
      "        [ 7.5736e-02,  5.7458e-02],\n",
      "        [ 4.7740e-03,  7.0847e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1\n",
      " 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1]\n",
      "train_true_bools [0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 0 1\n",
      " 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1]\n",
      "logits:  tensor([[-0.0900, -0.0534],\n",
      "        [-0.0911, -0.0527],\n",
      "        [ 0.0608,  0.0169],\n",
      "        [ 0.0573, -0.0165],\n",
      "        [-0.0427, -0.0644],\n",
      "        [-0.0297, -0.0026],\n",
      "        [-0.0249, -0.0916],\n",
      "        [ 0.0868,  0.0179],\n",
      "        [-0.0696,  0.0266],\n",
      "        [-0.0539, -0.0580],\n",
      "        [-0.0204,  0.0650],\n",
      "        [-0.0137, -0.0313],\n",
      "        [ 0.0224, -0.0299],\n",
      "        [-0.0697, -0.0367],\n",
      "        [-0.0014, -0.0509],\n",
      "        [-0.0723, -0.0477],\n",
      "        [ 0.0214, -0.0328],\n",
      "        [-0.0992, -0.0600],\n",
      "        [-0.0861, -0.0534],\n",
      "        [ 0.0414, -0.1073],\n",
      "        [-0.0084, -0.0726],\n",
      "        [ 0.0348,  0.0436],\n",
      "        [ 0.0024, -0.0347],\n",
      "        [ 0.0173, -0.0510],\n",
      "        [ 0.0384,  0.0125],\n",
      "        [-0.0777, -0.0727],\n",
      "        [-0.0796, -0.0484],\n",
      "        [ 0.0234, -0.0571],\n",
      "        [-0.0794,  0.0183],\n",
      "        [ 0.0674, -0.0882],\n",
      "        [ 0.0463, -0.0281],\n",
      "        [ 0.0231, -0.0458],\n",
      "        [-0.0093,  0.0443],\n",
      "        [-0.0323,  0.0297],\n",
      "        [-0.0731,  0.0224],\n",
      "        [-0.0880,  0.0365],\n",
      "        [-0.0103,  0.0476],\n",
      "        [ 0.0569, -0.0395],\n",
      "        [-0.0110, -0.0029],\n",
      "        [ 0.1058,  0.0676],\n",
      "        [-0.0818,  0.0645],\n",
      "        [-0.0891, -0.0651],\n",
      "        [-0.0002,  0.0028],\n",
      "        [ 0.0093,  0.0366],\n",
      "        [-0.0600,  0.0015],\n",
      "        [ 0.0147, -0.0097],\n",
      "        [ 0.0498, -0.0168],\n",
      "        [-0.0394, -0.0429],\n",
      "        [ 0.0111,  0.0679],\n",
      "        [ 0.0348, -0.0017],\n",
      "        [ 0.0507, -0.0848],\n",
      "        [ 0.0482,  0.0263],\n",
      "        [-0.0769,  0.0233],\n",
      "        [ 0.0052, -0.0147],\n",
      "        [-0.0578,  0.0474],\n",
      "        [ 0.0088,  0.0652],\n",
      "        [-0.1010,  0.0431],\n",
      "        [-0.0631,  0.0245],\n",
      "        [-0.0840,  0.0182],\n",
      "        [ 0.0691,  0.0170],\n",
      "        [ 0.0193,  0.0274],\n",
      "        [-0.0886, -0.0543],\n",
      "        [-0.0927, -0.0526],\n",
      "        [ 0.1634,  0.0197]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1\n",
      " 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0]\n",
      "train_true_bools [0 1 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0]\n",
      "logits:  tensor([[-0.0359, -0.0768],\n",
      "        [-0.0462, -0.0333],\n",
      "        [ 0.0113,  0.0734],\n",
      "        [ 0.1025, -0.0008],\n",
      "        [-0.0327,  0.0608]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 1 1 0 1]\n",
      "train_true_bools [0 1 1 0 1]\n",
      "Total training_time took 0.77 minutes \n",
      "training acc 112 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 18\t Train Loss: 0.6801\t  Train ACC: 0.8421\t Val Loss 0.6965\t Val Acc: 0.6119\t Val F1: 67.5000\t Val AUC: 0.6159\n",
      "Total val_time took 0.31 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 19.29 minutes\n",
      "\n",
      "======== Epoch 19 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-6.4336e-03,  8.4640e-02],\n",
      "        [ 2.3940e-02,  2.8367e-02],\n",
      "        [-3.8234e-02,  4.3707e-02],\n",
      "        [ 2.5882e-02, -2.7333e-02],\n",
      "        [-5.9893e-03,  1.2325e-02],\n",
      "        [-4.5104e-02,  2.4053e-02],\n",
      "        [-4.4697e-02,  2.9816e-02],\n",
      "        [-6.5755e-03, -4.9486e-03],\n",
      "        [ 2.5032e-02,  1.4139e-02],\n",
      "        [-7.2818e-02,  4.9447e-03],\n",
      "        [-2.0876e-02, -4.9415e-02],\n",
      "        [-2.4357e-02, -6.3118e-02],\n",
      "        [ 2.1070e-02,  1.2136e-02],\n",
      "        [ 4.4324e-04,  7.3680e-02],\n",
      "        [-8.8997e-02,  1.3193e-01],\n",
      "        [-2.1036e-02, -5.1499e-03],\n",
      "        [ 9.9037e-02,  4.5243e-02],\n",
      "        [-1.7274e-02,  4.2672e-02],\n",
      "        [-8.9604e-02, -5.1642e-02],\n",
      "        [ 1.1577e-02, -2.3765e-02],\n",
      "        [-4.4869e-02,  8.1919e-02],\n",
      "        [-8.3954e-02,  1.0823e-02],\n",
      "        [ 3.4327e-03,  1.0296e-01],\n",
      "        [-4.3341e-02, -3.9279e-02],\n",
      "        [ 1.3046e-02,  5.8380e-02],\n",
      "        [-1.1282e-02, -5.5305e-02],\n",
      "        [ 4.1206e-02,  4.5952e-02],\n",
      "        [-5.7760e-02, -4.4203e-02],\n",
      "        [-8.9181e-02, -7.0661e-02],\n",
      "        [ 7.0151e-02,  4.2569e-02],\n",
      "        [-6.2409e-04, -3.5097e-02],\n",
      "        [ 3.6533e-02,  2.1764e-02],\n",
      "        [-2.3432e-03,  3.1318e-02],\n",
      "        [ 8.7131e-02, -5.1835e-02],\n",
      "        [ 1.0921e-01, -1.8136e-02],\n",
      "        [-3.4445e-03, -2.9851e-02],\n",
      "        [-4.0914e-02,  6.7481e-02],\n",
      "        [-2.3679e-02,  4.3871e-03],\n",
      "        [ 2.3701e-02,  2.0992e-02],\n",
      "        [-2.8091e-02,  2.5601e-02],\n",
      "        [ 3.5167e-05,  1.5023e-02],\n",
      "        [ 1.2058e-02,  3.2830e-03],\n",
      "        [ 6.2689e-04, -6.6292e-02],\n",
      "        [-6.3909e-02,  6.0246e-02],\n",
      "        [-2.6352e-02,  1.1230e-02],\n",
      "        [-3.4853e-02,  1.8123e-02],\n",
      "        [-7.3360e-03, -4.9994e-02],\n",
      "        [ 5.8617e-02,  4.1071e-02],\n",
      "        [ 4.2591e-02,  1.0345e-02],\n",
      "        [-5.4202e-02,  5.2682e-02],\n",
      "        [-8.7622e-02, -5.1765e-02],\n",
      "        [ 5.7211e-02, -2.5742e-03],\n",
      "        [-3.7314e-02,  2.5291e-03],\n",
      "        [ 4.8814e-02,  5.7581e-02],\n",
      "        [ 3.4680e-02,  1.8767e-02],\n",
      "        [ 3.5848e-03,  1.8063e-02],\n",
      "        [-8.9592e-02, -5.7225e-02],\n",
      "        [-8.6687e-02, -5.5082e-02],\n",
      "        [-3.4775e-02,  5.7026e-03],\n",
      "        [ 9.1690e-02, -2.1247e-02],\n",
      "        [-8.7499e-02, -5.0804e-02],\n",
      "        [-4.4814e-02,  4.4411e-02],\n",
      "        [-5.1481e-02,  1.5803e-02],\n",
      "        [-3.8780e-02, -1.6146e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 0 0 1\n",
      " 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1]\n",
      "train_true_bools [1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1]\n",
      "logits:  tensor([[-0.0287,  0.0284],\n",
      "        [ 0.0600,  0.0183],\n",
      "        [-0.0549,  0.0030],\n",
      "        [ 0.0357,  0.0034],\n",
      "        [-0.1177,  0.1317],\n",
      "        [-0.0210,  0.0094],\n",
      "        [-0.0860, -0.0479],\n",
      "        [-0.0460, -0.0397],\n",
      "        [-0.0514,  0.0391],\n",
      "        [-0.0877, -0.0520],\n",
      "        [-0.0717, -0.0086],\n",
      "        [-0.0174,  0.0201],\n",
      "        [-0.0945, -0.0696],\n",
      "        [-0.0870, -0.0656],\n",
      "        [ 0.0738, -0.0217],\n",
      "        [-0.0895, -0.0635],\n",
      "        [ 0.0182, -0.0736],\n",
      "        [-0.0461,  0.0452],\n",
      "        [ 0.0772, -0.0195],\n",
      "        [ 0.1228,  0.0013],\n",
      "        [ 0.0076,  0.0674],\n",
      "        [ 0.0860,  0.0160],\n",
      "        [-0.0316,  0.0089],\n",
      "        [ 0.0992, -0.0645],\n",
      "        [ 0.0262, -0.0616],\n",
      "        [ 0.0108, -0.0306],\n",
      "        [-0.0004,  0.0101],\n",
      "        [ 0.0268, -0.0185],\n",
      "        [-0.0501, -0.0444],\n",
      "        [ 0.0507, -0.0367],\n",
      "        [ 0.0538, -0.0787],\n",
      "        [-0.0272,  0.0140],\n",
      "        [-0.0607,  0.0433],\n",
      "        [-0.0012,  0.0395],\n",
      "        [-0.0541,  0.0123],\n",
      "        [-0.0439,  0.1785],\n",
      "        [-0.0827, -0.0580],\n",
      "        [ 0.0070, -0.0401],\n",
      "        [-0.0663,  0.0734],\n",
      "        [ 0.0043, -0.1067],\n",
      "        [-0.0983, -0.0717],\n",
      "        [-0.0429,  0.0553],\n",
      "        [-0.0266, -0.0054],\n",
      "        [ 0.0224,  0.0357],\n",
      "        [ 0.0904,  0.0628],\n",
      "        [ 0.0163, -0.0188],\n",
      "        [-0.0409,  0.0403],\n",
      "        [-0.0903, -0.0546],\n",
      "        [-0.0865, -0.0611],\n",
      "        [ 0.0417,  0.0598],\n",
      "        [ 0.0888, -0.0316],\n",
      "        [ 0.0256,  0.0311],\n",
      "        [ 0.0056,  0.0021],\n",
      "        [-0.0896, -0.0578],\n",
      "        [ 0.0733, -0.0223],\n",
      "        [ 0.0358, -0.0199],\n",
      "        [-0.0762,  0.0550],\n",
      "        [-0.0073,  0.0047],\n",
      "        [ 0.0511, -0.0520],\n",
      "        [-0.0341,  0.0272],\n",
      "        [-0.0189,  0.0283],\n",
      "        [ 0.0056,  0.0745],\n",
      "        [-0.0789, -0.0488],\n",
      "        [ 0.0106,  0.0402]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1]\n",
      "train_true_bools [0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0\n",
      " 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1]\n",
      "logits:  tensor([[ 0.0680,  0.0168],\n",
      "        [-0.0864, -0.0624],\n",
      "        [-0.0911,  0.0060],\n",
      "        [-0.0973, -0.0573],\n",
      "        [-0.0152, -0.0463]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 1 1 1 0]\n",
      "train_true_bools [0 0 1 1 0]\n",
      "Total training_time took 0.75 minutes \n",
      "training acc 103 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 19\t Train Loss: 0.6830\t  Train ACC: 0.7744\t Val Loss 0.6922\t Val Acc: 0.5821\t Val F1: 64.1026\t Val AUC: 0.6043\n",
      "Total val_time took 0.32 minutes \n",
      "\n",
      "Total training took 20.35 minutes\n",
      "\n",
      "======== Epoch 20 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[-5.9340e-02,  3.3273e-02],\n",
      "        [-9.6687e-02, -5.9037e-02],\n",
      "        [ 9.0787e-02,  4.3173e-02],\n",
      "        [ 5.0273e-02,  7.4538e-02],\n",
      "        [-1.0113e-01, -2.9035e-02],\n",
      "        [-6.2292e-02,  1.8632e-02],\n",
      "        [ 5.5975e-02,  3.5375e-02],\n",
      "        [-3.3773e-02, -2.5263e-03],\n",
      "        [ 9.0299e-02, -2.5322e-02],\n",
      "        [ 7.7358e-02, -6.4667e-02],\n",
      "        [-9.5859e-02, -6.3027e-02],\n",
      "        [-8.3781e-02,  7.2632e-02],\n",
      "        [-4.2207e-02,  7.9344e-03],\n",
      "        [-6.0242e-02, -2.8696e-02],\n",
      "        [ 2.7942e-02, -4.1934e-03],\n",
      "        [-2.4505e-02,  7.8756e-02],\n",
      "        [-7.8209e-02, -5.8716e-02],\n",
      "        [-2.1861e-02, -2.2522e-03],\n",
      "        [-3.7596e-02,  5.3764e-02],\n",
      "        [-5.3516e-03, -1.7013e-02],\n",
      "        [-2.1142e-03,  6.9497e-02],\n",
      "        [-1.1338e-02, -1.2341e-01],\n",
      "        [-4.1596e-02,  1.4978e-01],\n",
      "        [ 6.2329e-02,  1.3577e-02],\n",
      "        [-4.2264e-02,  2.4719e-02],\n",
      "        [-9.0895e-02, -4.7689e-02],\n",
      "        [-4.3385e-02, -1.7393e-02],\n",
      "        [-4.9940e-02, -1.9082e-02],\n",
      "        [-4.0936e-02, -2.9643e-02],\n",
      "        [ 6.1464e-02, -8.2273e-03],\n",
      "        [-5.6240e-02,  2.4457e-02],\n",
      "        [ 3.9717e-02,  2.1637e-02],\n",
      "        [-1.7826e-02,  7.8427e-02],\n",
      "        [ 5.9055e-02, -5.5005e-04],\n",
      "        [-2.2995e-03, -2.3912e-02],\n",
      "        [-2.2892e-03, -5.6948e-02],\n",
      "        [-1.6743e-02,  9.0664e-02],\n",
      "        [-8.1565e-02, -5.7066e-02],\n",
      "        [ 6.4789e-02,  1.1258e-02],\n",
      "        [ 3.5189e-02,  1.9901e-02],\n",
      "        [ 4.2139e-02, -4.7121e-02],\n",
      "        [ 1.6917e-02, -7.0032e-02],\n",
      "        [-1.1664e-01,  5.2019e-02],\n",
      "        [-1.0161e-01, -6.7322e-02],\n",
      "        [-2.5465e-03,  2.0699e-04],\n",
      "        [ 7.1890e-02, -7.4015e-02],\n",
      "        [-5.1519e-02,  2.7149e-03],\n",
      "        [-8.2739e-02, -4.8952e-02],\n",
      "        [-8.1729e-02, -5.0929e-02],\n",
      "        [-8.3428e-02, -4.2756e-02],\n",
      "        [-3.5888e-03,  6.0360e-02],\n",
      "        [-4.8761e-02, -2.5673e-02],\n",
      "        [ 1.9814e-02, -5.4761e-02],\n",
      "        [ 4.6212e-02,  1.1520e-02],\n",
      "        [ 1.1136e-03, -2.2493e-05],\n",
      "        [ 1.2368e-02, -4.4996e-02],\n",
      "        [-6.9370e-02,  8.4542e-02],\n",
      "        [-2.5038e-03,  5.2234e-02],\n",
      "        [-8.2049e-02,  4.3416e-02],\n",
      "        [ 1.0308e-02, -3.2723e-02],\n",
      "        [ 4.6652e-02, -2.2690e-02],\n",
      "        [-8.8375e-03, -3.8150e-02],\n",
      "        [-8.4887e-02, -7.6569e-02],\n",
      "        [ 3.5819e-02, -6.0632e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1\n",
      " 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0]\n",
      "train_true_bools [1 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 1\n",
      " 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0]\n",
      "logits:  tensor([[-0.0339, -0.0027],\n",
      "        [ 0.0474, -0.0579],\n",
      "        [ 0.0552, -0.0023],\n",
      "        [-0.0154,  0.1009],\n",
      "        [ 0.0390, -0.0324],\n",
      "        [-0.0459, -0.0197],\n",
      "        [-0.0914, -0.0600],\n",
      "        [ 0.0882,  0.0027],\n",
      "        [-0.0025, -0.0053],\n",
      "        [-0.0271,  0.0484],\n",
      "        [ 0.0324,  0.0986],\n",
      "        [ 0.0702,  0.0226],\n",
      "        [ 0.0430,  0.0084],\n",
      "        [-0.0049, -0.0433],\n",
      "        [ 0.0017, -0.0344],\n",
      "        [ 0.0023,  0.0588],\n",
      "        [-0.0873, -0.0561],\n",
      "        [ 0.0154, -0.0599],\n",
      "        [-0.0857, -0.0530],\n",
      "        [ 0.0647, -0.0280],\n",
      "        [-0.0937, -0.0563],\n",
      "        [-0.0077, -0.0401],\n",
      "        [ 0.0760,  0.0502],\n",
      "        [ 0.0417, -0.0159],\n",
      "        [-0.0196,  0.0353],\n",
      "        [-0.0652, -0.0370],\n",
      "        [ 0.0417, -0.0176],\n",
      "        [-0.0144,  0.0753],\n",
      "        [ 0.0656, -0.0332],\n",
      "        [-0.0249,  0.0480],\n",
      "        [-0.0325, -0.0186],\n",
      "        [-0.0949,  0.0488],\n",
      "        [-0.0458,  0.0329],\n",
      "        [ 0.0543, -0.0368],\n",
      "        [-0.0251, -0.0315],\n",
      "        [-0.0977, -0.0558],\n",
      "        [ 0.0585,  0.0022],\n",
      "        [-0.0419,  0.0039],\n",
      "        [ 0.0781,  0.0085],\n",
      "        [ 0.0187, -0.0533],\n",
      "        [-0.0238, -0.1057],\n",
      "        [-0.0884, -0.0477],\n",
      "        [-0.0132, -0.0935],\n",
      "        [ 0.1308,  0.0094],\n",
      "        [-0.0653,  0.0805],\n",
      "        [-0.0330, -0.0033],\n",
      "        [ 0.0596, -0.0235],\n",
      "        [ 0.0309,  0.0289],\n",
      "        [-0.0301, -0.0076],\n",
      "        [ 0.0276, -0.0761],\n",
      "        [-0.0129, -0.0730],\n",
      "        [-0.0523,  0.0617],\n",
      "        [ 0.0053,  0.0654],\n",
      "        [-0.0276, -0.0870],\n",
      "        [ 0.0006, -0.0342],\n",
      "        [ 0.0660,  0.0014],\n",
      "        [-0.0188, -0.0551],\n",
      "        [ 0.0127, -0.0374],\n",
      "        [-0.0908, -0.0663],\n",
      "        [ 0.0204,  0.0570],\n",
      "        [-0.0936, -0.0599],\n",
      "        [ 0.0617,  0.0392],\n",
      "        [-0.0967, -0.0144],\n",
      "        [-0.0049, -0.0003]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1]\n",
      "train_true_bools [0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0]\n",
      "logits:  tensor([[ 0.0037,  0.0620],\n",
      "        [ 0.0555,  0.0212],\n",
      "        [-0.0268, -0.1019],\n",
      "        [-0.0619,  0.0595],\n",
      "        [ 0.0363,  0.0055]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [1 0 0 1 0]\n",
      "train_true_bools [1 0 0 1 0]\n",
      "Total training_time took 0.78 minutes \n",
      "training acc 111 133\n",
      "\n",
      "Running Validation...\n",
      "Epoch 20\t Train Loss: 0.6801\t  Train ACC: 0.8346\t Val Loss 0.6951\t Val Acc: 0.5821\t Val F1: 63.1579\t Val AUC: 0.5963\n",
      "Total val_time took 0.31 minutes \n",
      "\n",
      "Total training took 21.45 minutes\n",
      "load the best model ... \n",
      "np.argmax for pred_labels [[0.5034412  0.49655885]\n",
      " [0.50192624 0.4980738 ]\n",
      " [0.49350506 0.5064949 ]\n",
      " [0.4959936  0.5040064 ]\n",
      " [0.4979931  0.5020069 ]\n",
      " [0.49953282 0.5004671 ]\n",
      " [0.49580657 0.5041934 ]\n",
      " [0.4947836  0.5052164 ]\n",
      " [0.5003714  0.4996286 ]\n",
      " [0.5009394  0.4990606 ]\n",
      " [0.4961195  0.50388044]\n",
      " [0.5023687  0.4976313 ]\n",
      " [0.49749878 0.5025012 ]\n",
      " [0.49291515 0.50708485]\n",
      " [0.50247574 0.4975243 ]\n",
      " [0.5125231  0.48747694]\n",
      " [0.49573427 0.50426567]\n",
      " [0.50167745 0.49832255]\n",
      " [0.49257147 0.5074285 ]\n",
      " [0.49965808 0.50034195]\n",
      " [0.50195503 0.49804503]\n",
      " [0.48345402 0.51654595]\n",
      " [0.4961197  0.50388026]\n",
      " [0.49220064 0.5077993 ]\n",
      " [0.50880426 0.4911957 ]\n",
      " [0.4985185  0.5014815 ]\n",
      " [0.48797008 0.5120299 ]\n",
      " [0.49248248 0.5075175 ]\n",
      " [0.50321436 0.49678558]\n",
      " [0.4931757  0.5068243 ]\n",
      " [0.49505752 0.5049425 ]\n",
      " [0.49714115 0.5028589 ]\n",
      " [0.49467725 0.50532275]\n",
      " [0.5040381  0.49596187]\n",
      " [0.5114529  0.48854706]\n",
      " [0.48756737 0.51243263]\n",
      " [0.5003561  0.49964392]\n",
      " [0.4940268  0.5059732 ]\n",
      " [0.486033   0.513967  ]\n",
      " [0.49661013 0.5033899 ]\n",
      " [0.50067717 0.49932283]\n",
      " [0.50189346 0.4981065 ]\n",
      " [0.49663693 0.5033631 ]\n",
      " [0.4925776  0.50742245]\n",
      " [0.4824938  0.5175062 ]\n",
      " [0.49261096 0.507389  ]\n",
      " [0.5053991  0.49460095]\n",
      " [0.4924384  0.50756156]\n",
      " [0.4920286  0.5079714 ]\n",
      " [0.49219936 0.50780064]\n",
      " [0.4939665  0.50603354]\n",
      " [0.4960188  0.50398123]\n",
      " [0.49220064 0.5077993 ]\n",
      " [0.49744242 0.5025576 ]\n",
      " [0.4926509  0.5073491 ]\n",
      " [0.48860633 0.51139367]\n",
      " [0.48515972 0.51484025]\n",
      " [0.49969605 0.5003039 ]\n",
      " [0.4981901  0.50180995]\n",
      " [0.49347264 0.50652736]\n",
      " [0.49241182 0.50758815]\n",
      " [0.4955785  0.50442153]\n",
      " [0.49529776 0.5047022 ]\n",
      " [0.506603   0.493397  ]\n",
      " [0.50513047 0.4948695 ]\n",
      " [0.5030244  0.4969756 ]\n",
      " [0.504098   0.49590203]]\n",
      "np.argmax for true_labels [[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "Precision: 0.5870, Recall: 0.7941, F1: 0.6750, Loss: 0.6931, AUC: 0.6159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.42      0.52        33\n",
      "           1       0.59      0.79      0.68        34\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.63      0.61      0.60        67\n",
      "weighted avg       0.63      0.61      0.60        67\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fold 2 \n",
      "\n",
      "train fraud 67 test fraud 33\n",
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.0916, -0.0116],\n",
      "        [ 0.1629, -0.0837],\n",
      "        [ 0.2502,  0.0575],\n",
      "        [ 0.0681, -0.0381],\n",
      "        [ 0.0848, -0.0625],\n",
      "        [ 0.2129, -0.0734],\n",
      "        [ 0.0552, -0.0188],\n",
      "        [ 0.0814, -0.0087],\n",
      "        [ 0.1727, -0.0396],\n",
      "        [ 0.1221,  0.0585],\n",
      "        [ 0.0642,  0.0176],\n",
      "        [ 0.1469, -0.0069],\n",
      "        [ 0.1186, -0.0587],\n",
      "        [ 0.1366, -0.0392],\n",
      "        [ 0.0536, -0.1057],\n",
      "        [ 0.0634,  0.0380],\n",
      "        [ 0.1624,  0.0534],\n",
      "        [ 0.0852, -0.0129],\n",
      "        [ 0.1377, -0.0857],\n",
      "        [ 0.0592, -0.0410],\n",
      "        [ 0.1565, -0.0902],\n",
      "        [ 0.1826, -0.0308],\n",
      "        [ 0.0749,  0.0495],\n",
      "        [ 0.0963, -0.1078],\n",
      "        [ 0.0841, -0.0146],\n",
      "        [ 0.1260,  0.0407],\n",
      "        [ 0.0937, -0.0067],\n",
      "        [ 0.1222, -0.0229],\n",
      "        [ 0.1701, -0.0455],\n",
      "        [ 0.1026,  0.0003],\n",
      "        [ 0.0850,  0.0116],\n",
      "        [ 0.1112, -0.0995],\n",
      "        [ 0.1124,  0.0131],\n",
      "        [ 0.1530, -0.0121],\n",
      "        [ 0.0626, -0.0928],\n",
      "        [ 0.0550, -0.0704],\n",
      "        [ 0.1676, -0.0181],\n",
      "        [ 0.1179, -0.0896],\n",
      "        [ 0.0736,  0.0236],\n",
      "        [ 0.1398,  0.0889],\n",
      "        [ 0.1354,  0.0320],\n",
      "        [ 0.1988,  0.0057],\n",
      "        [ 0.0816, -0.1109],\n",
      "        [ 0.0832,  0.0008],\n",
      "        [ 0.1152,  0.0317],\n",
      "        [ 0.2079, -0.0217],\n",
      "        [ 0.1383,  0.0228],\n",
      "        [ 0.1700, -0.0300],\n",
      "        [ 0.0787,  0.0401],\n",
      "        [ 0.0669, -0.0301],\n",
      "        [ 0.0301, -0.1629],\n",
      "        [ 0.1221, -0.0925],\n",
      "        [ 0.1350, -0.0666],\n",
      "        [ 0.0730,  0.0157],\n",
      "        [ 0.0393, -0.0326],\n",
      "        [ 0.0810, -0.0754],\n",
      "        [ 0.0927,  0.0402],\n",
      "        [ 0.1761, -0.0213],\n",
      "        [ 0.1417,  0.0303],\n",
      "        [ 0.1349, -0.0188],\n",
      "        [ 0.1539,  0.0313],\n",
      "        [ 0.1042, -0.0196],\n",
      "        [ 0.0840, -0.0071],\n",
      "        [ 0.2064, -0.0121]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1]\n",
      "logits:  tensor([[ 0.1905, -0.0279],\n",
      "        [ 0.1708, -0.0713],\n",
      "        [ 0.0261, -0.0234],\n",
      "        [ 0.0899,  0.0057],\n",
      "        [ 0.1034, -0.2169],\n",
      "        [ 0.1845, -0.0794],\n",
      "        [ 0.1084, -0.0111],\n",
      "        [ 0.0478, -0.0551],\n",
      "        [ 0.0934, -0.0034],\n",
      "        [ 0.1331, -0.1424],\n",
      "        [ 0.0808, -0.0071],\n",
      "        [ 0.0978,  0.0070],\n",
      "        [ 0.1924,  0.0049],\n",
      "        [ 0.1435, -0.0969],\n",
      "        [ 0.0785, -0.0219],\n",
      "        [ 0.0874, -0.0409],\n",
      "        [ 0.1806,  0.0493],\n",
      "        [ 0.1081, -0.0106],\n",
      "        [ 0.1658, -0.0465],\n",
      "        [ 0.1570,  0.0524],\n",
      "        [ 0.1605,  0.0781],\n",
      "        [ 0.1624, -0.0970],\n",
      "        [ 0.1745, -0.1008],\n",
      "        [ 0.0918, -0.1561],\n",
      "        [ 0.2390,  0.0659],\n",
      "        [ 0.2314,  0.0765],\n",
      "        [ 0.1276, -0.0552],\n",
      "        [ 0.1519,  0.0593],\n",
      "        [ 0.0790, -0.0322],\n",
      "        [ 0.0828, -0.0697],\n",
      "        [ 0.1886,  0.0780],\n",
      "        [ 0.1329, -0.0003],\n",
      "        [ 0.2081, -0.0671],\n",
      "        [ 0.1919, -0.0629],\n",
      "        [ 0.0904, -0.0059],\n",
      "        [ 0.1734,  0.0147],\n",
      "        [ 0.1160, -0.0370],\n",
      "        [-0.0066, -0.0637],\n",
      "        [ 0.1587, -0.0486],\n",
      "        [ 0.0906, -0.0145],\n",
      "        [ 0.0804, -0.0117],\n",
      "        [ 0.0570, -0.0556],\n",
      "        [ 0.1471, -0.0192],\n",
      "        [ 0.0838, -0.1260],\n",
      "        [ 0.2093, -0.1264],\n",
      "        [ 0.0601, -0.0143],\n",
      "        [ 0.1639, -0.1024],\n",
      "        [ 0.1527, -0.0828],\n",
      "        [ 0.1117, -0.0326],\n",
      "        [ 0.0864, -0.0138],\n",
      "        [ 0.1175, -0.0620],\n",
      "        [ 0.1194, -0.0980],\n",
      "        [ 0.1069, -0.1221],\n",
      "        [ 0.0802,  0.0044],\n",
      "        [ 0.1401, -0.0380],\n",
      "        [ 0.1692,  0.0203],\n",
      "        [ 0.1420, -0.0391],\n",
      "        [ 0.0851, -0.0547],\n",
      "        [ 0.0899, -0.0019],\n",
      "        [ 0.0884, -0.0171],\n",
      "        [ 0.0900, -0.0072],\n",
      "        [ 0.1607, -0.0711],\n",
      "        [ 0.1843, -0.0355],\n",
      "        [ 0.0930, -0.0218]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1\n",
      " 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1]\n",
      "logits:  tensor([[ 0.1115, -0.0457],\n",
      "        [ 0.0842, -0.0246],\n",
      "        [ 0.1325,  0.0214],\n",
      "        [ 0.0552, -0.0497],\n",
      "        [ 0.1693,  0.0259],\n",
      "        [ 0.1750, -0.0539]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0]\n",
      "train_true_bools [0 1 1 0 0 0]\n",
      "Total training_time took 0.65 minutes \n",
      "training acc 67 134\n",
      "\n",
      "Running Validation...\n",
      "Epoch 1\t Train Loss: 0.6874\t  Train ACC: 0.5000\t Val Loss 0.6780\t Val Acc: 0.5000\t Val F1: 0.0000\t Val AUC: 0.5693\n",
      "Total val_time took 0.40 minutes \n",
      "model saved\n",
      "\n",
      "Total training took 1.05 minutes\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.1110, -0.0205],\n",
      "        [ 0.0710, -0.1042],\n",
      "        [ 0.1958, -0.0242],\n",
      "        [ 0.0775, -0.0172],\n",
      "        [ 0.0011, -0.1690],\n",
      "        [ 0.0809, -0.0052],\n",
      "        [ 0.1500, -0.1289],\n",
      "        [ 0.1544, -0.0450],\n",
      "        [ 0.2056, -0.1727],\n",
      "        [ 0.1433, -0.0548],\n",
      "        [ 0.0813, -0.0230],\n",
      "        [ 0.1447, -0.1025],\n",
      "        [ 0.1515,  0.0287],\n",
      "        [ 0.0658, -0.0262],\n",
      "        [ 0.1454, -0.0775],\n",
      "        [ 0.0937,  0.0014],\n",
      "        [ 0.1010, -0.0131],\n",
      "        [ 0.0770, -0.1038],\n",
      "        [ 0.0591, -0.0394],\n",
      "        [ 0.1053, -0.0868],\n",
      "        [ 0.1713, -0.0154],\n",
      "        [ 0.0883, -0.0691],\n",
      "        [ 0.1163, -0.0493],\n",
      "        [ 0.1714,  0.0275],\n",
      "        [ 0.1661, -0.1502],\n",
      "        [ 0.0599, -0.1342],\n",
      "        [ 0.0475, -0.0890],\n",
      "        [ 0.1016, -0.0744],\n",
      "        [ 0.1766, -0.0065],\n",
      "        [ 0.1663, -0.1439],\n",
      "        [ 0.0988, -0.0535],\n",
      "        [ 0.1589, -0.0610],\n",
      "        [ 0.1467,  0.0288],\n",
      "        [ 0.1253, -0.0727],\n",
      "        [ 0.2054, -0.0070],\n",
      "        [ 0.0720, -0.0039],\n",
      "        [ 0.1617, -0.1190],\n",
      "        [ 0.1287, -0.0508],\n",
      "        [ 0.1638, -0.0587],\n",
      "        [ 0.1688, -0.1149],\n",
      "        [ 0.0812, -0.0096],\n",
      "        [ 0.0884, -0.0940],\n",
      "        [ 0.0594, -0.0852],\n",
      "        [ 0.1369, -0.0701],\n",
      "        [ 0.1360, -0.0964],\n",
      "        [ 0.1004,  0.0176],\n",
      "        [ 0.1086, -0.0598],\n",
      "        [ 0.1128, -0.0754],\n",
      "        [ 0.0842, -0.0128],\n",
      "        [ 0.1032, -0.0555],\n",
      "        [ 0.1280, -0.0135],\n",
      "        [ 0.0730, -0.0550],\n",
      "        [ 0.1442, -0.0076],\n",
      "        [ 0.1424,  0.0737],\n",
      "        [ 0.2241, -0.0847],\n",
      "        [ 0.1533, -0.0482],\n",
      "        [ 0.1341, -0.0192],\n",
      "        [ 0.1742, -0.0543],\n",
      "        [ 0.1596, -0.0351],\n",
      "        [ 0.1009,  0.0152],\n",
      "        [ 0.0888, -0.0057],\n",
      "        [ 0.0862, -0.0194],\n",
      "        [ 0.0833, -0.0011],\n",
      "        [ 0.1027, -0.0787]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1]\n",
      "logits:  tensor([[ 1.2859e-01, -5.3869e-02],\n",
      "        [ 8.6459e-02, -4.4895e-04],\n",
      "        [ 7.7687e-02, -1.2899e-01],\n",
      "        [ 9.1247e-02, -1.8200e-02],\n",
      "        [ 1.0665e-01, -1.9736e-01],\n",
      "        [ 7.5296e-02,  5.8133e-05],\n",
      "        [ 1.5315e-01, -1.0915e-01],\n",
      "        [ 9.7655e-02, -7.1333e-02],\n",
      "        [ 1.5894e-01, -1.0778e-01],\n",
      "        [ 1.2798e-01, -7.8705e-02],\n",
      "        [ 1.5851e-01,  1.6052e-02],\n",
      "        [ 1.0719e-01, -1.0640e-01],\n",
      "        [ 9.0152e-02, -1.6053e-02],\n",
      "        [ 2.1985e-01, -5.4539e-02],\n",
      "        [ 1.1899e-01, -3.7518e-02],\n",
      "        [ 1.0268e-01, -6.0925e-02],\n",
      "        [ 1.8903e-01, -4.6404e-02],\n",
      "        [ 1.3333e-01, -8.2975e-02],\n",
      "        [ 6.8901e-02, -7.1307e-02],\n",
      "        [ 1.4522e-01, -1.2303e-01],\n",
      "        [ 1.0507e-01, -9.8169e-02],\n",
      "        [ 1.8775e-01, -3.6324e-02],\n",
      "        [ 9.9372e-02,  5.5432e-03],\n",
      "        [ 7.3058e-02, -9.1920e-03],\n",
      "        [ 7.9989e-02, -1.4713e-02],\n",
      "        [ 9.1116e-02, -1.4483e-02],\n",
      "        [ 1.0374e-01, -1.3286e-01],\n",
      "        [ 3.4191e-02, -1.8259e-01],\n",
      "        [ 1.0389e-01, -6.1102e-02],\n",
      "        [ 1.3345e-01, -1.1028e-01],\n",
      "        [ 9.1067e-02,  7.0560e-03],\n",
      "        [ 1.4111e-01, -1.0558e-01],\n",
      "        [ 1.3319e-01, -1.9209e-01],\n",
      "        [ 9.9048e-02, -1.3656e-02],\n",
      "        [ 1.6462e-01, -1.2412e-01],\n",
      "        [ 1.7167e-01, -8.9963e-02],\n",
      "        [ 7.1839e-02, -1.0663e-03],\n",
      "        [ 8.9077e-02,  1.1206e-02],\n",
      "        [ 1.8980e-01, -8.8372e-02],\n",
      "        [ 1.3842e-01, -9.3430e-02],\n",
      "        [ 4.5211e-02, -1.7837e-01],\n",
      "        [ 1.5075e-01, -5.0198e-02],\n",
      "        [ 1.6331e-01, -5.5418e-02],\n",
      "        [ 1.0934e-01, -1.1999e-01],\n",
      "        [ 1.8097e-01, -1.3365e-01],\n",
      "        [ 1.1745e-01, -7.7540e-02],\n",
      "        [ 1.5141e-01, -9.2167e-02],\n",
      "        [ 1.1661e-01, -1.0113e-01],\n",
      "        [ 1.9374e-01, -1.0071e-01],\n",
      "        [ 1.0881e-01,  2.0237e-02],\n",
      "        [ 1.1799e-01, -1.1886e-01],\n",
      "        [ 8.1419e-02, -1.9067e-03],\n",
      "        [ 1.7520e-01,  6.3003e-02],\n",
      "        [ 9.9063e-02, -9.3432e-02],\n",
      "        [ 1.0518e-01, -1.3164e-01],\n",
      "        [ 8.0953e-02, -2.5071e-02],\n",
      "        [ 3.6603e-02, -3.9585e-02],\n",
      "        [ 7.7877e-02, -1.5811e-01],\n",
      "        [ 1.4714e-01, -1.1634e-01],\n",
      "        [ 8.5159e-02, -1.2223e-01],\n",
      "        [ 1.6258e-01, -5.1359e-02],\n",
      "        [ 8.5737e-02, -1.6860e-02],\n",
      "        [ 9.6700e-02, -1.1288e-01],\n",
      "        [ 8.4808e-02, -6.9967e-03]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 1 0 1 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1]\n",
      "logits:  tensor([[ 0.1278, -0.1299],\n",
      "        [ 0.1283, -0.1902],\n",
      "        [ 0.1257, -0.0980],\n",
      "        [ 0.0955, -0.1056],\n",
      "        [ 0.0738, -0.0116],\n",
      "        [ 0.0469, -0.1350]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0]\n",
      "train_true_bools [1 0 1 1 1 0]\n",
      "Total training_time took 0.65 minutes \n",
      "training acc 67 134\n",
      "\n",
      "Running Validation...\n",
      "Epoch 2\t Train Loss: 0.6962\t  Train ACC: 0.5000\t Val Loss 0.7216\t Val Acc: 0.5000\t Val F1: 0.0000\t Val AUC: 0.5840\n",
      "Total val_time took 0.41 minutes \n",
      "\n",
      "Total training took 2.12 minutes\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.1928, -0.0420],\n",
      "        [ 0.0775, -0.0088],\n",
      "        [ 0.0800, -0.0947],\n",
      "        [ 0.1729,  0.0301],\n",
      "        [ 0.1253, -0.1340],\n",
      "        [ 0.0867, -0.1663],\n",
      "        [ 0.0814, -0.0022],\n",
      "        [ 0.0492, -0.0472],\n",
      "        [ 0.1678, -0.0470],\n",
      "        [ 0.1606, -0.1289],\n",
      "        [ 0.1456, -0.0453],\n",
      "        [ 0.0944,  0.0016],\n",
      "        [ 0.0851,  0.0011],\n",
      "        [ 0.2393, -0.0178],\n",
      "        [ 0.0813, -0.0166],\n",
      "        [ 0.2112, -0.1636],\n",
      "        [-0.0182, -0.2764],\n",
      "        [ 0.1089, -0.0216],\n",
      "        [ 0.1049, -0.2108],\n",
      "        [ 0.0797, -0.0013],\n",
      "        [ 0.0953, -0.1055],\n",
      "        [ 0.1099, -0.0247],\n",
      "        [ 0.0812, -0.2240],\n",
      "        [ 0.0676, -0.0432],\n",
      "        [ 0.2116,  0.0168],\n",
      "        [ 0.1310, -0.0205],\n",
      "        [ 0.1700, -0.0615],\n",
      "        [ 0.0685, -0.0987],\n",
      "        [ 0.1331, -0.0981],\n",
      "        [ 0.2242, -0.0135],\n",
      "        [ 0.2006, -0.0969],\n",
      "        [ 0.1424, -0.0926],\n",
      "        [ 0.0795, -0.0076],\n",
      "        [ 0.1060, -0.1009],\n",
      "        [ 0.0979, -0.0855],\n",
      "        [ 0.1649, -0.0020],\n",
      "        [ 0.1531, -0.1507],\n",
      "        [ 0.1663, -0.0161],\n",
      "        [ 0.1836, -0.0589],\n",
      "        [ 0.1196, -0.2152],\n",
      "        [ 0.0758, -0.0094],\n",
      "        [ 0.1422, -0.0805],\n",
      "        [ 0.1447, -0.1613],\n",
      "        [ 0.1610, -0.0966],\n",
      "        [ 0.1541, -0.1394],\n",
      "        [ 0.0677, -0.0884],\n",
      "        [ 0.0863, -0.1202],\n",
      "        [ 0.1189, -0.1319],\n",
      "        [ 0.1383, -0.0351],\n",
      "        [ 0.0497, -0.1802],\n",
      "        [ 0.0744, -0.0419],\n",
      "        [ 0.1199, -0.0582],\n",
      "        [ 0.1610, -0.0933],\n",
      "        [ 0.0935, -0.0181],\n",
      "        [ 0.1843, -0.0913],\n",
      "        [ 0.0909, -0.0159],\n",
      "        [ 0.0489, -0.1586],\n",
      "        [ 0.0614, -0.0918],\n",
      "        [ 0.0856, -0.0203],\n",
      "        [ 0.1969, -0.1124],\n",
      "        [ 0.1590, -0.1386],\n",
      "        [ 0.1740, -0.1455],\n",
      "        [ 0.0798, -0.0090],\n",
      "        [ 0.0822, -0.0096]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1]\n",
      "logits:  tensor([[ 0.0830,  0.0005],\n",
      "        [ 0.0520, -0.2751],\n",
      "        [ 0.1532, -0.0814],\n",
      "        [ 0.2287, -0.1289],\n",
      "        [ 0.1700, -0.0425],\n",
      "        [ 0.1634, -0.0763],\n",
      "        [ 0.2368, -0.1181],\n",
      "        [ 0.0987, -0.2034],\n",
      "        [ 0.1466, -0.1516],\n",
      "        [ 0.1306,  0.0007],\n",
      "        [ 0.0854, -0.0982],\n",
      "        [ 0.0756, -0.0152],\n",
      "        [ 0.0786,  0.0021],\n",
      "        [ 0.1122, -0.0723],\n",
      "        [ 0.0599, -0.0344],\n",
      "        [ 0.1540, -0.0565],\n",
      "        [ 0.1872, -0.1021],\n",
      "        [ 0.1190, -0.0430],\n",
      "        [ 0.1210, -0.1316],\n",
      "        [ 0.0765, -0.1624],\n",
      "        [ 0.1593, -0.1621],\n",
      "        [ 0.0894, -0.0745],\n",
      "        [ 0.0961, -0.1599],\n",
      "        [ 0.0859, -0.1015],\n",
      "        [ 0.0900,  0.0050],\n",
      "        [ 0.1939, -0.0585],\n",
      "        [ 0.1016, -0.0946],\n",
      "        [ 0.1236, -0.1574],\n",
      "        [ 0.1771, -0.1726],\n",
      "        [ 0.1970, -0.0129],\n",
      "        [ 0.1521, -0.1008],\n",
      "        [ 0.1450, -0.0765],\n",
      "        [ 0.1806, -0.0401],\n",
      "        [ 0.0843, -0.0671],\n",
      "        [ 0.1121, -0.0844],\n",
      "        [ 0.0919, -0.0068],\n",
      "        [ 0.0781,  0.0090],\n",
      "        [ 0.1368, -0.2232],\n",
      "        [ 0.1533, -0.1203],\n",
      "        [ 0.1192, -0.1095],\n",
      "        [ 0.1708, -0.0184],\n",
      "        [ 0.0497, -0.0597],\n",
      "        [ 0.1547, -0.0257],\n",
      "        [ 0.0899, -0.0056],\n",
      "        [ 0.1113, -0.2009],\n",
      "        [ 0.0905, -0.0191],\n",
      "        [ 0.1220, -0.1526],\n",
      "        [ 0.1663,  0.0246],\n",
      "        [ 0.2386, -0.0733],\n",
      "        [ 0.0802, -0.0147],\n",
      "        [ 0.1426, -0.0810],\n",
      "        [ 0.0817,  0.0232],\n",
      "        [ 0.1339, -0.1668],\n",
      "        [ 0.0877, -0.0095],\n",
      "        [ 0.1313, -0.1201],\n",
      "        [ 0.1385, -0.1223],\n",
      "        [ 0.1390, -0.1058],\n",
      "        [ 0.0898, -0.1550],\n",
      "        [ 0.1594, -0.2025],\n",
      "        [ 0.0518, -0.1919],\n",
      "        [ 0.1359, -0.0184],\n",
      "        [ 0.1762, -0.1215],\n",
      "        [ 0.1452, -0.0089],\n",
      "        [ 0.2177, -0.0221]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0]\n",
      "logits:  tensor([[ 0.1295, -0.1239],\n",
      "        [ 0.0813, -0.0605],\n",
      "        [ 0.2135, -0.0730],\n",
      "        [ 0.1479, -0.0276],\n",
      "        [ 0.0790, -0.0130],\n",
      "        [ 0.0901, -0.0661]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0]\n",
      "train_true_bools [1 1 0 1 1 0]\n",
      "Total training_time took 0.65 minutes \n",
      "training acc 67 134\n",
      "\n",
      "Running Validation...\n",
      "Epoch 3\t Train Loss: 0.6931\t  Train ACC: 0.5000\t Val Loss 0.7144\t Val Acc: 0.5000\t Val F1: 0.0000\t Val AUC: 0.5941\n",
      "Total val_time took 0.41 minutes \n",
      "\n",
      "Total training took 3.18 minutes\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 1.6133e-01, -1.2563e-01],\n",
      "        [ 5.5366e-02, -1.4968e-01],\n",
      "        [ 1.7528e-01, -2.6003e-01],\n",
      "        [ 1.0135e-01, -8.0328e-02],\n",
      "        [ 7.3331e-02, -1.0494e-02],\n",
      "        [ 1.0353e-01, -1.9517e-02],\n",
      "        [ 9.9088e-02,  3.0348e-05],\n",
      "        [ 9.5124e-02, -1.8261e-01],\n",
      "        [ 2.0004e-01,  1.2467e-02],\n",
      "        [ 8.5442e-02, -9.1639e-03],\n",
      "        [ 6.8548e-02, -7.7247e-02],\n",
      "        [ 2.0465e-01, -1.4163e-01],\n",
      "        [ 6.7302e-02, -9.6154e-02],\n",
      "        [-4.6169e-03, -1.9496e-01],\n",
      "        [ 1.2093e-01, -2.0192e-01],\n",
      "        [ 4.0996e-02, -1.0126e-01],\n",
      "        [ 8.0166e-02, -1.4429e-03],\n",
      "        [ 1.3153e-01, -1.7600e-01],\n",
      "        [ 9.1718e-02, -9.3024e-03],\n",
      "        [ 1.9938e-01, -1.2078e-01],\n",
      "        [ 8.7392e-02, -1.5231e-01],\n",
      "        [ 2.0716e-01, -9.2678e-02],\n",
      "        [ 1.6635e-01, -8.3984e-02],\n",
      "        [ 1.0975e-01, -1.3276e-01],\n",
      "        [ 1.2275e-01, -2.2874e-02],\n",
      "        [ 4.3785e-02, -1.5633e-01],\n",
      "        [ 8.4486e-02, -5.6242e-04],\n",
      "        [ 8.0711e-02, -1.5081e-01],\n",
      "        [ 1.5228e-01, -1.5537e-01],\n",
      "        [ 7.6099e-02, -7.9000e-02],\n",
      "        [ 5.5726e-02, -2.3362e-02],\n",
      "        [ 8.7321e-02, -8.0598e-03],\n",
      "        [ 1.6395e-01, -3.4773e-02],\n",
      "        [ 2.4482e-01, -3.3981e-02],\n",
      "        [ 1.5202e-01, -1.1529e-01],\n",
      "        [ 9.6636e-02, -1.7524e-01],\n",
      "        [ 1.3049e-01,  2.5729e-03],\n",
      "        [ 1.9324e-01, -1.1520e-01],\n",
      "        [ 2.2454e-01,  7.6254e-03],\n",
      "        [ 1.3724e-01, -1.2777e-01],\n",
      "        [ 6.2519e-02, -1.2343e-01],\n",
      "        [ 1.7380e-01, -1.9259e-01],\n",
      "        [ 1.2700e-01, -9.0040e-02],\n",
      "        [ 3.2473e-02, -1.0307e-01],\n",
      "        [ 1.4605e-01, -1.4896e-01],\n",
      "        [ 5.6812e-02, -1.0395e-01],\n",
      "        [ 1.7102e-01, -1.1881e-01],\n",
      "        [ 1.2494e-02, -7.7965e-02],\n",
      "        [ 1.1056e-01, -1.3553e-01],\n",
      "        [ 2.0443e-01, -5.8773e-02],\n",
      "        [ 1.9191e-01, -9.7045e-02],\n",
      "        [ 9.6118e-02, -3.0005e-03],\n",
      "        [ 1.6871e-01, -2.1844e-01],\n",
      "        [ 8.3848e-02, -1.6191e-03],\n",
      "        [ 3.9260e-02, -1.6585e-01],\n",
      "        [ 5.1003e-02, -8.4922e-02],\n",
      "        [ 1.1139e-01, -1.2318e-01],\n",
      "        [ 1.3853e-01, -1.1734e-01],\n",
      "        [ 7.0386e-02, -2.2264e-02],\n",
      "        [ 7.8550e-02, -1.2597e-01],\n",
      "        [ 8.0470e-02, -2.2534e-02],\n",
      "        [ 1.4701e-01, -7.3182e-02],\n",
      "        [ 3.4318e-02, -1.8152e-01],\n",
      "        [ 1.4226e-01, -8.1053e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 0 0]\n",
      "logits:  tensor([[ 0.1310,  0.0117],\n",
      "        [ 0.1263, -0.0653],\n",
      "        [ 0.0642, -0.1520],\n",
      "        [ 0.0490, -0.0596],\n",
      "        [ 0.0692, -0.1114],\n",
      "        [ 0.1525, -0.1043],\n",
      "        [ 0.1127, -0.1228],\n",
      "        [ 0.0837, -0.1709],\n",
      "        [ 0.1138,  0.0463],\n",
      "        [ 0.0877, -0.0493],\n",
      "        [ 0.1417, -0.0685],\n",
      "        [ 0.0826, -0.0937],\n",
      "        [ 0.0957, -0.0110],\n",
      "        [ 0.1540, -0.0844],\n",
      "        [ 0.0905, -0.0090],\n",
      "        [ 0.0235, -0.2267],\n",
      "        [ 0.0837, -0.1280],\n",
      "        [ 0.0517, -0.0433],\n",
      "        [ 0.0928, -0.0948],\n",
      "        [ 0.1868, -0.1425],\n",
      "        [ 0.1266, -0.0999],\n",
      "        [ 0.0911,  0.0037],\n",
      "        [ 0.1004, -0.1271],\n",
      "        [ 0.1369, -0.1151],\n",
      "        [ 0.1942, -0.0735],\n",
      "        [ 0.0556, -0.0507],\n",
      "        [ 0.2138, -0.0942],\n",
      "        [ 0.1275, -0.1000],\n",
      "        [ 0.0944, -0.1626],\n",
      "        [ 0.1051, -0.0873],\n",
      "        [ 0.1810, -0.0246],\n",
      "        [ 0.1344, -0.0263],\n",
      "        [ 0.2330, -0.1159],\n",
      "        [ 0.0940, -0.0064],\n",
      "        [ 0.2349, -0.1443],\n",
      "        [ 0.0875, -0.0205],\n",
      "        [ 0.0725, -0.0736],\n",
      "        [ 0.0893, -0.0099],\n",
      "        [ 0.0368, -0.1238],\n",
      "        [ 0.1311, -0.1482],\n",
      "        [ 0.1130, -0.0746],\n",
      "        [ 0.2138, -0.0412],\n",
      "        [ 0.0642,  0.0146],\n",
      "        [ 0.2262, -0.1466],\n",
      "        [ 0.0769, -0.1706],\n",
      "        [ 0.0279, -0.1081],\n",
      "        [ 0.1236, -0.1931],\n",
      "        [ 0.1808, -0.0183],\n",
      "        [ 0.1791, -0.0824],\n",
      "        [ 0.0788, -0.0127],\n",
      "        [ 0.0867, -0.0073],\n",
      "        [ 0.0794, -0.0351],\n",
      "        [ 0.0913, -0.0359],\n",
      "        [ 0.0658, -0.0771],\n",
      "        [ 0.0761, -0.1585],\n",
      "        [ 0.0874, -0.0627],\n",
      "        [ 0.1091, -0.0486],\n",
      "        [ 0.1407, -0.1700],\n",
      "        [ 0.1339, -0.0492],\n",
      "        [ 0.1565, -0.0489],\n",
      "        [ 0.1442, -0.0646],\n",
      "        [ 0.0286, -0.1469],\n",
      "        [ 0.1243, -0.1144],\n",
      "        [ 0.1681,  0.0061]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1\n",
      " 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 0]\n",
      "logits:  tensor([[ 0.0862, -0.0021],\n",
      "        [ 0.0837, -0.0113],\n",
      "        [ 0.0797,  0.0040],\n",
      "        [ 0.1341, -0.0078],\n",
      "        [ 0.1281, -0.0557],\n",
      "        [ 0.1394, -0.1150]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0]\n",
      "train_true_bools [1 1 1 1 1 1]\n",
      "Total training_time took 0.64 minutes \n",
      "training acc 67 134\n",
      "\n",
      "Running Validation...\n",
      "Epoch 4\t Train Loss: 0.7021\t  Train ACC: 0.5000\t Val Loss 0.7201\t Val Acc: 0.5000\t Val F1: 0.0000\t Val AUC: 0.6079\n",
      "Total val_time took 0.40 minutes \n",
      "\n",
      "Total training took 4.22 minutes\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 0.1001, -0.0392],\n",
      "        [ 0.1052, -0.0533],\n",
      "        [ 0.1396, -0.0633],\n",
      "        [ 0.1778, -0.0813],\n",
      "        [ 0.1332, -0.2231],\n",
      "        [ 0.0810, -0.0259],\n",
      "        [ 0.1152, -0.0936],\n",
      "        [ 0.0461, -0.0520],\n",
      "        [ 0.1681, -0.0486],\n",
      "        [-0.0170, -0.0844],\n",
      "        [ 0.1391, -0.0251],\n",
      "        [ 0.1552, -0.0874],\n",
      "        [ 0.1487, -0.0176],\n",
      "        [ 0.1141, -0.0474],\n",
      "        [ 0.0600, -0.0820],\n",
      "        [ 0.1146, -0.1465],\n",
      "        [ 0.1766, -0.1362],\n",
      "        [ 0.1272, -0.0585],\n",
      "        [ 0.1366, -0.1014],\n",
      "        [ 0.1351, -0.2012],\n",
      "        [ 0.1381, -0.0905],\n",
      "        [ 0.1485, -0.0978],\n",
      "        [ 0.1848, -0.0714],\n",
      "        [ 0.0706, -0.2583],\n",
      "        [ 0.1266, -0.1501],\n",
      "        [ 0.1385, -0.2053],\n",
      "        [ 0.0660, -0.0724],\n",
      "        [ 0.1722, -0.0870],\n",
      "        [ 0.1534, -0.0304],\n",
      "        [ 0.0924, -0.0021],\n",
      "        [ 0.1134, -0.2030],\n",
      "        [ 0.0690, -0.1704],\n",
      "        [ 0.1576, -0.1232],\n",
      "        [ 0.0485, -0.1242],\n",
      "        [ 0.1128, -0.1171],\n",
      "        [ 0.1174, -0.0376],\n",
      "        [ 0.1581, -0.2109],\n",
      "        [ 0.0141, -0.1214],\n",
      "        [ 0.1551, -0.0867],\n",
      "        [ 0.0910, -0.1452],\n",
      "        [ 0.1843, -0.0609],\n",
      "        [ 0.0898,  0.0056],\n",
      "        [ 0.1704, -0.0824],\n",
      "        [ 0.2222,  0.0152],\n",
      "        [ 0.1150, -0.1009],\n",
      "        [ 0.1477, -0.1009],\n",
      "        [ 0.1854, -0.0032],\n",
      "        [ 0.1579,  0.0006],\n",
      "        [ 0.0781, -0.0143],\n",
      "        [ 0.0632, -0.1769],\n",
      "        [ 0.1751, -0.0292],\n",
      "        [ 0.0894, -0.0200],\n",
      "        [ 0.1125, -0.0798],\n",
      "        [ 0.0757, -0.0050],\n",
      "        [ 0.0848, -0.0154],\n",
      "        [ 0.0807, -0.0448],\n",
      "        [ 0.1358, -0.0646],\n",
      "        [ 0.1253, -0.0631],\n",
      "        [ 0.2100, -0.0794],\n",
      "        [ 0.1479, -0.0674],\n",
      "        [ 0.0767, -0.2131],\n",
      "        [ 0.1338, -0.0792],\n",
      "        [ 0.0820, -0.0032],\n",
      "        [ 0.0365, -0.0058]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [0 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1]\n",
      "logits:  tensor([[ 0.0803, -0.0135],\n",
      "        [ 0.0733, -0.1758],\n",
      "        [ 0.1311, -0.1354],\n",
      "        [ 0.0780, -0.0432],\n",
      "        [ 0.1560, -0.0363],\n",
      "        [ 0.1588, -0.0798],\n",
      "        [ 0.1431, -0.1246],\n",
      "        [ 0.1465,  0.0154],\n",
      "        [ 0.1533,  0.0064],\n",
      "        [ 0.1609, -0.0198],\n",
      "        [ 0.0663, -0.0108],\n",
      "        [ 0.1303, -0.0900],\n",
      "        [ 0.0923, -0.0041],\n",
      "        [ 0.0535, -0.0575],\n",
      "        [ 0.1249, -0.0169],\n",
      "        [ 0.1748, -0.0969],\n",
      "        [ 0.0871, -0.0233],\n",
      "        [ 0.0695, -0.0548],\n",
      "        [ 0.0972, -0.1024],\n",
      "        [ 0.1404, -0.1020],\n",
      "        [ 0.0923, -0.1746],\n",
      "        [ 0.1285, -0.1572],\n",
      "        [ 0.0304, -0.1281],\n",
      "        [ 0.0426, -0.0582],\n",
      "        [ 0.1173, -0.0481],\n",
      "        [ 0.1160,  0.0607],\n",
      "        [ 0.0889, -0.0197],\n",
      "        [ 0.1267, -0.1672],\n",
      "        [ 0.1707, -0.0648],\n",
      "        [ 0.0943, -0.0877],\n",
      "        [ 0.1160, -0.0798],\n",
      "        [ 0.1550, -0.1324],\n",
      "        [ 0.0423, -0.1113],\n",
      "        [ 0.0599, -0.0977],\n",
      "        [ 0.0887, -0.0053],\n",
      "        [ 0.0446, -0.0910],\n",
      "        [ 0.1007, -0.1631],\n",
      "        [ 0.1973,  0.0268],\n",
      "        [ 0.1606, -0.2364],\n",
      "        [ 0.0981, -0.1106],\n",
      "        [ 0.0886, -0.0106],\n",
      "        [ 0.1145, -0.1610],\n",
      "        [ 0.1337, -0.0140],\n",
      "        [ 0.0919, -0.0024],\n",
      "        [ 0.0392, -0.1326],\n",
      "        [ 0.1357, -0.0693],\n",
      "        [ 0.0850, -0.0094],\n",
      "        [ 0.0587, -0.1483],\n",
      "        [ 0.0932, -0.0058],\n",
      "        [ 0.0951, -0.0030],\n",
      "        [ 0.1576, -0.2435],\n",
      "        [ 0.0897,  0.0053],\n",
      "        [ 0.0805, -0.0663],\n",
      "        [ 0.2025, -0.0585],\n",
      "        [ 0.1556, -0.0318],\n",
      "        [ 0.1376, -0.0779],\n",
      "        [ 0.1416, -0.1633],\n",
      "        [ 0.0799, -0.0826],\n",
      "        [ 0.0895, -0.0102],\n",
      "        [ 0.1691, -0.1075],\n",
      "        [ 0.0810, -0.0933],\n",
      "        [ 0.0602, -0.1751],\n",
      "        [ 0.1760, -0.0122],\n",
      "        [ 0.0916, -0.0073]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0\n",
      " 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0]\n",
      "logits:  tensor([[ 0.1544, -0.1739],\n",
      "        [ 0.0927, -0.0057],\n",
      "        [ 0.1087, -0.0776],\n",
      "        [ 0.0267, -0.1666],\n",
      "        [ 0.0858, -0.1366],\n",
      "        [ 0.1741, -0.0277]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0]\n",
      "train_true_bools [0 0 1 0 1 0]\n",
      "Total training_time took 0.65 minutes \n",
      "training acc 67 134\n",
      "\n",
      "Running Validation...\n",
      "Epoch 5\t Train Loss: 0.6840\t  Train ACC: 0.5000\t Val Loss 0.7108\t Val Acc: 0.5000\t Val F1: 0.0000\t Val AUC: 0.6263\n",
      "Total val_time took 0.42 minutes \n",
      "\n",
      "Total training took 5.29 minutes\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "logits:  tensor([[ 1.2076e-01, -9.2149e-02],\n",
      "        [ 1.9071e-01, -4.2179e-02],\n",
      "        [ 7.7282e-02, -2.1540e-01],\n",
      "        [ 6.3421e-02, -8.0221e-02],\n",
      "        [ 8.7332e-02, -4.6848e-03],\n",
      "        [ 1.5747e-02, -1.2413e-01],\n",
      "        [ 1.1918e-01, -3.7662e-02],\n",
      "        [ 1.1658e-01, -6.9047e-02],\n",
      "        [ 8.1273e-02, -1.7685e-02],\n",
      "        [ 1.1782e-01, -8.9630e-02],\n",
      "        [ 5.1456e-02, -6.0774e-02],\n",
      "        [ 4.3532e-02, -8.4157e-02],\n",
      "        [ 1.8688e-01, -4.7016e-02],\n",
      "        [ 4.0990e-02, -9.4528e-02],\n",
      "        [ 1.9979e-02, -1.4619e-01],\n",
      "        [ 9.2711e-02, -9.4638e-02],\n",
      "        [ 1.9350e-01, -7.5917e-02],\n",
      "        [ 7.3214e-02, -1.3606e-04],\n",
      "        [ 8.5438e-02,  6.4121e-03],\n",
      "        [ 5.3050e-02, -8.2122e-02],\n",
      "        [ 1.0662e-01, -3.2258e-02],\n",
      "        [ 8.9718e-02,  2.2283e-03],\n",
      "        [ 1.5339e-01,  2.5194e-02],\n",
      "        [ 7.1138e-02, -1.9320e-01],\n",
      "        [ 7.4483e-02, -4.9586e-02],\n",
      "        [ 1.6772e-01, -1.8698e-02],\n",
      "        [ 1.7113e-01, -9.3960e-02],\n",
      "        [ 1.2313e-01, -8.4030e-02],\n",
      "        [ 2.1881e-01, -5.7230e-02],\n",
      "        [ 8.6211e-02, -7.1476e-03],\n",
      "        [ 4.2590e-02, -3.9998e-02],\n",
      "        [ 1.8086e-01, -1.3686e-01],\n",
      "        [ 1.8207e-01, -1.5604e-02],\n",
      "        [ 2.6634e-02, -4.7628e-02],\n",
      "        [ 8.6726e-02, -1.7130e-02],\n",
      "        [ 7.6989e-02, -4.5535e-02],\n",
      "        [ 1.6258e-01, -1.0745e-01],\n",
      "        [ 9.6353e-02, -5.2012e-02],\n",
      "        [ 8.0067e-02,  1.5485e-02],\n",
      "        [ 6.5554e-02, -1.1359e-01],\n",
      "        [ 1.0231e-01, -5.0141e-03],\n",
      "        [ 4.7306e-02,  1.5124e-02],\n",
      "        [ 4.7042e-02, -1.2626e-01],\n",
      "        [ 9.7164e-02, -1.5963e-01],\n",
      "        [ 1.4306e-01, -1.3600e-01],\n",
      "        [ 6.3197e-02, -1.3637e-01],\n",
      "        [ 2.2493e-01, -1.2305e-01],\n",
      "        [ 7.5066e-02, -3.5582e-03],\n",
      "        [ 1.6720e-01,  4.7036e-02],\n",
      "        [ 8.0226e-02,  3.4143e-04],\n",
      "        [ 1.3815e-01, -6.3149e-02],\n",
      "        [ 1.4998e-01, -9.7594e-02],\n",
      "        [ 8.5731e-02, -3.4165e-02],\n",
      "        [ 1.1804e-01, -1.0475e-01],\n",
      "        [ 6.5701e-02, -1.9783e-02],\n",
      "        [ 8.9129e-02, -4.7370e-02],\n",
      "        [ 3.9614e-02, -8.4798e-02],\n",
      "        [ 1.7568e-01, -3.5693e-02],\n",
      "        [ 2.2181e-01, -5.9378e-02],\n",
      "        [ 9.5171e-02, -1.9653e-01],\n",
      "        [ 1.1610e-01, -1.0488e-01],\n",
      "        [ 8.5950e-02, -1.9656e-02],\n",
      "        [ 1.0902e-01, -1.2288e-01],\n",
      "        [ 7.4022e-02, -5.7801e-02]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0\n",
      " 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0]\n",
      "logits:  tensor([[ 0.0848, -0.0098],\n",
      "        [ 0.1790, -0.0368],\n",
      "        [ 0.0711, -0.0183],\n",
      "        [ 0.1562, -0.0345],\n",
      "        [ 0.1745,  0.0200],\n",
      "        [ 0.0151, -0.1129],\n",
      "        [ 0.0803, -0.0153],\n",
      "        [ 0.0520,  0.0831],\n",
      "        [ 0.0836,  0.0064],\n",
      "        [ 0.1549, -0.0229],\n",
      "        [ 0.0547, -0.0649],\n",
      "        [ 0.0669, -0.1215],\n",
      "        [ 0.1721, -0.0805],\n",
      "        [ 0.0976, -0.1936],\n",
      "        [ 0.0888, -0.1234],\n",
      "        [ 0.1700, -0.1289],\n",
      "        [ 0.0854, -0.0014],\n",
      "        [ 0.0825, -0.0236],\n",
      "        [ 0.1265, -0.0790],\n",
      "        [ 0.1180, -0.0944],\n",
      "        [ 0.1389,  0.0124],\n",
      "        [ 0.0908, -0.0673],\n",
      "        [ 0.0917, -0.1488],\n",
      "        [ 0.0788, -0.0125],\n",
      "        [ 0.0718, -0.0516],\n",
      "        [ 0.0620, -0.1014],\n",
      "        [ 0.1231, -0.0355],\n",
      "        [ 0.0715, -0.0675],\n",
      "        [ 0.1493, -0.0239],\n",
      "        [ 0.0819,  0.0049],\n",
      "        [ 0.0740, -0.0517],\n",
      "        [ 0.1505,  0.0201],\n",
      "        [ 0.1400, -0.0615],\n",
      "        [ 0.0645,  0.0070],\n",
      "        [ 0.0863, -0.0082],\n",
      "        [ 0.1393, -0.0456],\n",
      "        [ 0.1857, -0.1123],\n",
      "        [ 0.1445, -0.0514],\n",
      "        [ 0.0783, -0.0339],\n",
      "        [ 0.1349,  0.0028],\n",
      "        [ 0.0945, -0.1132],\n",
      "        [ 0.1497, -0.0533],\n",
      "        [ 0.0910, -0.1162],\n",
      "        [ 0.0822, -0.0055],\n",
      "        [ 0.2201, -0.1354],\n",
      "        [ 0.1279,  0.0071],\n",
      "        [ 0.0846, -0.0062],\n",
      "        [ 0.1380, -0.1042],\n",
      "        [ 0.0388,  0.0534],\n",
      "        [ 0.0827, -0.0008],\n",
      "        [ 0.1875, -0.0303],\n",
      "        [ 0.1291, -0.0233],\n",
      "        [ 0.0819, -0.0060],\n",
      "        [ 0.0398, -0.0127],\n",
      "        [ 0.0546, -0.1788],\n",
      "        [ 0.1025, -0.0061],\n",
      "        [ 0.1106, -0.1066],\n",
      "        [ 0.0876,  0.0004],\n",
      "        [ 0.0382, -0.0723],\n",
      "        [ 0.1606, -0.0176],\n",
      "        [ 0.1233,  0.0054],\n",
      "        [ 0.2005, -0.1473],\n",
      "        [ 0.1089, -0.1734],\n",
      "        [ 0.0888, -0.1002]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "train_true_bools [1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 0 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0]\n",
      "logits:  tensor([[ 2.9581e-02, -2.1254e-01],\n",
      "        [ 1.9455e-01, -1.9543e-02],\n",
      "        [ 1.4784e-01, -7.9439e-02],\n",
      "        [ 8.3447e-02, -3.2676e-05],\n",
      "        [ 1.6038e-01, -9.4580e-02],\n",
      "        [ 2.2740e-02, -1.5595e-01]], device='cuda:1', grad_fn=<AddmmBackward0>)\n",
      "b_labels.type_as(logits):  tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]], device='cuda:1')\n",
      "train_pred_bools [0 0 0 0 0 0]\n",
      "train_true_bools [0 1 1 1 0 0]\n",
      "Total training_time took 0.65 minutes \n",
      "training acc 69 134\n",
      "\n",
      "Running Validation...\n",
      "Epoch 6\t Train Loss: 0.6873\t  Train ACC: 0.5149\t Val Loss 0.6666\t Val Acc: 0.5000\t Val F1: 0.0000\t Val AUC: 0.6281\n",
      "Total val_time took 0.41 minutes \n",
      "\n",
      "\n",
      "early stopping at epoch 6\n",
      "load the best model ... \n",
      "np.argmax for pred_labels [[0.5476167  0.45238322]\n",
      " [0.5242555  0.4757445 ]\n",
      " [0.5414101  0.45858988]\n",
      " [0.54302317 0.45697686]\n",
      " [0.5502292  0.4497708 ]\n",
      " [0.54465526 0.45534477]\n",
      " [0.5423084  0.4576916 ]\n",
      " [0.52276367 0.47723636]\n",
      " [0.54467267 0.4553274 ]\n",
      " [0.54061896 0.45938107]\n",
      " [0.54523236 0.4547676 ]\n",
      " [0.54939985 0.45060015]\n",
      " [0.55219597 0.44780397]\n",
      " [0.55110455 0.44889545]\n",
      " [0.54465175 0.45534825]\n",
      " [0.54943717 0.45056286]\n",
      " [0.542726   0.45727405]\n",
      " [0.54876596 0.45123398]\n",
      " [0.52424484 0.47575516]\n",
      " [0.5473098  0.4526902 ]\n",
      " [0.5450152  0.45498475]\n",
      " [0.5485512  0.45144883]\n",
      " [0.54575217 0.4542478 ]\n",
      " [0.5503406  0.4496594 ]\n",
      " [0.5424592  0.45754084]\n",
      " [0.54921913 0.45078084]\n",
      " [0.542332   0.457668  ]\n",
      " [0.5362275  0.4637725 ]\n",
      " [0.5408866  0.4591134 ]\n",
      " [0.5362668  0.46373323]\n",
      " [0.5242505  0.47574952]\n",
      " [0.5498643  0.4501357 ]\n",
      " [0.52486354 0.4751365 ]\n",
      " [0.54028106 0.45971894]\n",
      " [0.54261273 0.45738733]\n",
      " [0.553458   0.44654202]\n",
      " [0.54382885 0.45617115]\n",
      " [0.5506065  0.44939354]\n",
      " [0.5418479  0.45815215]\n",
      " [0.54080987 0.45919013]\n",
      " [0.5507706  0.4492294 ]\n",
      " [0.53678846 0.4632115 ]\n",
      " [0.5415067  0.45849326]\n",
      " [0.5426376  0.45736244]\n",
      " [0.5244935  0.47550645]\n",
      " [0.5551662  0.44483376]\n",
      " [0.5444112  0.4555888 ]\n",
      " [0.5239974  0.4760025 ]\n",
      " [0.5448606  0.4551394 ]\n",
      " [0.54147536 0.4585246 ]\n",
      " [0.5456251  0.45437488]\n",
      " [0.54095185 0.45904815]\n",
      " [0.5490801  0.45091996]\n",
      " [0.5480901  0.4519099 ]\n",
      " [0.5456241  0.45437595]\n",
      " [0.537254   0.46274608]\n",
      " [0.5484765  0.45152345]\n",
      " [0.53599894 0.46400106]\n",
      " [0.52473557 0.47526443]\n",
      " [0.545938   0.45406204]\n",
      " [0.54685533 0.45314467]\n",
      " [0.5222807  0.47771928]\n",
      " [0.5441192  0.45588082]\n",
      " [0.5448043  0.45519572]\n",
      " [0.5358848  0.46411523]\n",
      " [0.5458512  0.45414886]]\n",
      "np.argmax for true_labels [[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "Precision: 0.0000, Recall: 0.0000, F1: 0.0000, Loss: 0.7137, AUC: 0.5693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        33\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.50        66\n",
      "   macro avg       0.25      0.50      0.33        66\n",
      "weighted avg       0.25      0.50      0.33        66\n",
      "\n",
      "\n",
      "\n",
      "=== finish  === \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jujun/.conda/envs/jujun_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # If there's a GPU available...\n",
    "    if torch.cuda.is_available():    \n",
    "        # Tell PyTorch to use the GPU. \n",
    "        id = 1 \n",
    "        torch.cuda.set_device(1)\n",
    "        device = torch.device(\"cuda\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(id))\n",
    "        print(torch.cuda.current_device())\n",
    "    # If not...\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    # print(get_free_gpu())\n",
    "\n",
    "    # load data\n",
    "    para_map = pickle.load(open(\"/research/rliu/fraud/data/mda/paragraphs_1994_2016.pkl\",\"rb\"))\n",
    "    pos_neg_pair = pd.read_csv('./data/pos_neg_pair.csv')\n",
    "    pos_neg_pair = pos_neg_pair.dropna()\n",
    "\n",
    "    imbalance =False\n",
    "    if not imbalance:\n",
    "        pos_index = pos_neg_pair[pos_neg_pair.fraud == 1].index[0:100]\n",
    "        neg_index = pos_neg_pair[pos_neg_pair.fraud == 0].sample(len(pos_index)).index\n",
    "        df = pos_neg_pair.loc[neg_index.append(pos_index),:]\n",
    "        print(df.shape)\n",
    "    else:\n",
    "        pos_cik = list(set(pos_neg_pair[pos_neg_pair.fraud == 1].cik))\n",
    "        neg_cik = list(set(pos_neg_pair[pos_neg_pair.fraud == 0].cik))\n",
    "        neg_cik = [c for c in neg_cik if c not in pos_cik]\n",
    "        neg_cik = random.sample(neg_cik, len(pos_cik))\n",
    "        df = pos_neg_pair[pos_neg_pair.cik.isin(pos_cik[0:10] + neg_cik[0:10])]\n",
    "        print(df.shape)\n",
    "    print('successfully load data ...')\n",
    "    \n",
    "\n",
    "\n",
    "    emb_dim = siamese_config.emb_dim\n",
    "    wrd_len = siamese_config.wrd_len\n",
    "    para_len = siamese_config.para_len\n",
    "    num_filters = siamese_config.num_filters\n",
    "    kernel_sizes =  siamese_config.kernel_sizes\n",
    "    kernel_sizes2 = siamese_config.kernel_sizes2\n",
    "    kernel_sizes3 = siamese_config.kernel_sizes3\n",
    "    dropout_rate = siamese_config.dropout_rate\n",
    "    num_classes= siamese_config.num_classes\n",
    "    batch_size = siamese_config.batch_size\n",
    "    \n",
    "    siamese_config.set_parm_map(para_map)\n",
    "    para_map = siamese_config.para_map\n",
    "    class_weight = siamese_config.class_weight\n",
    "\n",
    "    set_ct_loss = False\n",
    "    result = []\n",
    "    val_label_save = []\n",
    "    val_true_label_save = []\n",
    "    label_cols = ['fraud']\n",
    "\n",
    "    # global my_ct_loss\n",
    "    # global my_sim\n",
    "    # global my_label\n",
    "\n",
    "    #embedding\n",
    "    print('Loading BERT tokenizer...')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "\n",
    "    bert_model = AutoModel.from_pretrained(\n",
    "        # 'ProsusAI/finbert',\n",
    "        'bert-base-uncased',\n",
    "        # 'yiyanghkust/finbert-pretrain',\n",
    "        num_labels = 2, \n",
    "        output_attentions = False, # Whether the model returns attentions weights.\n",
    "        output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "        )\n",
    "    bert_model.cuda()\n",
    "\n",
    "    for col in label_cols:\n",
    "        print(\"\\n------------\")\n",
    "        print(col)\n",
    "        print(\"------------\")\n",
    "\n",
    "        y = df[col].astype(int).values\n",
    "        x_key = df[['cik', 'fyear', 'fyear_bf']].values\n",
    "\n",
    "        fold = 0\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
    "\n",
    "        for train_index, test_index in skf.split(x_key, y):\n",
    "\n",
    "            print(\"\\nfold {} \\n\".format(fold))\n",
    "\n",
    "            fold += 1\n",
    "            X_train, X_test = x_key[train_index], x_key[test_index]\n",
    "            X_train = torch.tensor(X_train)\n",
    "            X_test = torch.tensor(X_test)\n",
    "\n",
    "            Y_train, Y_test = y[train_index], y[test_index]\n",
    "            print('train fraud', sum(Y_train),'test fraud', sum(Y_test))\n",
    "\n",
    "            Y_train = pd.get_dummies(Y_train).values\n",
    "            Y_train = torch.tensor(Y_train)\n",
    "\n",
    "            Y_test = pd.get_dummies(Y_test).values\n",
    "            Y_test = torch.tensor(Y_test)\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, Y_train)\n",
    "            val_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "            train_dataloader = DataLoader(\n",
    "                train_dataset,  # The training samples.\n",
    "                sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
    "                batch_size=batch_size  # Trains with this batch size.\n",
    "            )\n",
    "\n",
    "            validation_dataloader = DataLoader(\n",
    "                val_dataset,  # The validation samples.\n",
    "                sampler=RandomSampler(\n",
    "                    val_dataset),  # Pull out batches sequentially.\n",
    "                batch_size=batch_size  # Evaluate with this batch size.\n",
    "            )\n",
    "\n",
    "            if class_weight == None:\n",
    "                pass\n",
    "            else:\n",
    "                train_sample_weight = np.array(\n",
    "                    [class_weight if i[1] == 1 else 1 for i in Y_train])\n",
    "                test_sample_weight = np.array(\n",
    "                    [class_weight if i[1] == 1 else 1 for i in Y_test])\n",
    "\n",
    "            model_name = \"./model/simple_siamese_\" + str(fold)\n",
    "            #model = cnn(emb_dim, seq_len, num_filters, kernel_sizes, num_labels)\n",
    "            model = simple_siamese(siamese_config)\n",
    "            model.to(device)\n",
    "\n",
    "\n",
    "            model, training_stats = train_model(model, siamese_config, train_dataloader, validation_dataloader, \\\n",
    "                                                            model_path = model_name, class_weight = class_weight,\\\n",
    "                                                            optimizer=None, scheduler=None, epochs = 20)\n",
    "\n",
    "            print(\"load the best model ... \")\n",
    "\n",
    "            model.load_state_dict(torch.load(model_name))\n",
    "\n",
    "            # show performance of best model\n",
    "            model.eval()\n",
    "            pred_labels, true_labels,avg_val_loss = model_eval(model, \\\n",
    "                                                    validation_dataloader, num_classes, class_weight = class_weight)\n",
    "\n",
    "            pred_bools = np.argmax(pred_labels, axis = 1)\n",
    "            print(\"np.argmax for pred_labels\", pred_labels)\n",
    "            true_bools = np.argmax(true_labels, axis = 1)\n",
    "            print(\"np.argmax for true_labels\", true_labels)\n",
    "\n",
    "            p, r, f, _ = precision_recall_fscore_support(true_bools,pred_bools, pos_label = 1)\n",
    "            #val_f1 = f1_score(true_bools,pred_bools, average = None)*100\n",
    "            #val_f1 = val_f1[1] # return f1 for  class 1\n",
    "            val_acc = (pred_bools == true_bools).astype(int).sum()/len(pred_bools)\n",
    "            val_auc = roc_auc_score(true_bools, pred_labels[:,1])\n",
    "\n",
    "            print('Precision: {0:.4f}, Recall: {1:.4f}, F1: {2:.4f}, Loss: {3:.4f}, AUC: {4:.4f}'.format(p[1], r[1], f[1], avg_val_loss, val_auc))\n",
    "            print(classification_report(true_bools, pred_bools) )\n",
    "\n",
    "\n",
    "            result.append([col, fold, p[1], r[1], f[1], val_acc, val_auc,training_stats[-1][\"Best epoch\"]])\n",
    "            with open(\"./result/simple_siamese.pkl\", \"wb\") as fp:   #Pickling\n",
    "                pickle.dump(result, fp)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            get_free_gpu()\n",
    "    print('=== finish  === ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lista' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lista\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lista' is not defined"
     ]
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5074626865671642"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(lista) == np.array(listb)).sum()/len(listb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3543, 0.6457],\n",
       "        [0.4256, 0.5744]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([[1.2,1.8],[0.4,0.7]]),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_true_label_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label_save[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = val_label_save[0].sum(axis=1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.99999994, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.99999994, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99999994,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99999994, 0.99999994,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.99999994, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.99999994, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = val_label_save[-6][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5232506 , 0.52386016, 0.5344516 , 0.53550726, 0.5339036 ,\n",
       "       0.5286611 , 0.54368126, 0.52959067, 0.53475684, 0.5256853 ,\n",
       "       0.5267108 , 0.5245599 , 0.5256226 , 0.53362614, 0.5177412 ,\n",
       "       0.5290738 , 0.529948  , 0.52800107, 0.535685  , 0.5296777 ,\n",
       "       0.5218666 , 0.5270513 , 0.5201257 , 0.53249747, 0.52939105,\n",
       "       0.5444209 , 0.52398705, 0.52389795, 0.52814114, 0.5319519 ,\n",
       "       0.542003  , 0.52385616, 0.5255244 , 0.54056376, 0.53032464,\n",
       "       0.5200995 , 0.5266097 , 0.5445139 , 0.5436612 , 0.53760165,\n",
       "       0.52690154, 0.5336137 , 0.52661014, 0.5175091 , 0.5360116 ,\n",
       "       0.5146469 , 0.5444209 , 0.52182204, 0.52531785, 0.53059375,\n",
       "       0.52379906, 0.5237532 , 0.52738565, 0.537102  , 0.5298776 ,\n",
       "       0.5313965 , 0.5444209 , 0.5305427 , 0.53344834, 0.5347967 ,\n",
       "       0.5347793 , 0.53182554, 0.52058893, 0.5248482 , 0.5445116 ,\n",
       "       0.53187764, 0.52167225, 0.5279042 , 0.5444209 , 0.52309513,\n",
       "       0.5233589 , 0.526377  , 0.52767414, 0.53171754, 0.5278243 ,\n",
       "       0.5236914 , 0.53111106, 0.53145856, 0.53837997, 0.54021734,\n",
       "       0.52733415, 0.5444209 , 0.53894365, 0.5264531 , 0.52539766,\n",
       "       0.53347206, 0.5234432 , 0.52611053, 0.5307614 , 0.5311188 ,\n",
       "       0.5289063 , 0.5386362 , 0.5272374 , 0.5269312 , 0.5444209 ,\n",
       "       0.53484106, 0.5231909 , 0.53432584, 0.5374232 , 0.5363107 ,\n",
       "       0.52896607, 0.5376783 , 0.533387  , 0.5415936 , 0.5412273 ,\n",
       "       0.52701706, 0.52021104, 0.5239231 , 0.52942353, 0.54245305,\n",
       "       0.529255  , 0.53740704, 0.52882856, 0.533306  , 0.5441272 ,\n",
       "       0.5252909 , 0.52819705, 0.53995603, 0.5444209 , 0.53343064,\n",
       "       0.5361816 , 0.5289746 , 0.5301317 , 0.5172907 , 0.5324675 ,\n",
       "       0.5292827 , 0.5371292 , 0.53039557, 0.53041834, 0.5337891 ,\n",
       "       0.5444209 , 0.52287215, 0.52436435, 0.52656436, 0.5291967 ,\n",
       "       0.5348332 , 0.5428467 , 0.5214875 , 0.5444209 , 0.52779615,\n",
       "       0.5243266 , 0.5441867 , 0.5273261 , 0.53619254, 0.5222131 ,\n",
       "       0.52277625, 0.54400104, 0.53379697, 0.52685755, 0.5313955 ,\n",
       "       0.5437501 , 0.5254951 , 0.5351441 , 0.5294371 , 0.51996577,\n",
       "       0.5279399 , 0.5278855 , 0.53106725, 0.52615833, 0.5378316 ,\n",
       "       0.53071535, 0.536214  , 0.5286343 , 0.52578634, 0.53091645,\n",
       "       0.53429735, 0.5231423 , 0.52890855, 0.528456  , 0.53170615,\n",
       "       0.527932  , 0.52771556, 0.528957  , 0.52195334, 0.5333441 ,\n",
       "       0.5264274 , 0.5238866 , 0.524075  , 0.53413516, 0.54486275,\n",
       "       0.524945  , 0.52664983, 0.52691776, 0.5444209 , 0.5234715 ,\n",
       "       0.5202584 , 0.5346228 , 0.53535867, 0.5267555 , 0.5275513 ,\n",
       "       0.5312791 , 0.5365671 , 0.53975284, 0.5220513 , 0.52181315,\n",
       "       0.52501565, 0.5327609 , 0.54064333, 0.5313472 , 0.52228236],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "para_map = pickle.load(open(\"/research/rliu/fraud/data/mda/paragraphs_1994_2016.pkl\",\"rb\"))\n",
    "pos_neg_pair = pd.read_csv('./data/pos_neg_pair.csv')\n",
    "pos_neg_pair = pos_neg_pair.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75208      12\n",
       "803014     10\n",
       "849547     10\n",
       "6284       10\n",
       "859475     10\n",
       "           ..\n",
       "928395      1\n",
       "932112      1\n",
       "18498       1\n",
       "947431      1\n",
       "1604028     1\n",
       "Name: cik, Length: 328, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_pair[pos_neg_pair.fraud == 1].cik.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>fyear</th>\n",
       "      <th>count_para</th>\n",
       "      <th>fraud</th>\n",
       "      <th>fyear_bf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150242</th>\n",
       "      <td>1604028</td>\n",
       "      <td>2015</td>\n",
       "      <td>183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150243</th>\n",
       "      <td>1604028</td>\n",
       "      <td>2016</td>\n",
       "      <td>152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cik  fyear  count_para  fraud  fyear_bf\n",
       "150242  1604028   2015         183    1.0    2014.0\n",
       "150243  1604028   2016         152    0.0    2015.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_pair[pos_neg_pair.cik == 1604028]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cik = list(set(pos_neg_pair[pos_neg_pair.fraud == 1].cik))\n",
    "neg_cik = list(set(pos_neg_pair[pos_neg_pair.fraud == 0].cik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_cik = [c for c in neg_cik if c not in pos_cik]\n",
    "neg_cik = random.sample(neg_cik, len(pos_cik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 328\n"
     ]
    }
   ],
   "source": [
    "print(len(neg_cik), len(pos_cik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_cik + neg_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully load data ...\n",
      "(6293, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('successfully load data ...')\n",
    "df = pos_neg_pair[pos_neg_pair.cik.isin(pos_cik + neg_cik)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df.cik))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_label_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m my_label_1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_label_1' is not defined"
     ]
    }
   ],
   "source": [
    "my_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tb = pd.DataFrame(result, columns=['label','fold','precison','recall','f1','acc','auc','best_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = 10\n",
    "weights = torch.tensor([1,pos_weight]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_loss = nn.CrossEntropyLoss(weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_loss = nn.CrossEntropyLoss(weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0]], device='cuda:1', dtype=torch.uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jujun_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d855bc81b0407a867dfce63c14005faefd0874fe81a6ad417f5d7e68a600d1a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
